{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8Vi3NqCZl4I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **`README.md`**\n",
        "\n",
        "# History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis\n",
        "\n",
        "<!-- PROJECT SHIELDS -->\n",
        "[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)\n",
        "[![Python Version](https://img.shields.io/badge/python-3.9%2B-blue.svg)](https://www.python.org/)\n",
        "[![arXiv](https://img.shields.io/badge/arXiv-2601.10143-b31b1b.svg)](https://arxiv.org/abs/2601.10143)\n",
        "[![Journal](https://img.shields.io/badge/Journal-ArXiv%20Preprint-003366)](https://arxiv.org/abs/2601.10143)\n",
        "[![Year](https://img.shields.io/badge/Year-2026-purple)](https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis)\n",
        "[![Discipline](https://img.shields.io/badge/Discipline-Quantitative%20Finance%20%7C%20Deep%20Learning-00529B)](https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis)\n",
        "[![Data Sources](https://img.shields.io/badge/Data-Yahoo%20Finance%20%7C%20Binance-lightgrey)](https://finance.yahoo.com/)\n",
        "[![Core Method](https://img.shields.io/badge/Method-Bi--Level%20Optimization-orange)](https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis)\n",
        "[![Analysis](https://img.shields.io/badge/Analysis-Cointegration--Aware%20Mixup-red)](https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis)\n",
        "[![Validation](https://img.shields.io/badge/Validation-Stylized%20Facts%20Fidelity-green)](https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis)\n",
        "[![Robustness](https://img.shields.io/badge/Robustness-Distributional%20Drift%20Metrics-yellow)](https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis)\n",
        "[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)\n",
        "[![Type Checking: mypy](https://img.shields.io/badge/type%20checking-mypy-blue)](http://mypy-lang.org/)\n",
        "[![NumPy](https://img.shields.io/badge/numpy-%23013243.svg?style=flat&logo=numpy&logoColor=white)](https://numpy.org/)\n",
        "[![Pandas](https://img.shields.io/badge/pandas-%23150458.svg?style=flat&logo=pandas&logoColor=white)](https://pandas.pydata.org/)\n",
        "[![PyTorch](https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&logo=PyTorch&logoColor=white)](https://pytorch.org/)\n",
        "[![SciPy](https://img.shields.io/badge/SciPy-%230C55A5.svg?style=flat&logo=scipy&logoColor=white)](https://scipy.org/)\n",
        "[![Statsmodels](https://img.shields.io/badge/statsmodels-blue.svg)](https://www.statsmodels.org/)\n",
        "[![Jupyter](https://img.shields.io/badge/Jupyter-%23F37626.svg?style=flat&logo=Jupyter&logoColor=white)](https://jupyter.org/)\n",
        "\n",
        "**Repository:** `https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis`\n",
        "\n",
        "**Owner:** 2025 Craig Chirinda (Open Source Projects)\n",
        "\n",
        "This repository contains an **independent**, professional-grade Python implementation of the research methodology from the 2026 paper entitled **\"History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis\"** by:\n",
        "\n",
        "*   **Haochong Xia** (Nanyang Technological University)\n",
        "*   **Yao Long Teng** (Nanyang Technological University)\n",
        "*   **Regan Tan** (Nanyang Technological University)\n",
        "*   **Molei Qin** (Nanyang Technological University)\n",
        "*   **Xinrun Wang** (Singapore Management University)\n",
        "*   **Bo An** (Nanyang Technological University)\n",
        "\n",
        "The project provides a complete, end-to-end computational framework for replicating the paper's findings. It delivers a modular, auditable, and extensible pipeline that executes the entire research workflow: from the ingestion and rigorous validation of financial time-series data to the training of adaptive planners and task models via bi-level optimization, culminating in the evaluation of model robustness against concept drift and non-stationarity.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "- [Introduction](#introduction)\n",
        "- [Theoretical Background](#theoretical-background)\n",
        "- [Features](#features)\n",
        "- [Methodology Implemented](#methodology-implemented)\n",
        "- [Core Components (Notebook Structure)](#core-components-notebook-structure)\n",
        "- [Key Callable: `run_pipeline_orchestrator`](#key-callable-run_pipeline_orchestrator)\n",
        "- [Prerequisites](#prerequisites)\n",
        "- [Installation](#installation)\n",
        "- [Input Data Structure](#input-data-structure)\n",
        "- [Usage](#usage)\n",
        "- [Output Structure](#output-structure)\n",
        "- [Project Structure](#project-structure)\n",
        "- [Customization](#customization)\n",
        "- [Contributing](#contributing)\n",
        "- [Recommended Extensions](#recommended-extensions)\n",
        "- [License](#license)\n",
        "- [Citation](#citation)\n",
        "- [Acknowledgments](#acknowledgments)\n",
        "\n",
        "## Introduction\n",
        "\n",
        "This project provides a Python implementation of the analytical framework presented in Xia et al. (2026). The core of this repository is the iPython Notebook `adaptive_dataflow_system_for_financial_time_series_synthesis_draft.ipynb`, which contains a comprehensive suite of functions to replicate the paper's findings. The pipeline addresses the critical challenge of **concept drift** in financial markets by treating data augmentation not as a static preprocessing step, but as a dynamic, learnable policy.\n",
        "\n",
        "The paper argues that models trained on static historical data fail to generalize because market dynamics evolve ($P_t(X, Y) \\neq P_{t+k}(X, Y)$). This codebase operationalizes the proposed solution: a **Drift-Aware Adaptive Dataflow System** that:\n",
        "-   **Validates** financial data integrity using strict K-line consistency checks ($L_t \\le \\min(O_t, C_t) \\le \\max(O_t, C_t) \\le H_t$).\n",
        "-   **Synthesizes** realistic financial scenarios using a parameterized manipulation module that respects cointegration relationships.\n",
        "-   **Optimizes** augmentation strategies in real-time using a meta-learning Planner trained via bi-level optimization.\n",
        "-   **Evaluates** robustness using rigorous distributional distance metrics (PSI, K-S, MMD) and financial stylized facts.\n",
        "\n",
        "## Theoretical Background\n",
        "\n",
        "The implemented methods combine techniques from Financial Econometrics, Deep Learning, and Meta-Learning.\n",
        "\n",
        "**1. Parameterized Data Manipulation Module ($\\mathcal{M}$):**\n",
        "A controllable synthesis engine that transforms input data while preserving economic validity.\n",
        "-   **Single-Stock Transformations:** Jittering, Scaling, Magnitude Warping, Permutation, and STL Decomposition.\n",
        "-   **Multi-Stock Mix-up:** Blends assets based on **Cointegration** strength. If manipulation strength $\\lambda \\le 0.5$, it mixes highly cointegrated pairs (fidelity); if $\\lambda > 0.5$, it mixes weakly correlated pairs (stress testing).\n",
        "-   **Interpolation Compensation:** Uses **Mutual Information (MI)** to ensure augmented samples retain semantic meaning.\n",
        "\n",
        "**2. Bi-Level Optimization:**\n",
        "The system learns the optimal augmentation policy by solving a nested optimization problem:\n",
        "-   **Inner Loop:** The Task Model ($f_\\theta$) minimizes training loss on *augmented* data.\n",
        "-   **Outer Loop:** The Planner ($g_\\phi$) minimizes the Task Model's loss on *real validation* data by adjusting the augmentation policy ($p, \\lambda$).\n",
        "$$ \\min_{\\phi} \\mathcal{L}_{val}(f_\\theta, x_{valid}) \\quad \\text{s.t.} \\quad \\theta = \\arg\\min_{\\theta} \\mathcal{L}_{train}(f_\\theta, \\tilde{x}_{train}) $$\n",
        "\n",
        "**3. Adaptive Curriculum Learning:**\n",
        "An overfitting-aware scheduler dynamically adjusts the proportion of data to be augmented ($\\alpha$) based on the model's learning progress, implementing a soft curriculum that ramps up difficulty as the model improves.\n",
        "\n",
        "**4. Reinforcement Learning Transfer:**\n",
        "The augmentation policy learned on forecasting tasks is transferred to RL agents (DQN, PPO) to improve their robustness in trading environments with transaction costs and regime shifts.\n",
        "\n",
        "## Features\n",
        "\n",
        "The provided iPython Notebook (`adaptive_dataflow_system_for_financial_time_series_synthesis_draft.ipynb`) implements the full research pipeline, including:\n",
        "\n",
        "-   **Modular, Multi-Task Architecture:** The pipeline is decomposed into 36 distinct, modular tasks, each with its own orchestrator function.\n",
        "-   **Configuration-Driven Design:** All study parameters (architectures, learning rates, augmentation settings) are managed in an external `config.yaml` file.\n",
        "-   **Rigorous Data Validation:** A multi-stage validation process checks schema integrity, K-line consistency, and temporal alignment.\n",
        "-   **Deterministic Execution:** Enforces reproducibility through seed control, deterministic sorting, and rigorous logging of all stochastic outputs.\n",
        "-   **Comprehensive Evaluation:** Computes forecasting metrics (MSE, MAE), trading metrics (Sharpe Ratio, Total Return), and distributional drift metrics (PSI, K-S, MMD).\n",
        "-   **Reproducible Artifacts:** Generates structured `RunContext` objects, serializable outputs, and cryptographic manifests for every intermediate result.\n",
        "\n",
        "## Methodology Implemented\n",
        "\n",
        "The core analytical steps directly implement the methodology from the paper:\n",
        "\n",
        "1.  **Validation & Cleansing (Tasks 1-4):** Ingests raw OHLCV data, validates schemas, enforces K-line constraints, and cleanses missing values.\n",
        "2.  **Configuration Resolution (Task 5):** Resolves missing parameters with ground-truth defaults and hashes the configuration for provenance.\n",
        "3.  **Feature Engineering (Tasks 6-10):** Computes forecasting targets, constructs sliding windows, aligns tensors for mix-up, creates chronological splits, normalizes data, and computes cointegration matrices.\n",
        "4.  **Data Manipulation Module (Tasks 11-15):** Implements single-stock transformations, curation layers, multi-stock mix-up operations (CutMix, LinearMix, AmplitudeMix), target sampling (Algorithm 1), and binary mix compensation (Algorithm 2).\n",
        "5.  **Adaptive Control (Tasks 16-26):** Implements the curriculum scheduler (Algorithm 3), the joint training scheme (Algorithm 4), the modular task model interface, specific architectures (GRU, LSTM, TCN, Transformer, DLinear), the Planner network, risk-aware loss, and bi-level optimization updates.\n",
        "6.  **Training Pipeline (Task 27):** Orchestrates the end-to-end training of forecasting models using the adaptive planner.\n",
        "7.  **RL Transfer (Tasks 28-31):** Implements the trading environment, DQN/PPO agents, and the transfer learning experiment using the pre-trained planner.\n",
        "8.  **Evaluation (Tasks 32-35):** Computes trading metrics, distribution shift metrics, stylized facts fidelity, and generates t-SNE visualizations.\n",
        "9.  **Orchestration (Task 36):** Unifies all components into a single `run_pipeline_orchestrator` function.\n",
        "\n",
        "## Core Components (Notebook Structure)\n",
        "\n",
        "The notebook is structured as a logical pipeline with modular orchestrator functions for each of the 36 major tasks. All functions are self-contained, fully documented with type hints and docstrings, and designed for professional-grade execution.\n",
        "\n",
        "## Key Callable: `run_pipeline_orchestrator`\n",
        "\n",
        "The project is designed around a single, top-level user-facing interface function:\n",
        "\n",
        "-   **`run_pipeline_orchestrator`:** This master orchestrator function runs the entire automated research pipeline from end-to-end. A single call to this function reproduces the entire computational portion of the project, managing data flow between validation, cleansing, modeling, transfer learning, and evaluation modules.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "-   Python 3.9+\n",
        "-   Core dependencies: `pandas`, `numpy`, `torch`, `scipy`, `statsmodels`, `scikit-learn`, `matplotlib`, `pyyaml`.\n",
        "\n",
        "## Installation\n",
        "\n",
        "1.  **Clone the repository:**\n",
        "    ```sh\n",
        "    git clone https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis.git\n",
        "    cd adaptive_dataflow_system_for_financial_time_series_synthesis\n",
        "    ```\n",
        "\n",
        "2.  **Create and activate a virtual environment (recommended):**\n",
        "    ```sh\n",
        "    python -m venv venv\n",
        "    source venv/bin/activate  # On Windows, use `venv\\Scripts\\activate`\n",
        "    ```\n",
        "\n",
        "3.  **Install Python dependencies:**\n",
        "    ```sh\n",
        "    pip install pandas numpy torch scipy statsmodels scikit-learn matplotlib pyyaml\n",
        "    ```\n",
        "\n",
        "## Input Data Structure\n",
        "\n",
        "The pipeline requires a primary DataFrame `df_raw` with a MultiIndex `(date, ticker)` and the following columns:\n",
        "1.  **`Open`**: Float, $>0$.\n",
        "2.  **`High`**: Float, $\\ge \\max(Open, Close)$.\n",
        "3.  **`Low`**: Float, $\\le \\min(Open, Close)$.\n",
        "4.  **`Close`**: Float, $>0$.\n",
        "5.  **`Volume`**: Int/Float, $\\ge 0$.\n",
        "6.  **`AdjClose`**: Float, $>0$ (Required for US Stocks).\n",
        "7.  **`technical_indicators`**: Numeric columns as specified in the config.\n",
        "\n",
        "## Usage\n",
        "\n",
        "The notebook provides a complete, step-by-step guide. The primary workflow is to execute the final cell, which demonstrates how to use the top-level `run_pipeline_orchestrator` orchestrator:\n",
        "\n",
        "```python\n",
        "# Final cell of the notebook\n",
        "\n",
        "# This block serves as the main entry point for the entire project.\n",
        "if __name__ == '__main__':\n",
        "    # 1. Load the master configuration from the YAML file.\n",
        "    with open(\"config.yaml\", \"r\") as f:\n",
        "        study_config = yaml.safe_load(f)\n",
        "    \n",
        "    # 2. Load raw datasets (Example using synthetic generator provided in the notebook)\n",
        "    # In production, load from CSV/Parquet: pd.read_csv(...)\n",
        "    df_raw = generate_synthetic_financial_data()\n",
        "\n",
        "    # 3. Execute the entire replication study.\n",
        "    run_context = run_pipeline_orchestrator(\n",
        "        df_raw=df_raw,\n",
        "        universe=\"US_Stocks_Daily\",\n",
        "        study_config=study_config,\n",
        "        output_dir=\"./experiment_artifacts\"\n",
        "    )\n",
        "    \n",
        "    # 4. Access results\n",
        "    if run_context.training_results:\n",
        "        print(run_context.training_results[\"LSTM\"][\"metrics\"])\n",
        "```\n",
        "\n",
        "## Output Structure\n",
        "\n",
        "The pipeline returns a `RunContext` object containing:\n",
        "-   **`config`**: The resolved configuration dictionary.\n",
        "-   **`df_clean`**: The cleansed and curated DataFrame.\n",
        "-   **`tensor_data`**: Dictionary of windowed and aligned tensors.\n",
        "-   **`training_results`**: Dictionary containing metrics, history, and state dicts for all trained models.\n",
        "-   **`rl_results`**: Results from the RL transfer experiment.\n",
        "-   **`drift_metrics`**: Dictionary of PSI, K-S, and MMD scores.\n",
        "-   **`stylized_facts`**: Dictionary of fidelity metrics (ACF, Leverage Effect).\n",
        "-   **`drift_plots`**: Paths to generated t-SNE plots.\n",
        "\n",
        "## Project Structure\n",
        "\n",
        "```\n",
        "adaptive_dataflow_system_for_financial_time_series_synthesis/\n",
        "│\n",
        "├── adaptive_dataflow_system_for_financial_time_series_synthesis_draft.ipynb   # Main implementation notebook\n",
        "├── config.yaml                                                                # Master configuration file\n",
        "├── requirements.txt                                                           # Python package dependencies\n",
        "│\n",
        "├── LICENSE                                                                    # MIT Project License File\n",
        "└── README.md                                                                  # This file\n",
        "```\n",
        "\n",
        "## Customization\n",
        "\n",
        "The pipeline is highly customizable via the `config.yaml` file. Users can modify study parameters such as:\n",
        "-   **Global Settings:** `lookback_window`, `split_ratios`, `rolling_protocol`.\n",
        "-   **Model Architectures:** `hidden_dim`, `num_layers`, `dropout` for GRU, LSTM, TCN, Transformer, DLinear.\n",
        "-   **Planner Settings:** `input_dim`, `sharpe_loss_gamma`, `update_freq`.\n",
        "-   **Augmentation:** `operations` list, `cointegration_threshold_lambda`.\n",
        "-   **RL Environment:** `transaction_cost`, `initial_capital`, `policy_lr`.\n",
        "\n",
        "## Contributing\n",
        "\n",
        "Contributions are welcome. Please fork the repository, create a feature branch, and submit a pull request with a clear description of your changes. Adherence to PEP 8, type hinting, and comprehensive docstrings is required.\n",
        "\n",
        "## Recommended Extensions\n",
        "\n",
        "Future extensions could include:\n",
        "-   **Additional Task Models:** Integrating state-of-the-art architectures like N-BEATS or TFT.\n",
        "-   **Real-Time Adaptation:** Extending the pipeline to support online learning with streaming data.\n",
        "-   **Multi-Asset RL:** Expanding the RL environment to support portfolio optimization across multiple assets.\n",
        "\n",
        "## License\n",
        "\n",
        "This project is licensed under the MIT License. See the `LICENSE` file for details.\n",
        "\n",
        "## Citation\n",
        "\n",
        "If you use this code or the methodology in your research, please cite the original paper:\n",
        "\n",
        "```bibtex\n",
        "@article{xia2026history,\n",
        "  title={History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis},\n",
        "  author={Xia, Haochong and Teng, Yao Long and Tan, Regan and Qin, Molei and Wang, Xinrun and An, Bo},\n",
        "  journal={arXiv preprint arXiv:2601.10143},\n",
        "  year={2026}\n",
        "}\n",
        "```\n",
        "\n",
        "For the implementation itself, you may cite this repository:\n",
        "```\n",
        "Chirinda, C. (2025). Adaptive Dataflow System for Financial Time-Series Synthesis: An Open Source Implementation.\n",
        "GitHub repository: https://github.com/chirindaopensource/adaptive_dataflow_system_for_financial_time_series_synthesis\n",
        "```\n",
        "\n",
        "## Acknowledgments\n",
        "\n",
        "-   Credit to **Haochong Xia, Yao Long Teng, Regan Tan, Molei Qin, Xinrun Wang, and Bo An** for the foundational research that forms the entire basis for this computational replication.\n",
        "-   This project is built upon the exceptional tools provided by the open-source community. Sincere thanks to the developers of the scientific Python ecosystem, including **Pandas, NumPy, PyTorch, SciPy, Statsmodels, and Scikit-Learn**.\n",
        "\n",
        "--\n",
        "\n",
        "*This README was generated based on the structure and content of the `adaptive_dataflow_system_for_financial_time_series_synthesis_draft.ipynb` notebook and follows best practices for research software documentation.*\n"
      ],
      "metadata": {
        "id": "bEQQQO7vYqX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Paper\n",
        "\n",
        "Title: *\"History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis*\"\n",
        "\n",
        "Authors: Haochong Xia, Yao Long Teng, Regan Tan, Molei Qin, Xinrun Wang, Bo An\n",
        "\n",
        "E-Journal Submission Date: 15 June 2026\n",
        "\n",
        "Link: https://arxiv.org/abs/2601.10143\n",
        "\n",
        "Abstract:\n",
        "\n",
        "In quantitative finance, the gap between training and real-world performance-driven by concept drift and distributional non-stationarity-remains a critical obstacle for building reliable data-driven systems. Models trained on static historical data often overfit, resulting in poor generalization in dynamic markets. The mantra \"History Is Not Enough\" underscores the need for adaptive data generation that learns to evolve with the market rather than relying solely on past observations. We present a drift-aware dataflow system that integrates machine learning-based adaptive control into the data curation process. The system couples a parameterized data manipulation module comprising single-stock transformations, multi-stock mix-ups, and curation operations, with an adaptive planner-scheduler that employs gradient-based bi-level optimization to control the system. This design unifies data augmentation, curriculum learning, and data workflow management under a single differentiable framework, enabling provenance-aware replay and continuous data quality monitoring. Extensive experiments on forecasting and reinforcement learning trading tasks demonstrate that our framework enhances model robustness and improves risk-adjusted returns. The system provides a generalizable approach to adaptive data management and learning-guided workflow automation for financial data.\n"
      ],
      "metadata": {
        "id": "4mpftqeOuw6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "### **Executive Summary**\n",
        "\n",
        "This paper addresses a fundamental pathology in quantitative finance: the failure of the **Independent and Identically Distributed (i.i.d.)** assumption due to **concept drift** and **distributional non-stationarity**. The authors argue that training models on static historical data leads to overfitting because market dynamics evolve ($P_t(X, Y) \\neq P_{t+k}(X, Y)$).\n",
        "\n",
        "To resolve this, they propose a **Drift-Aware Adaptive Dataflow System**. Unlike static data augmentation (common in Computer Vision) or computationally expensive generative models (GANs/Diffusion), this system employs a **bi-level optimization framework**. It couples a financially grounded **Parameterized Data Manipulation Module** with a **Learning-Guided Planner-Scheduler**. The system dynamically adjusts data synthesis strategies based on real-time validation feedback from the downstream task model, effectively unifying data augmentation, curriculum learning, and workflow automation.\n",
        "\n",
        "--\n",
        "\n",
        "### **Problem Formulation & Motivation**\n",
        "\n",
        "The authors identify three critical gaps in current financial machine learning pipelines:\n",
        "1.  **Concept Drift:** Financial markets exhibit time-varying joint probability distributions. Models trained on past regimes fail to generalize to future regimes (the \"History Is Not Enough\" mantra).\n",
        "2.  **Lack of Financial Fidelity in Augmentation:** Standard time-series augmentations often violate economic constraints (e.g., K-line consistency where $High \\geq Low$, or destroying cointegration relationships).\n",
        "3.  **Static Pipelines:** Existing adaptive methods (like AdaAug) do not continuously adapt transformation policies as the model state evolves during training.\n",
        "\n",
        "**The Objective:** To create a differentiable, closed-loop system where the data generation process evolves alongside the model learning process, maximizing generalization on unseen (future) data.\n",
        "\n",
        "--\n",
        "\n",
        "### **The Parameterized Data Manipulation Module ($\\mathcal{M}$)**\n",
        "\n",
        "The authors introduce a synthesis module designed to inject diversity while strictly preserving financial \"stylized facts.\" This is not a black-box generator but a controllable pipeline composed of four layers:\n",
        "\n",
        "1.  **Transformation Layer (Single-Stock):**\n",
        "    *   *Operations:* Jittering (noise injection), Scaling, Magnitude Warping (cubic spline interpolation), Permutation, and STL Decomposition (bootstrapping residuals).\n",
        "    *   *Control:* Parameterized by strength $\\lambda$.\n",
        "\n",
        "2.  **Curation & Normalization Layer:**\n",
        "    *   **Constraint Enforcement:** Explicitly enforces K-line consistency ($Low \\leq \\min(Open, Close) \\leq \\max(Open, Close) \\leq High$).\n",
        "    *   **Normalization:** Uses rolling-window standard normalization to facilitate cross-asset mixing.\n",
        "\n",
        "3.  **Mix-up Layer (Multi-Stock):**\n",
        "    *   *Innovation:* Instead of random mixing, they use **Cointegration Testing**.\n",
        "    *   *Target Selection:* A source stock is mixed with a target stock selected based on cointegration p-values.\n",
        "    *   *Mechanism:* If manipulation strength $\\lambda \\leq 0.5$, the system favors highly cointegrated pairs (preserving logic). If $\\lambda > 0.5$, it selects less correlated stocks (introducing regime-shift stress testing).\n",
        "    *   *Methods:* CutMix, Linear Mix, Amplitude Mix (frequency domain), and Phase/Magnitude mixing.\n",
        "\n",
        "4.  **Interpolation Compensation Layer:**\n",
        "    *   Uses **Mutual Information (MI)** to calculate a mixing factor $b_{mix}$.\n",
        "    *   Ensures that if the augmented sample loses too much semantic information (low MI with original), the system compensates by weighting the original data more heavily.\n",
        "\n",
        "--\n",
        "\n",
        "### **The Learning-Guided Controller (Planner & Scheduler)**\n",
        "\n",
        "The core algorithmic contribution is the automation of the synthesis module via a **Bi-Level Optimization** scheme.\n",
        "\n",
        "#### **A. The Planner ($g_\\phi$)**\n",
        "*   **Role:** Acts as a meta-learner that outputs the policy $\\pi_\\phi(p, \\lambda | f, x_i)$, determining the probability ($p$) and strength ($\\lambda$) of augmentations.\n",
        "*   **Input State:**\n",
        "    1.  **Model State:** Features from the task model's ($f_\\theta$) penultimate layer.\n",
        "    2.  **Data State:** Statistical moments (mean, volatility, skewness, kurtosis, trend) of the input batch.\n",
        "*   **Optimization:** The planner minimizes the **Validation Loss** of the task model (proxy for future generalization), while the task model minimizes Training Loss on augmented data.\n",
        "    $$ \\min_{\\phi} \\mathcal{L}_{val}(f_\\theta, x_{valid}) \\quad \\text{s.t.} \\quad \\theta = \\arg\\min_{\\theta} \\mathcal{L}_{train}(f_\\theta, \\tilde{x}_{train}) $$\n",
        "\n",
        "#### **B. The Overfitting-Aware Scheduler**\n",
        "*   **Role:** Controls the curriculum pacing, specifically the proportion ($\\alpha$) of data to be augmented.\n",
        "*   **Mechanism:**\n",
        "    *   Starts with low augmentation (easy samples).\n",
        "    *   Increases $\\alpha$ monotonically based on a soft curriculum.\n",
        "    *   **Feedback Loop:** If validation loss stagnates or rises (signaling overfitting), the scheduler removes the \"rate penalty,\" allowing for more aggressive data manipulation to force the model out of local minima.\n",
        "\n",
        "--\n",
        "\n",
        "### **Experimental Validation**\n",
        "\n",
        "The system was rigorously tested against baselines (Original, RandAug, TrivialAug, AdaAug) and generative models (TimeGAN, Diffusion-TS).\n",
        "\n",
        "#### **A. Setup**\n",
        "*   **Datasets:** US Stocks (DJIA components, daily) and Cryptocurrency (BTC/ETH/etc., hourly).\n",
        "*   **Task Models:** Forecasting (GRU, LSTM, TCN, Transformer, DLinear) and RL Trading (DQN, PPO).\n",
        "\n",
        "#### **B. Key Results**\n",
        "1.  **Forecasting Accuracy:** The system consistently achieved the lowest MSE and MAE across almost all architectures. Notably, it rescued weaker models (like TCN/DLinear) where random augmentation often hurt performance.\n",
        "2.  **RL Trading Performance:**\n",
        "    *   **Sharpe Ratio (SR):** Significant improvements. For DQN on INTC stock, SR improved from 5.06 to **25.74**.\n",
        "    *   **Risk Control:** The agent learned to exit positions before downturns, attributed to training on diverse, synthesized \"stress scenarios.\"\n",
        "3.  **Data Fidelity (Stylized Facts):**\n",
        "    *   The augmented data maintained the lowest **Discriminative Score** (hardest for a classifier to distinguish from real data) compared to GANs.\n",
        "    *   It accurately reproduced the **Leverage Effect** (correlation between returns and volatility) and autocorrelation structures, which are often lost in deep generative models.\n",
        "\n",
        "--\n",
        "\n",
        "### **Critical Synthesis**\n",
        "\n",
        "This paper represents a maturation of data augmentation in finance. It moves away from the *ad-hoc* application of Computer Vision techniques (like simple jittering) toward a **structural, domain-aware methodology**.\n",
        "\n",
        "**Three distinct contributions stand out:**\n",
        "1.  **Economic Plausibility:** By integrating cointegration logic and K-line constraints into the mix-up process, the authors solve the \"validity\" problem of financial augmentation.\n",
        "2.  **Dynamic Control:** The use of a validation-loss-driven planner acknowledges that the optimal augmentation strategy is not static; it changes as the model learns. This effectively creates an automated curriculum.\n",
        "3.  **Provenance & Auditability:** Unlike \"black-box\" latent space sampling (GANs/Diffusion), this pipeline uses explicit, parameterized operations. This allows for exact replay and auditing, a crucial requirement for institutional quantitative finance.\n",
        "\n",
        "**Conclusion:** The authors successfully demonstrate that while historical data is static, the *learning process* need not be. By synthesizing \"possible futures\" that are statistically grounded yet diverse, the system builds models that are robust to the inevitable non-stationarity of financial markets."
      ],
      "metadata": {
        "id": "11u2Y6FT17iq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Essential Modules"
      ],
      "metadata": {
        "id": "KPNwGJilx-wk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# ========================================================================================#\n",
        "#\n",
        "#  History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis\n",
        "#\n",
        "#  This module provides a complete, production-grade implementation of the\n",
        "#  adaptive dataflow system presented in \"History Is Not Enough: An Adaptive\n",
        "#  Dataflow System for Financial Time-Series Synthesis\" by Haochong Xia et al.\n",
        "#  (2026). It delivers a computationally rigorous framework for immunizing\n",
        "#  quantitative financial models against concept drift and distributional\n",
        "#  non-stationarity through a bi-level optimization scheme that unifies data\n",
        "#  augmentation, curriculum learning, and automated workflow management.\n",
        "#\n",
        "#  Core Methodological Components:\n",
        "#  • Parameterized Data Manipulation Module (M) with K-line consistency enforcement\n",
        "#  • Cointegration-aware multi-stock mix-up target sampling (Algorithm 1)\n",
        "#  • Information-theoretic interpolation compensation via Mutual Information (Algorithm 2)\n",
        "#  • Adaptive curriculum pacing via an overfitting-aware scheduler (Algorithm 3)\n",
        "#  • Gradient-based bi-level optimization for joint planner-task model training (Algorithm 4)\n",
        "#  • Straight-Through Estimator (STE) for differentiable augmentation policy learning\n",
        "#  • Reinforcement Learning (RL) environment with transaction costs and regime-switching logic\n",
        "#\n",
        "#  Technical Implementation Features:\n",
        "#  • Modular neural architecture separating feature extraction from prediction heads\n",
        "#  • Frequency-domain signal processing (FFT) for amplitude and phase mixing\n",
        "#  • Robust statistical evaluation metrics: PSI, K-S Statistic, MMD, and Stylized Facts\n",
        "#  • Provenance-aware replay system for exact reproducibility of synthetic data streams\n",
        "#  • Leakage-proof rolling window protocols for rigorous backtesting and validation\n",
        "#  • Integration with PyTorch for differentiable meta-learning and optimization\n",
        "#\n",
        "#  Paper Reference:\n",
        "#  Xia, H., Teng, Y. L., Tan, R., Qin, M., Wang, X., & An, B. (2026).\n",
        "#  History Is Not Enough: An Adaptive Dataflow System for Financial Time-Series Synthesis.\n",
        "#  arXiv preprint arXiv:2601.10143.\n",
        "#  https://arxiv.org/abs/2601.10143\n",
        "#\n",
        "#  Author: CS Chirinda\n",
        "#  License: MIT\n",
        "#  Version: 1.0.0\n",
        "#\n",
        "# ========================================================================================#\n",
        "\n",
        "# ==============================================================================\n",
        "# Consolidated Imports for Adaptive Dataflow System\n",
        "# ==============================================================================\n",
        "\n",
        "# Standard Library Imports\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import logging\n",
        "import math\n",
        "import random\n",
        "import hashlib\n",
        "import copy\n",
        "from abc import ABC, abstractmethod\n",
        "from collections import deque\n",
        "from functools import partial\n",
        "from dataclasses import dataclass, field\n",
        "from typing import (\n",
        "    Dict,\n",
        "    List,\n",
        "    Tuple,\n",
        "    Optional,\n",
        "    Union,\n",
        "    Any,\n",
        "    Callable,\n",
        "    Deque,\n",
        "    Set\n",
        ")\n",
        "\n",
        "# Scientific Computing & Data Analysis\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from numpy.lib.stride_tricks import sliding_window_view\n",
        "from scipy import stats\n",
        "from scipy.interpolate import CubicSpline\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Machine Learning & Deep Learning (PyTorch)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Function\n",
        "from torch.distributions import Categorical\n",
        "from torch.nn.utils import weight_norm\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Machine Learning (Scikit-Learn)\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "# Financial Econometrics\n",
        "from statsmodels.tsa.stattools import coint\n",
        "\n",
        "# ==============================================================================\n",
        "# End of Imports\n",
        "# ==============================================================================\n",
        "\n",
        "# Configure logging for the module\n",
        "logger = logging.getLogger(__name__)\n",
        "logger.setLevel(logging.INFO)\n",
        "if not logger.handlers:\n",
        "    handler = logging.StreamHandler()\n",
        "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
        "    handler.setFormatter(formatter)\n",
        "    logger.addHandler(handler)\n"
      ],
      "metadata": {
        "id": "hYltJbebyDLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementation"
      ],
      "metadata": {
        "id": "rrqpxGatyFC2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Draft 1\n",
        "\n",
        "## **Discussion of the Inputs, Processes, and Outputs (IPO) of Key Callables**\n",
        "\n",
        "### **1. `validate_raw_data_schema` (Task 1 Orchestrator)**\n",
        "*   **Role:** Implements the foundational data integrity checks required before any processing begins. It ensures the input data adheres to the schema assumed by the mathematical models (e.g., K-line structure).\n",
        "*   **Inputs:** `df_raw` (Pandas DataFrame), `universe` (String), `study_config` (Dictionary).\n",
        "*   **Process:** Sequentially invokes structural validation (MultiIndex check), temporal integrity validation (monotonicity check), and universe membership validation. It aggregates the results into a metadata report.\n",
        "*   **Outputs:** A dictionary containing validation status and per-ticker statistics.\n",
        "*   **Transformation:** The input DataFrame is inspected but not modified. Metadata is extracted.\n",
        "*   **Manuscript Link:** Enforces the data structure defined in **Section III-A (Preliminaries)**:\n",
        "    $$ x_t = [O_t, H_t, L_t, C_t, V_t] $$\n",
        "    It ensures the necessary components for this tuple exist.\n",
        "\n",
        "### **2. `validate_study_config` (Task 2 Orchestrator)**\n",
        "*   **Role:** Ensures the experimental configuration is complete and consistent with the manuscript's specifications. It acts as a gatekeeper for reproducibility.\n",
        "*   **Inputs:** `study_config` (Dictionary).\n",
        "*   **Process:** Checks for the existence of all required keys (e.g., `planner`, `scheduler`), identifies any `REQUIRED_FROM_CODE` placeholders, and validates cross-references (e.g., ensuring `topk_candidates` matches between econometrics and manipulation modules).\n",
        "*   **Outputs:** A list of unresolved parameter paths.\n",
        "*   **Transformation:** The configuration dictionary is traversed and inspected.\n",
        "*   **Manuscript Link:** Validates the hyperparameters detailed in **Section V-A (Experiment Setup)**, such as learning rates, batch sizes, and the specific $\\tau$ values for the scheduler.\n",
        "\n",
        "### **3. `validate_financial_realism` (Task 3 Orchestrator)**\n",
        "*   **Role:** Enforces the economic constraints that distinguish financial time series from generic data.\n",
        "*   **Inputs:** `df_raw` (Pandas DataFrame), `universe` (String).\n",
        "*   **Process:** Checks for price positivity ($P > 0$) and validates the K-line consistency constraint. It also checks for temporal gaps in high-frequency data.\n",
        "*   **Outputs:** A report dictionary containing DataFrames of violating rows.\n",
        "*   **Transformation:** Boolean masks are generated to identify invalid rows.\n",
        "*   **Manuscript Link:** Strictly enforces **Equation (2)**:\n",
        "    $$ L_t \\leq \\min(O_t, C_t) \\leq \\max(O_t, C_t) \\leq H_t $$\n",
        "\n",
        "### **4. `cleanse_and_curate_data` (Task 4 Orchestrator)**\n",
        "*   **Role:** Transforms raw, potentially noisy data into a clean dataset that respects financial constraints.\n",
        "*   **Inputs:** `df_raw` (Pandas DataFrame), `universe` (String).\n",
        "*   **Process:** Removes duplicates and NaNs. Applies deterministic curation to fix K-line violations (e.g., swapping High/Low if inverted). Ensures `AdjClose` exists for valuation.\n",
        "*   **Outputs:** `df_final` (Clean DataFrame), metadata dictionary.\n",
        "*   **Transformation:**\n",
        "    *   Rows with NaNs are dropped.\n",
        "    *   Values are modified in-place: $H_t \\leftarrow \\max(O,H,L,C)$, $L_t \\leftarrow \\min(O,H,L,C)$.\n",
        "*   **Manuscript Link:** Implements the \"Curation\" step described in **Section IV-B (Parameterized Data Manipulation Module)**, ensuring input data is valid before augmentation.\n",
        "\n",
        "### **5. `resolve_study_configuration` (Task 5 Orchestrator)**\n",
        "*   **Role:** Bridges the gap between the manuscript's text and the code implementation by injecting ground-truth default values for unspecified parameters.\n",
        "*   **Inputs:** `study_config` (Dictionary).\n",
        "*   **Process:** Merges the input config with a dictionary of resolved specifications (e.g., specific architecture details for TCN). Computes a SHA256 hash of the final config for provenance.\n",
        "*   **Outputs:** `resolved_config` (Dictionary), `config_hash` (String).\n",
        "*   **Transformation:** The configuration dictionary is mutated to replace placeholders with concrete values.\n",
        "*   **Manuscript Link:** Enables the exact reproduction of the experiments in **Section V**, ensuring parameters like `topk_candidates` match the authors' setup.\n",
        "\n",
        "### **6. `compute_forecasting_targets` (Task 6 Orchestrator)**\n",
        "*   **Role:** Generates the supervised learning targets for the forecasting task.\n",
        "*   **Inputs:** `df_final` (Pandas DataFrame).\n",
        "*   **Process:** Calculates the one-step close-to-close return for each ticker. Aligns the target $y_t$ with the feature vector at time $t$ (representing the return realized at $t+1$). Drops the final row where the target is undefined.\n",
        "*   **Outputs:** `y` (Pandas Series), metadata.\n",
        "*   **Transformation:**\n",
        "    $$ y_t = \\frac{C_{t+1} - C_t}{C_t} $$\n",
        "*   **Manuscript Link:** Implements **Equation (5)**, defining the prediction target for the forecasting models.\n",
        "\n",
        "### **7. `construct_feature_tensors` (Task 7 Orchestrator)**\n",
        "*   **Role:** Converts tabular data into the tensor formats required for deep learning and the manipulation module.\n",
        "*   **Inputs:** `df_final` (DataFrame), `target_series` (Series), `study_config` (Dictionary).\n",
        "*   **Process:**\n",
        "    1.  Generates sliding windows $(N, L, F)$ for the forecasting model.\n",
        "    2.  Constructs an aligned tensor $(T, S, F)$ for multi-stock mix-up operations.\n",
        "    3.  Prepares data for the RL environment.\n",
        "*   **Outputs:** Dictionary containing `X_windows`, `aligned_tensor`, `rl_data`.\n",
        "*   **Transformation:**\n",
        "    *   Sliding Window: $X_{i} = [x_{t-L+1}, \\dots, x_t]$.\n",
        "    *   Alignment: Pivots data so that $X_{t, s, f}$ corresponds to feature $f$ of stock $s$ at time $t$.\n",
        "*   **Manuscript Link:** Prepares the input $x_{t-L+1:t}$ defined in **Equation (3)** and the aligned structure required for **Algorithm 1**.\n",
        "\n",
        "### **8. `create_chronological_splits` (Task 8 Orchestrator)**\n",
        "*   **Role:** Defines the training, validation, and test boundaries to prevent look-ahead bias.\n",
        "*   **Inputs:** `timestamps` (Pandas Index), `universe` (String), `study_config` (Dictionary).\n",
        "*   **Process:** Calculates indices for a strict chronological split (0.6/0.2/0.2). Generates rolling window folds for the proximity analysis.\n",
        "*   **Outputs:** `SplitMetadata` object.\n",
        "*   **Transformation:** Maps global timestamps to integer indices for each subset.\n",
        "*   **Manuscript Link:** Implements the splitting protocol described in **Section III-C (Validation-Test Proximity)** and **Section V-A**.\n",
        "\n",
        "### **9. `normalize_data` (Task 9 Orchestrator)**\n",
        "*   **Role:** Standardizes the data to facilitate gradient descent and cross-asset mixing.\n",
        "*   **Inputs:** `aligned_tensor` (NumPy Array), `split_metadata` (Object), `feature_names` (List).\n",
        "*   **Process:** Fits a Z-score normalizer using **only** the training set indices. Applies this normalization to the entire tensor.\n",
        "*   **Outputs:** `normalized_tensor`, `normalizer` (Artifact).\n",
        "*   **Transformation:**\n",
        "    $$ \\tilde{x} = \\frac{x - \\mu_{train}}{\\sigma_{train}} $$\n",
        "*   **Manuscript Link:** Implements the normalization required by the **Mix-up Layer** in **Section IV-B**, ensuring no information leakage from the future.\n",
        "\n",
        "### **10. `compute_cointegration_matrix` (Task 10 Orchestrator)**\n",
        "*   **Role:** Computes the statistical relationships between assets to guide the mix-up target sampling.\n",
        "*   **Inputs:** `tensor` (Array), `split_metadata` (Object), `study_config` (Dictionary).\n",
        "*   **Process:** Extracts training-set prices. Computes pairwise Engle-Granger cointegration p-values for all stock pairs. Validates the resulting matrix.\n",
        "*   **Outputs:** `p_matrix` (NumPy Array of shape $S \\times S$).\n",
        "*   **Transformation:**\n",
        "    *   Input: Price series $P_i, P_j$.\n",
        "    *   Output: $p_{ij} = \\text{p-value of } \\text{ADF}(\\text{residuals}(P_i, P_j))$.\n",
        "*   **Manuscript Link:** Generates the input $\\mathbf{p}=\\{p_{aj}\\}_j$ required by **Algorithm 1 (Mix-up Target Stock Sampling)**.\n",
        "\n",
        "### **11. `SingleStockTransformations` (Task 11 Class)**\n",
        "*   **Role:** A registry of augmentation operations applied to individual time series.\n",
        "*   **Inputs:** `x` (Window), `op_name` (String), `strength` (Float), `seed` (Int).\n",
        "*   **Process:** Dispatches the call to specific functions like `op_jitter`, `op_scaling`, or `op_stl_augmentation`. Uses a seeded RNG for determinism.\n",
        "*   **Outputs:** Transformed window `x_aug`.\n",
        "*   **Transformation:** Applies operations like $x' = x + \\epsilon$ (Jitter) or $x' = x \\cdot (1+\\alpha)$ (Scaling), parameterized by $\\lambda$.\n",
        "*   **Manuscript Link:** Implements the **Transformation Layer** described in **Section IV-B** and **Section III-E**.\n",
        "\n",
        "### **12. `apply_curation_and_normalization` (Task 12 Orchestrator)**\n",
        "*   **Role:** Ensures that augmented data remains valid and is properly scaled for mixing.\n",
        "*   **Inputs:** `x` (Raw Window), `ohlc_indices`, `mean`, `std`.\n",
        "*   **Process:**\n",
        "    1.  **Curation:** Enforces $L \\le \\min(O,C) \\le \\max(O,C) \\le H$.\n",
        "    2.  **Normalization:** Applies Z-score normalization using the provided statistics.\n",
        "*   **Outputs:** Curated and normalized window.\n",
        "*   **Transformation:** Modifies OHLC values to satisfy constraints, then scales.\n",
        "*   **Manuscript Link:** Implements the **Curation and Normalization Layer** of Module $\\mathcal{M}$ (**Section IV-B**).\n",
        "\n",
        "### **13. `MultiStockMixup` (Task 13 Class)**\n",
        "*   **Role:** A registry of augmentation operations that blend two different assets.\n",
        "*   **Inputs:** `x_src`, `y_src`, `x_tgt`, `y_tgt`, `op_name`, `strength`, `seed`.\n",
        "*   **Process:** Dispatches to operations like `op_cut_mix` or `op_amplitude_mix`.\n",
        "*   **Outputs:** Mixed window `x_new` and label `y_new`.\n",
        "*   **Transformation:** Blends features and labels, e.g., via linear interpolation or frequency domain mixing.\n",
        "*   **Manuscript Link:** Implements the **Mix-up Layer** described in **Section IV-B** and **Section III-E**.\n",
        "\n",
        "### **14. `sample_mixup_target` (Task 14 Orchestrator)**\n",
        "*   **Role:** Selects a target stock for mix-up based on cointegration and manipulation strength.\n",
        "*   **Inputs:** `source_idx`, `strength` ($\\lambda$), `p_matrix`, `k`, `seed`.\n",
        "*   **Process:**\n",
        "    1.  Calculates scores $S_j$ based on $\\lambda$ (favoring strong vs. weak cointegration).\n",
        "    2.  Selects top-$k$ candidates.\n",
        "    3.  Samples target $b$ using softmax probabilities.\n",
        "*   **Outputs:** Target stock index $b$.\n",
        "*   **Transformation:** Maps a source stock and $\\lambda$ to a target stock index.\n",
        "*   **Manuscript Link:** Strictly implements **Algorithm 1: Mix-up Target Stock Sampling**.\n",
        "\n",
        "### **15. `binary_mix_compensation` (Task 15 Orchestrator)**\n",
        "*   **Role:** Adjusts the intensity of augmentation to preserve semantic information.\n",
        "*   **Inputs:** `x_orig`, `x_aug`, `b_max`, `seed`.\n",
        "*   **Process:**\n",
        "    1.  Estimates Mutual Information $MI(X; Y)$.\n",
        "    2.  Computes mixing factor $b_{mix}$.\n",
        "    3.  Interpolates original data back into the augmented sample.\n",
        "*   **Outputs:** Compensated window.\n",
        "*   **Transformation:**\n",
        "    $$ x' = b_{mix}x + (1-b_{mix})y $$\n",
        "*   **Manuscript Link:** Strictly implements **Algorithm 2: Binary Mix**.\n",
        "\n",
        "### **16. `scheduler_step` (Task 16 Orchestrator)**\n",
        "*   **Role:** Determines the proportion of data to augment based on training progress and overfitting signals.\n",
        "*   **Inputs:** `epoch`, `tau`, `current_es`, `last_es`.\n",
        "*   **Process:** Calculates the rate penalty based on early stopping counters. Computes $\\alpha$ using a $\\tanh$ curriculum.\n",
        "*   **Outputs:** `alpha` (Float), `new_last_es` (Int).\n",
        "*   **Transformation:**\n",
        "    $$ \\alpha = \\min(\\tanh(E/\\tau) + 0.01, 1.0) \\times R_{penalty} $$\n",
        "*   **Manuscript Link:** Strictly implements **Algorithm 3: Proportion $\\alpha$ Scheduler**.\n",
        "\n",
        "### **17. `joint_training_orchestrator` (Task 17 Orchestrator)**\n",
        "*   **Role:** Manages the bi-level optimization loop between the Task Model and the Planner.\n",
        "*   **Inputs:** Models, DataLoaders, Config, Wrappers.\n",
        "*   **Process:**\n",
        "    1.  **Inner Loop:** Updates Task Model on augmented data (using `inner_loop_manipulation_wrapper`).\n",
        "    2.  **Outer Loop:** Updates Planner on validation data (using `outer_loop_step`).\n",
        "    3.  **Scheduler:** Updates $\\alpha$ each epoch.\n",
        "*   **Outputs:** Trained models, history.\n",
        "*   **Transformation:** Updates model weights $\\theta$ and $\\phi$ iteratively.\n",
        "*   **Manuscript Link:** Strictly implements **Algorithm 4: Joint Training Scheme**.\n",
        "\n",
        "### **18. `ModularTaskModel` (Task 18 Class)**\n",
        "*   **Role:** Defines the architectural interface required for the Planner.\n",
        "*   **Inputs:** None (Abstract Base Class).\n",
        "*   **Process:** Enforces the implementation of `extract_embedding` (returning the penultimate layer output) and `functional_forward` (for stateless evaluation).\n",
        "*   **Outputs:** N/A.\n",
        "*   **Transformation:** N/A.\n",
        "*   **Manuscript Link:** Implements the **Task Model** requirements described in **Section V-A**, specifically the separation of feature extraction $j(\\cdot)$ and prediction $k(\\cdot)$.\n",
        "\n",
        "### **19. `GRUForecaster` (Task 19 Class)**\n",
        "*   **Role:** A concrete Task Model using a GRU encoder.\n",
        "*   **Inputs:** Time-series window.\n",
        "*   **Process:** Passes input through GRU layers, extracts the last hidden state, and passes it through the modular head.\n",
        "*   **Outputs:** Prediction $\\hat{y}$.\n",
        "*   **Transformation:** $x \\to \\text{GRU}(x) \\to h \\to \\text{MLP}(h) \\to \\hat{y}$.\n",
        "*   **Manuscript Link:** One of the five task models evaluated in **Section V-B**.\n",
        "\n",
        "### **20. `LSTMForecaster` (Task 20 Class)**\n",
        "*   **Role:** A concrete Task Model using an LSTM encoder.\n",
        "*   **Inputs:** Time-series window.\n",
        "*   **Process:** Similar to GRU but using LSTM cells.\n",
        "*   **Outputs:** Prediction $\\hat{y}$.\n",
        "*   **Transformation:** $x \\to \\text{LSTM}(x) \\to h \\to \\text{MLP}(h) \\to \\hat{y}$.\n",
        "*   **Manuscript Link:** One of the five task models evaluated in **Section V-B**.\n",
        "\n",
        "### **21. `DLinearForecaster` (Task 21 Class)**\n",
        "*   **Role:** A concrete Task Model using linear decomposition.\n",
        "*   **Inputs:** Time-series window.\n",
        "*   **Process:** Decomposes input into Trend and Seasonal components. Applies linear layers to each. Sums them to form the representation.\n",
        "*   **Outputs:** Prediction $\\hat{y}$.\n",
        "*   **Transformation:** $x \\to (x_{trend}, x_{seas}) \\to W_1 x_{trend} + W_2 x_{seas} \\to \\hat{y}$.\n",
        "*   **Manuscript Link:** One of the five task models evaluated in **Section V-B**.\n",
        "\n",
        "### **22. `TCNForecaster` (Task 22 Class)**\n",
        "*   **Role:** A concrete Task Model using Temporal Convolutional Networks.\n",
        "*   **Inputs:** Time-series window.\n",
        "*   **Process:** Applies dilated causal convolutions. Extracts the output at the last time step.\n",
        "*   **Outputs:** Prediction $\\hat{y}$.\n",
        "*   **Transformation:** $x \\to \\text{DilatedConv}(x) \\to h \\to \\text{MLP}(h) \\to \\hat{y}$.\n",
        "*   **Manuscript Link:** One of the five task models evaluated in **Section V-B**.\n",
        "\n",
        "### **23. `TransformerForecaster` (Task 23 Class)**\n",
        "*   **Role:** A concrete Task Model using a Transformer Encoder.\n",
        "*   **Inputs:** Time-series window.\n",
        "*   **Process:** Applies positional encoding and self-attention layers.\n",
        "*   **Outputs:** Prediction $\\hat{y}$.\n",
        "*   **Transformation:** $x \\to \\text{SelfAttn}(x + PE) \\to h \\to \\text{MLP}(h) \\to \\hat{y}$.\n",
        "*   **Manuscript Link:** One of the five task models evaluated in **Section V-B**.\n",
        "\n",
        "### **24. `Planner` (Task 24 Class)**\n",
        "*   **Role:** The meta-learner that generates the augmentation policy.\n",
        "*   **Inputs:** `model_embedding` ($h$), `x_raw` (Data Window).\n",
        "*   **Process:**\n",
        "    1.  Computes data statistics (Mean, Volatility, Skewness, etc.).\n",
        "    2.  Concatenates statistics with the model embedding.\n",
        "    3.  Passes the fused state through a Transformer Encoder.\n",
        "    4.  Outputs policy parameters via linear heads.\n",
        "*   **Outputs:** `p_matrix` (Probabilities), `lambda_matrix` (Strengths).\n",
        "*   **Transformation:** $(h, x) \\to \\pi_\\phi(p, \\lambda)$.\n",
        "*   **Manuscript Link:** Implements the **Curriculum Planner** described in **Section IV-C**.\n",
        "\n",
        "### **25. `RiskAwareLoss` (Task 25 Class)**\n",
        "*   **Role:** A loss function that penalizes volatility in performance.\n",
        "*   **Inputs:** Predictions, Targets.\n",
        "*   **Process:** Computes the mean and standard deviation of the element-wise loss.\n",
        "*   **Outputs:** Scalar loss.\n",
        "*   **Transformation:**\n",
        "    $$ \\mathcal{L} = \\mathbb{E}[\\text{loss}] + \\gamma \\times \\sigma(\\text{loss}) $$\n",
        "*   **Manuscript Link:** Implements **Equation (15)**.\n",
        "\n",
        "### **26. `bi_level_outer_update` (Task 26 Orchestrator)**\n",
        "*   **Role:** Performs the meta-update for the Planner.\n",
        "*   **Inputs:** Models, Optimizers, Batches, Policy.\n",
        "*   **Process:**\n",
        "    1.  Generates a weighted mixture of augmented data (using STE).\n",
        "    2.  Performs a \"lookahead\" update on the Task Model ($\\theta \\to \\theta'$).\n",
        "    3.  Evaluates $\\theta'$ on validation data.\n",
        "    4.  Backpropagates the validation loss to the Planner parameters $\\phi$.\n",
        "*   **Outputs:** Validation loss.\n",
        "*   **Transformation:** Updates $\\phi$ to minimize $\\mathcal{L}_{val}(\\theta')$.\n",
        "*   **Manuscript Link:** Implements the outer loop of **Equation (13)** and the update rule in **Equation (18)**.\n",
        "\n",
        "### **27. `run_full_training_pipeline` (Task 27 Orchestrator)**\n",
        "*   **Role:** Orchestrates the training of all forecasting models.\n",
        "*   **Inputs:** Tensor data, Config, Registries.\n",
        "*   **Process:** Iterates through each model type (GRU, LSTM, etc.), instantiates the model and planner, and executes the `joint_training_orchestrator`.\n",
        "*   **Outputs:** Dictionary of results (metrics, history, state dicts).\n",
        "*   **Transformation:** Trains models and records performance.\n",
        "*   **Manuscript Link:** Executes the experiments described in **Section V-B**.\n",
        "\n",
        "### **28. `TradingEnvironment` (Task 28 Class)**\n",
        "*   **Role:** Simulates the trading environment for RL agents.\n",
        "*   **Inputs:** Data, Prices, Returns.\n",
        "*   **Process:** Executes actions (Buy/Sell/Hold), updates portfolio value accounting for transaction costs, and computes rewards.\n",
        "*   **Outputs:** Next state, Reward, Done flag.\n",
        "*   **Transformation:**\n",
        "    $$ r_t = p_{t-1} r_t^{\\text{mkt}} - c |\\Delta p_t| $$\n",
        "*   **Manuscript Link:** Implements the **MDP** defined in **Section III-A**.\n",
        "\n",
        "### **29. `DQNAgent` (Task 29 Class)**\n",
        "*   **Role:** A Value-based RL agent.\n",
        "*   **Inputs:** State window.\n",
        "*   **Process:** Estimates Q-values using a neural network. Selects actions via epsilon-greedy policy. Updates weights using Bellman error.\n",
        "*   **Outputs:** Action.\n",
        "*   **Transformation:** Updates $Q(s,a)$ to approximate $r + \\gamma \\max Q(s', a')$.\n",
        "*   **Manuscript Link:** Implements the **DQN** agent used in **Section V-A**.\n",
        "\n",
        "### **30. `PPOAgent` (Task 30 Class)**\n",
        "*   **Role:** A Policy-Gradient RL agent.\n",
        "*   **Inputs:** State window.\n",
        "*   **Process:** Estimates policy $\\pi(a|s)$ and value $V(s)$. Updates using Clipped Surrogate Objective and GAE.\n",
        "*   **Outputs:** Action, Value, Log-prob.\n",
        "*   **Transformation:** Optimizes the PPO objective function.\n",
        "*   **Manuscript Link:** Implements the **PPO** agent used in **Section V-A**.\n",
        "\n",
        "### **31. `run_rl_transfer_experiment` (Task 31 Orchestrator)**\n",
        "*   **Role:** Evaluates the transferability of the Planner to RL tasks.\n",
        "*   **Inputs:** Planner artifact, Real Data.\n",
        "*   **Process:** Wraps the pre-trained Planner to work with RL states (disabling mix-up). Trains DQN and PPO agents using the transferred augmentation policy.\n",
        "*   **Outputs:** RL training results.\n",
        "*   **Transformation:** Applies the learned curriculum to the RL environment.\n",
        "*   **Manuscript Link:** Executes the **Transfer to Reinforcement Learning Trading** experiment in **Section V-B**.\n",
        "\n",
        "### **32. `evaluate_trading_performance` (Task 32 Orchestrator)**\n",
        "*   **Role:** Computes financial performance metrics.\n",
        "*   **Inputs:** Portfolio values.\n",
        "*   **Process:** Calculates Total Return and Sharpe Ratio.\n",
        "*   **Outputs:** Metrics dictionary.\n",
        "*   **Transformation:**\n",
        "    $$ \\text{TR} = \\frac{P_T - P_0}{P_0}, \\quad \\text{SR} = \\frac{\\mathbb{E}[r]}{\\sigma(r)} $$\n",
        "*   **Manuscript Link:** Implements **Equation (19)** and **Equation (20)**.\n",
        "\n",
        "### **33. `compute_distributional_shift_metrics` (Task 33 Orchestrator)**\n",
        "*   **Role:** Quantifies concept drift between datasets.\n",
        "*   **Inputs:** Train/Test/Val data.\n",
        "*   **Process:** Computes PSI, K-S Statistic, and MMD.\n",
        "*   **Outputs:** Metrics dictionary.\n",
        "*   **Transformation:** Calculates statistical distances between distributions.\n",
        "*   **Manuscript Link:** Implements **Equations (9), (10), and (11)**.\n",
        "\n",
        "### **34. `compute_stylized_facts` (Task 34 Orchestrator)**\n",
        "*   **Role:** Verifies that synthetic data preserves financial properties.\n",
        "*   **Inputs:** Real Returns, Synthetic Returns.\n",
        "*   **Process:** Computes ACF of returns, ACF of absolute returns, and Leverage Effect correlation. Calculates error between real and synthetic stats.\n",
        "*   **Outputs:** Error metrics and stats.\n",
        "*   **Transformation:** Calculates correlations and autocorrelations.\n",
        "*   **Manuscript Link:** Implements **Equations (21), (22), and (23)**.\n",
        "\n",
        "### **35. `run_drift_visualization` (Task 35 Orchestrator)**\n",
        "*   **Role:** Visualizes the data distribution using t-SNE.\n",
        "*   **Inputs:** Train/Test data.\n",
        "*   **Process:** Computes t-SNE embeddings for $P(X)$ and $P(Y|X)$. Plots the results.\n",
        "*   **Outputs:** Paths to saved plots.\n",
        "*   **Transformation:** Dimensionality reduction $\\mathbb{R}^F \\to \\mathbb{R}^2$.\n",
        "*   **Manuscript Link:** Generates the visualizations shown in **Figure 1** and **Figure 7**.\n",
        "\n",
        "### **36. `run_pipeline_orchestrator` (Task 36 Orchestrator)**\n",
        "*   **Role:** The master controller for the entire system.\n",
        "*   **Inputs:** Raw Data, Universe, Config.\n",
        "*   **Process:** Sequentially executes all preceding tasks in the correct order, managing data flow and artifact persistence via the `RunContext`.\n",
        "*   **Outputs:** `RunContext` object containing all results.\n",
        "*   **Transformation:** Transforms raw data into a trained, evaluated, and audited adaptive dataflow system.\n",
        "*   **Manuscript Link:** Implements the **Overall Workflow** described in **Section IV-A** and **Figure 2**.\n",
        "\n",
        "<br><br>\n",
        "## **Usage Example**\n",
        "\n",
        "Below is an example which uses synthetic data to illustrate how to use the pipeline orchestrator callable accurately:\n",
        "\n",
        "```python\n",
        "# ==============================================================================\n",
        "# Example Usage: End-to-End Adaptive Dataflow Pipeline\n",
        "# ==============================================================================\n",
        "# This script demonstrates the professional instantiation and execution of the\n",
        "# \"History Is Not Enough\" research pipeline. It covers:\n",
        "# 1. Synthetic generation of high-fidelity financial data (US Stocks Schema).\n",
        "# 2. Loading the study configuration from a YAML file.\n",
        "# 3. Executing the orchestrator.\n",
        "# 4. Inspecting the resulting artifacts.\n",
        "# ==============================================================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import yaml  # Requires PyYAML\n",
        "import os\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Ensure the pipeline functions and essential Python modules are available in the namespace\n",
        "# (In a real script, these would be imported from the module)\n",
        "# from adaptive_dataflow import run_pipeline_orchestrator, RunContext\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Step 1: Synthetic Data Generation (Faker/Numpy)\n",
        "# ------------------------------------------------------------------------------\n",
        "# We generate a dataset mimicking the \"US_Stocks_Daily\" universe:\n",
        "# - 27 Tickers (DJIA subset)\n",
        "# - Daily frequency (business days)\n",
        "# - Range: 2000-01-01 to 2024-01-01\n",
        "# - Columns: Open, High, Low, Close, AdjClose, Volume + Technical Indicators\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "def generate_synthetic_financial_data(\n",
        "    start_date: str = \"2000-01-01\",\n",
        "    end_date: str = \"2024-01-01\",\n",
        "    num_tickers: int = 27,\n",
        "    seed: int = 42\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Generates a synthetic MultiIndex DataFrame adhering to the strict K-line\n",
        "    and schema constraints of the study.\n",
        "\n",
        "    This function simulates financial time-series data for a specified number of tickers\n",
        "    over a given date range. It ensures that the generated data respects the fundamental\n",
        "    K-line consistency constraint: L_t <= min(O_t, C_t) <= max(O_t, C_t) <= H_t.\n",
        "    It also generates dummy technical indicators as required by the study configuration.\n",
        "\n",
        "    Args:\n",
        "        start_date (str): The start date for the data generation in 'YYYY-MM-DD' format.\n",
        "                          Default is \"2000-01-01\".\n",
        "        end_date (str): The end date for the data generation in 'YYYY-MM-DD' format.\n",
        "                        Default is \"2024-01-01\".\n",
        "        num_tickers (int): The number of synthetic tickers to generate. Default is 27.\n",
        "        seed (int): The random seed for reproducibility. Default is 42.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A pandas DataFrame containing the synthetic financial data.\n",
        "                      The DataFrame has a MultiIndex with levels [\"date\", \"ticker\"] and\n",
        "                      columns [\"Open\", \"High\", \"Low\", \"Close\", \"AdjClose\", \"Volume\"]\n",
        "                      plus technical indicators.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If start_date is after end_date or num_tickers is not positive.\n",
        "    \"\"\"\n",
        "    # Validate inputs\n",
        "    if pd.Timestamp(start_date) >= pd.Timestamp(end_date):\n",
        "        raise ValueError(f\"start_date ({start_date}) must be before end_date ({end_date}).\")\n",
        "    if num_tickers <= 0:\n",
        "        raise ValueError(f\"num_tickers must be positive. Got {num_tickers}.\")\n",
        "\n",
        "    print(f\"Generating synthetic data for {num_tickers} tickers from {start_date} to {end_date}...\")\n",
        "    \n",
        "    # Set random seed for reproducibility\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # 1. Define Tickers and Date Range\n",
        "    # Generate ticker symbols\n",
        "    tickers = [f\"TICKER_{i:02d}\" for i in range(num_tickers)]\n",
        "    \n",
        "    # Generate business days range\n",
        "    dates = pd.date_range(start=start_date, end=end_date, freq=\"B\")\n",
        "    n_dates = len(dates)\n",
        "    \n",
        "    dfs = []\n",
        "    \n",
        "    for ticker in tickers:\n",
        "        # 2. Generate Random Walk for Price Dynamics\n",
        "        # Geometric Brownian Motion approximation parameters\n",
        "        mu = 0.0005  # Daily drift\n",
        "        sigma = 0.02 # Daily volatility\n",
        "        \n",
        "        # Generate daily returns\n",
        "        returns = np.random.normal(loc=mu, scale=sigma, size=n_dates)\n",
        "        \n",
        "        # Calculate price path starting at 100\n",
        "        price_path = 100.0 * np.cumprod(1 + returns)\n",
        "        \n",
        "        # 3. Construct OHLCV ensuring K-Line Consistency\n",
        "        # Equation: L_t <= min(O_t, C_t) <= max(O_t, C_t) <= H_t\n",
        "        \n",
        "        # Open: Previous Close (with slight gap noise)\n",
        "        open_prices = price_path * np.random.uniform(0.995, 1.005, size=n_dates)\n",
        "        \n",
        "        # Close: The random walk path\n",
        "        close_prices = price_path\n",
        "        \n",
        "        # High: Max(Open, Close) + positive noise\n",
        "        # Ensures High is greater than or equal to the maximum of Open and Close\n",
        "        high_prices = np.maximum(open_prices, close_prices) * np.random.uniform(1.001, 1.02, size=n_dates)\n",
        "        \n",
        "        # Low: Min(Open, Close) - positive noise\n",
        "        # Ensures Low is less than or equal to the minimum of Open and Close\n",
        "        low_prices = np.minimum(open_prices, close_prices) * np.random.uniform(0.98, 0.999, size=n_dates)\n",
        "        \n",
        "        # AdjClose: Same as Close for simplicity (or add dividend drop logic)\n",
        "        adj_close = close_prices\n",
        "        \n",
        "        # Volume: Log-normal distribution to simulate trading volume\n",
        "        volume = np.random.lognormal(mean=16, sigma=0.5, size=n_dates).astype(int)\n",
        "        \n",
        "        # 4. Generate Technical Indicators (Required by Schema)\n",
        "        # We generate dummy columns matching the config requirements\n",
        "        # (RSI, MACD, etc. are just float features for the model)\n",
        "        tech_indicators = {\n",
        "            \"RSI_14\": np.random.uniform(0, 100, size=n_dates),\n",
        "            \"MACD\": np.random.normal(0, 1, size=n_dates),\n",
        "            \"MACD_Signal\": np.random.normal(0, 1, size=n_dates),\n",
        "            \"ATR_14\": np.random.uniform(0.5, 5.0, size=n_dates),\n",
        "            \"CCI_14\": np.random.uniform(-200, 200, size=n_dates),\n",
        "            \"MOM_10\": np.random.normal(0, 2, size=n_dates),\n",
        "            \"ROC_10\": np.random.normal(0, 0.05, size=n_dates)\n",
        "        }\n",
        "        \n",
        "        # 5. Assemble DataFrame for the current ticker\n",
        "        data = {\n",
        "            \"Open\": open_prices,\n",
        "            \"High\": high_prices,\n",
        "            \"Low\": low_prices,\n",
        "            \"Close\": close_prices,\n",
        "            \"AdjClose\": adj_close,\n",
        "            \"Volume\": volume,\n",
        "            **tech_indicators\n",
        "        }\n",
        "        \n",
        "        df_ticker = pd.DataFrame(data, index=dates)\n",
        "        df_ticker[\"ticker\"] = ticker\n",
        "        dfs.append(df_ticker)\n",
        "        \n",
        "    # 6. Concatenate and Set MultiIndex\n",
        "    # Combine all ticker DataFrames into one\n",
        "    df_raw = pd.concat(dfs)\n",
        "    \n",
        "    # Reset index to make 'date' a column, then set MultiIndex [\"date\", \"ticker\"]\n",
        "    df_raw = df_raw.reset_index().rename(columns={\"index\": \"date\"})\n",
        "    df_raw = df_raw.set_index([\"date\", \"ticker\"]).sort_index()\n",
        "    \n",
        "    # 7. Final Integrity Check (Task 3 Logic)\n",
        "    # Verify K-line consistency across the entire DataFrame\n",
        "    if not (df_raw[\"Low\"] <= df_raw[[\"Open\", \"Close\"]].min(axis=1)).all():\n",
        "        raise ValueError(\"Generated data violates Low <= min(Open, Close) constraint.\")\n",
        "    if not (df_raw[\"High\"] >= df_raw[[\"Open\", \"Close\"]].max(axis=1)).all():\n",
        "        raise ValueError(\"Generated data violates High >= max(Open, Close) constraint.\")\n",
        "    \n",
        "    print(f\"Data generated successfully. Shape: {df_raw.shape}\")\n",
        "    return df_raw\n",
        "\n",
        "# Generate the data\n",
        "df_raw = generate_synthetic_financial_data()\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Step 2: Load Configuration\n",
        "# ------------------------------------------------------------------------------\n",
        "# We assume 'config.yaml' exists in the working directory.\n",
        "# This file contains the 'STUDY_CONFIG' structure defined previously.\n",
        "# ------------------------------------------------------------------------------\n",
        "\n",
        "config_path = \"config.yaml\"\n",
        "\n",
        "if not os.path.exists(config_path):\n",
        "    # Fallback for demonstration if file is missing in this specific env\n",
        "    # In a real run, this block would raise FileNotFoundError\n",
        "    print(f\"Warning: {config_path} not found. Please ensure the YAML file is present.\")\n",
        "    # For the sake of the example running, we would normally stop here.\n",
        "else:\n",
        "    print(f\"Loading configuration from {config_path}...\")\n",
        "    with open(config_path, \"r\") as f:\n",
        "        study_config = yaml.safe_load(f)\n",
        "\n",
        "    # --------------------------------------------------------------------------\n",
        "    # Step 3: Execute the Pipeline Orchestrator\n",
        "    # --------------------------------------------------------------------------\n",
        "    # We pass the raw data, the universe identifier, and the loaded config.\n",
        "    # The orchestrator handles validation, cleansing, training, and evaluation.\n",
        "    # --------------------------------------------------------------------------\n",
        "    \n",
        "    universe_id = \"US_Stocks_Daily\"\n",
        "    output_directory = \"./experiment_artifacts\"\n",
        "    \n",
        "    print(\"Initializing Pipeline Orchestrator...\")\n",
        "    \n",
        "    try:\n",
        "        run_context = run_pipeline_orchestrator(\n",
        "            df_raw=df_raw,\n",
        "            universe=universe_id,\n",
        "            study_config=study_config,\n",
        "            output_dir=output_directory\n",
        "        )\n",
        "        \n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"PIPELINE EXECUTION SUCCESSFUL\")\n",
        "        print(\"=\"*50)\n",
        "        \n",
        "        # ----------------------------------------------------------------------\n",
        "        # Step 4: Inspect Artifacts\n",
        "        # ----------------------------------------------------------------------\n",
        "        # The RunContext object holds all results. We can inspect them programmatically.\n",
        "        \n",
        "        # 1. Check Forecasting Metrics\n",
        "        if run_context.training_results:\n",
        "            print(\"\\nForecasting Performance (Test Set):\")\n",
        "            for model_name, res in run_context.training_results.items():\n",
        "                metrics = res[\"metrics\"]\n",
        "                print(f\"  {model_name}: MSE={metrics['MSE']:.6f}, MAE={metrics['MAE']:.6f}\")\n",
        "        \n",
        "        # 2. Check RL Transfer Results\n",
        "        if run_context.rl_results:\n",
        "            print(\"\\nRL Transfer Performance:\")\n",
        "            for agent, res in run_context.rl_results.items():\n",
        "                final_val = res[\"final_value\"]\n",
        "                print(f\"  {agent}: Final Portfolio Value = ${final_val:,.2f}\")\n",
        "        \n",
        "        # 3. Check Drift Metrics\n",
        "        if run_context.drift_metrics:\n",
        "            print(\"\\nDistributional Drift Metrics (Train vs Test):\")\n",
        "            for metric, value in run_context.drift_metrics.items():\n",
        "                print(f\"  {metric}: {value:.4f}\")\n",
        "                \n",
        "        # 4. Check Stylized Facts\n",
        "        if run_context.stylized_facts:\n",
        "            print(\"\\nStylized Facts Fidelity (Real vs Synthetic):\")\n",
        "            err = run_context.stylized_facts['ACF_Returns_Error']\n",
        "            print(f\"  ACF Returns MAE: {err:.6f}\")\n",
        "            \n",
        "        print(f\"\\nFull artifacts saved to: {os.path.abspath(output_directory)}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"\\nPipeline Failed: {e}\")\n",
        "        # In production, we would log the full traceback here\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "```\n",
        "\n",
        "<br>\n",
        "\n",
        "## **Implementation of Callables**"
      ],
      "metadata": {
        "id": "RtiffEoeyJEa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1 — Validate `df_raw` schema presence, data types, and index integrity\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 1: Validate df_raw schema presence, data types, and index integrity\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 1, Step 1: Validate MultiIndex structure and data types\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_multiindex_and_dtypes(\n",
        "    df_raw: pd.DataFrame,\n",
        "    universe: str,\n",
        "    study_config: Dict[str, Any]\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Validates the structural integrity of the input DataFrame's MultiIndex and column data types.\n",
        "\n",
        "    Enforces the schema contract:\n",
        "    1. Index must be a MultiIndex with levels [\"date\", \"ticker\"].\n",
        "    2. Level \"date\" must be datetime64[ns].\n",
        "    3. Level \"ticker\" must be object or Categorical.\n",
        "    4. Required columns (Open, High, Low, Close, Volume) must exist and be numeric.\n",
        "    5. AdjClose must exist for US Stocks; optional for Crypto but numeric if present.\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "        universe (str): The universe identifier (e.g., \"US_Stocks_Daily\").\n",
        "        study_config (Dict[str, Any]): The master configuration dictionary.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If index structure, names, or required columns are missing/incorrect.\n",
        "        TypeError: If data types do not match requirements.\n",
        "    \"\"\"\n",
        "    # 1. Validate Index Type and Levels\n",
        "    # Rationale: The system relies on (date, ticker) alignment for all downstream tensor operations.\n",
        "    if not isinstance(df_raw.index, pd.MultiIndex):\n",
        "        raise ValueError(\"df_raw must have a pandas MultiIndex.\")\n",
        "\n",
        "    if len(df_raw.index.levels) != 2:\n",
        "        raise ValueError(f\"df_raw index must have exactly 2 levels. Found {len(df_raw.index.levels)}.\")\n",
        "\n",
        "    # Check level names order\n",
        "    expected_names = [\"date\", \"ticker\"]\n",
        "    if df_raw.index.names != expected_names:\n",
        "        raise ValueError(f\"df_raw index names must be {expected_names}. Found {df_raw.index.names}.\")\n",
        "\n",
        "    # 2. Validate Index Dtypes\n",
        "    # Level 0: date -> datetime64[ns]\n",
        "    date_level_dtype = df_raw.index.get_level_values(0).dtype\n",
        "    if not pd.api.types.is_datetime64_ns_dtype(date_level_dtype):\n",
        "        raise TypeError(f\"Index level 'date' must be datetime64[ns]. Found {date_level_dtype}.\")\n",
        "\n",
        "    # Level 1: ticker -> object or categorical\n",
        "    ticker_level_dtype = df_raw.index.get_level_values(1).dtype\n",
        "    if not (pd.api.types.is_object_dtype(ticker_level_dtype) or isinstance(ticker_level_dtype, pd.CategoricalDtype)):\n",
        "        raise TypeError(f\"Index level 'ticker' must be object or Categorical. Found {ticker_level_dtype}.\")\n",
        "\n",
        "    # 3. Validate Required Columns\n",
        "    # Base required columns for all universes\n",
        "    required_columns = [\"Open\", \"High\", \"Low\", \"Close\", \"Volume\"]\n",
        "\n",
        "    # Conditional requirement for AdjClose\n",
        "    # Constraint: For US stocks, AdjClose must be present.\n",
        "    if universe == \"US_Stocks_Daily\":\n",
        "        required_columns.append(\"AdjClose\")\n",
        "\n",
        "    missing_cols = [col for col in required_columns if col not in df_raw.columns]\n",
        "    if missing_cols:\n",
        "        raise ValueError(f\"Missing required columns for universe '{universe}': {missing_cols}\")\n",
        "\n",
        "    # 4. Validate Column Dtypes (Numeric)\n",
        "    # All price/volume columns must be numeric.\n",
        "    # Note: AdjClose is checked if it exists (required for Stocks, optional for Crypto).\n",
        "    cols_to_check = required_columns.copy()\n",
        "    if universe == \"Crypto_Hourly\" and \"AdjClose\" in df_raw.columns:\n",
        "        cols_to_check.append(\"AdjClose\")\n",
        "\n",
        "    for col in cols_to_check:\n",
        "        if not pd.api.types.is_numeric_dtype(df_raw[col]):\n",
        "            raise TypeError(f\"Column '{col}' must be numeric. Found {df_raw[col].dtype}.\")\n",
        "\n",
        "    # 5. Validate Technical Indicators\n",
        "    # The config specifies 'technical_indicators' as a required key, but the exact list might be REQUIRED_FROM_CODE.\n",
        "    # We check if the columns specified in config exist in dataframe, if the list is resolved.\n",
        "    tech_indicators_config = study_config[\"data_schemas\"][universe][\"columns\"][\"technical_indicators\"]\n",
        "    # If it's a string placeholder, we skip specific column validation but log a warning.\n",
        "    if isinstance(tech_indicators_config, dict) and isinstance(tech_indicators_config.get(\"constraint\"), str) and \"REQUIRED_FROM_CODE\" in tech_indicators_config[\"constraint\"]:\n",
        "        logger.warning(f\"Technical indicator list is 'REQUIRED_FROM_CODE'. Skipping specific column existence check for indicators.\")\n",
        "    elif isinstance(tech_indicators_config, list):\n",
        "        # If it's a list of strings (resolved), validate them.\n",
        "        missing_indicators = [ti for ti in tech_indicators_config if ti not in df_raw.columns]\n",
        "        if missing_indicators:\n",
        "            raise ValueError(f\"Missing required technical indicator columns: {missing_indicators}\")\n",
        "\n",
        "    logger.info(\"Task 1 Step 1: Schema validation passed.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 1, Step 2: Validate temporal monotonicity within each ticker\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_temporal_monotonicity(df_raw: pd.DataFrame) -> Dict[str, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Validates that the 'date' index level is strictly monotonic increasing within each 'ticker' group.\n",
        "    Also detects duplicate (date, ticker) keys.\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe with MultiIndex (date, ticker).\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Dict[str, Any]]: A summary dictionary keyed by ticker containing date ranges and row counts.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If duplicate keys are found or if dates are not strictly increasing for any ticker.\n",
        "    \"\"\"\n",
        "    # 1. Check for Duplicate Index Keys\n",
        "    # Duplicates violate strict monotonicity (t_i < t_{i+1} cannot hold if t_i == t_{i+1}).\n",
        "    if df_raw.index.has_duplicates:\n",
        "        duplicate_count = df_raw.index.duplicated().sum()\n",
        "        # Extract sample duplicates for logging\n",
        "        duplicates = df_raw[df_raw.index.duplicated()].head()\n",
        "        raise ValueError(f\"df_raw contains {duplicate_count} duplicate index keys. Sample:\\n{duplicates}\")\n",
        "\n",
        "    # 2. Check Monotonicity per Ticker\n",
        "    # Strategy: Group by ticker and check the 'date' level values.\n",
        "    # Note: df_raw might not be sorted by ticker primarily.\n",
        "\n",
        "    # Get unique tickers\n",
        "    tickers = df_raw.index.get_level_values(\"ticker\").unique()\n",
        "\n",
        "    ticker_stats = {}\n",
        "\n",
        "    for ticker in tickers:\n",
        "        # Slicing via cross-section or boolean mask.\n",
        "        # Boolean mask is robust if index is unsorted.\n",
        "        # Ideally, we use xs if sorted, but we can't assume sort yet.\n",
        "        # Using boolean indexing on the index level is safe.\n",
        "        mask = df_raw.index.get_level_values(\"ticker\") == ticker\n",
        "\n",
        "        # Extract dates for this ticker\n",
        "        dates = df_raw.index.get_level_values(\"date\")[mask]\n",
        "\n",
        "        # Check strict monotonicity\n",
        "        # is_monotonic_increasing allows duplicates (t_i <= t_{i+1}), but we already checked for duplicates globally.\n",
        "        # If no duplicates exist, is_monotonic_increasing implies strict increasing.\n",
        "        if not dates.is_monotonic_increasing:\n",
        "            raise ValueError(f\"Dates for ticker '{ticker}' are not strictly monotonic increasing.\")\n",
        "\n",
        "        # Log stats\n",
        "        ticker_stats[ticker] = {\n",
        "            \"min_date\": dates.min(),\n",
        "            \"max_date\": dates.max(),\n",
        "            \"count\": len(dates)\n",
        "        }\n",
        "\n",
        "    logger.info(f\"Task 1 Step 2: Temporal monotonicity validated for {len(tickers)} tickers.\")\n",
        "    return ticker_stats\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 1, Step 3: Validate universe membership against STUDY_CONFIG\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_universe_membership(\n",
        "    df_raw: pd.DataFrame,\n",
        "    universe: str,\n",
        "    study_config: Dict[str, Any]\n",
        ") -> None:\n",
        "    \"\"\"\n",
        "    Validates that the tickers present in df_raw match the expected universe definition in STUDY_CONFIG.\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "        universe (str): The universe identifier.\n",
        "        study_config (Dict[str, Any]): The master configuration dictionary.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the observed ticker set does not match the configuration requirements.\n",
        "    \"\"\"\n",
        "    # 1. Extract Observed Tickers\n",
        "    observed_tickers = set(df_raw.index.get_level_values(\"ticker\").unique())\n",
        "\n",
        "    # 2. Extract Expected Tickers from Config\n",
        "    schema_config = study_config[\"data_schemas\"][universe]\n",
        "    required_tickers_config = schema_config[\"required_tickers\"]\n",
        "\n",
        "    # 3. Validate\n",
        "    if isinstance(required_tickers_config, str) and \"REQUIRED_FROM_CODE\" in required_tickers_config:\n",
        "        # Structural replication mode: We cannot validate exact membership, but we log the observed set.\n",
        "        logger.warning(f\"Universe '{universe}' required_tickers is 'REQUIRED_FROM_CODE'. Skipping exact set equality check.\")\n",
        "        logger.info(f\"Observed tickers ({len(observed_tickers)}): {sorted(list(observed_tickers))}\")\n",
        "    elif isinstance(required_tickers_config, list):\n",
        "        # Exact replication mode: Enforce set equality.\n",
        "        expected_tickers = set(required_tickers_config)\n",
        "\n",
        "        missing = expected_tickers - observed_tickers\n",
        "        extra = observed_tickers - expected_tickers\n",
        "\n",
        "        if missing or extra:\n",
        "            error_msg = f\"Ticker set mismatch for universe '{universe}'.\\n\"\n",
        "            if missing:\n",
        "                error_msg += f\"Missing expected tickers: {missing}\\n\"\n",
        "            if extra:\n",
        "                error_msg += f\"Found unexpected tickers: {extra}\\n\"\n",
        "            raise ValueError(error_msg)\n",
        "\n",
        "        logger.info(f\"Task 1 Step 3: Ticker set matches configuration exactly ({len(expected_tickers)} tickers).\")\n",
        "    else:\n",
        "        raise ValueError(f\"Invalid configuration format for 'required_tickers' in universe '{universe}'.\")\n",
        "\n",
        "    # 4. Validate Date Range Coverage (Soft Check)\n",
        "    # We check if the data covers the config's start/end dates roughly.\n",
        "    # We don't fail hard here because individual tickers might start late/end early,\n",
        "    # but the global dataset should span the range.\n",
        "    config_start = pd.Timestamp(schema_config[\"start_date\"])\n",
        "    config_end = pd.Timestamp(schema_config[\"end_date\"])\n",
        "\n",
        "    global_min_date = df_raw.index.get_level_values(\"date\").min()\n",
        "    global_max_date = df_raw.index.get_level_values(\"date\").max()\n",
        "\n",
        "    if global_min_date > config_start:\n",
        "        logger.warning(f\"Data start date ({global_min_date}) is later than config start date ({config_start}).\")\n",
        "    if global_max_date < config_end:\n",
        "        logger.warning(f\"Data end date ({global_max_date}) is earlier than config end date ({config_end}).\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 1, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_raw_data_schema(\n",
        "    df_raw: pd.DataFrame,\n",
        "    universe: str,\n",
        "    study_config: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 1: Validates df_raw schema, types, index integrity, and universe membership.\n",
        "\n",
        "    This function executes the validation pipeline sequentially:\n",
        "    1. Structural validation (MultiIndex, Dtypes).\n",
        "    2. Temporal integrity (Monotonicity, Duplicates).\n",
        "    3. Universe membership (Ticker set matching).\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "        universe (str): The universe identifier (e.g., \"US_Stocks_Daily\").\n",
        "        study_config (Dict[str, Any]): The master configuration dictionary.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A metadata dictionary containing validation summaries (e.g., ticker stats).\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If any validation step fails.\n",
        "        TypeError: If data types are incorrect.\n",
        "    \"\"\"\n",
        "    logger.info(f\"Starting Task 1: Validating schema for universe '{universe}'...\")\n",
        "\n",
        "    # Step 1: Structure and Types\n",
        "    validate_multiindex_and_dtypes(df_raw, universe, study_config)\n",
        "\n",
        "    # Step 2: Temporal Integrity\n",
        "    # Returns stats per ticker which we can return as metadata\n",
        "    ticker_stats = validate_temporal_monotonicity(df_raw)\n",
        "\n",
        "    # Step 3: Universe Membership\n",
        "    validate_universe_membership(df_raw, universe, study_config)\n",
        "\n",
        "    logger.info(\"Task 1 completed successfully.\")\n",
        "\n",
        "    return {\n",
        "        \"validation_status\": \"passed\",\n",
        "        \"ticker_stats\": ticker_stats,\n",
        "        \"universe\": universe\n",
        "    }\n"
      ],
      "metadata": {
        "id": "GUL4VYWJyN5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2 — Validate STUDY_CONFIG internal consistency and flag unresolved parameters\n",
        "\n",
        "# ===================================================================================\n",
        "# Task 2: Validate STUDY_CONFIG internal consistency and flag unresolved parameters\n",
        "# ===================================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 2, Step 1: Validate all required keys exist in STUDY_CONFIG\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_config_schema_completeness(study_config: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Validates that the STUDY_CONFIG dictionary contains all top-level sections and\n",
        "    critical sub-sections required by the manuscript's algorithms.\n",
        "\n",
        "    This function enforces the structural contract of the configuration, ensuring\n",
        "    that downstream modules (Planner, Scheduler, RL) find their expected parameters.\n",
        "\n",
        "    Args:\n",
        "        study_config (Dict[str, Any]): The master configuration dictionary.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: If any required section or sub-key is missing.\n",
        "    \"\"\"\n",
        "    # Define the expected schema structure (subset of critical keys)\n",
        "    # We use a dictionary where keys are parent keys and values are lists of required subkeys.\n",
        "    # Empty list implies only the parent key is checked for existence.\n",
        "    required_structure = {\n",
        "        \"reproducibility\": [\"device\", \"random_seed\", \"log_provenance\"],\n",
        "        \"data_schemas\": [\"US_Stocks_Daily\", \"Crypto_Hourly\"],\n",
        "        \"preprocessing\": [\n",
        "            \"lookback_window\", \"target_type\", \"split_ratios\",\n",
        "            \"rolling_protocol\", \"leakage_control\", \"normalization\", \"alignment_policy\"\n",
        "        ],\n",
        "        \"econometrics\": [\"cointegration\"],\n",
        "        \"task_models\": [\"common\", \"GRU\", \"LSTM\", \"TCN\", \"Transformer\", \"DLinear\"],\n",
        "        \"planner\": [\"architecture\", \"input_dim\", \"learning_rate\", \"sharpe_loss_gamma\", \"state_features\"],\n",
        "        \"scheduler\": [\"rate_penalty_active\", \"tau\", \"early_stopping\"],\n",
        "        \"manipulation_module\": [\"kline_constraint\", \"operations\", \"mixup_target_sampling\", \"binary_mix\"],\n",
        "        \"baselines\": [\"Original\", \"RandAugment\", \"TrivialAugment\", \"AdaAug\", \"Ours\"],\n",
        "        \"evaluation\": [\"proximity_metrics\", \"forecasting_metrics\", \"trading_metrics\", \"discriminative_score\", \"stylized_facts\", \"tsne\"],\n",
        "        \"rl_environment\": [\"transaction_cost\", \"action_space\", \"valuation_price_field\", \"DQN\", \"PPO\"]\n",
        "    }\n",
        "\n",
        "    # 1. Validate Top-Level Keys\n",
        "    missing_top_level = [key for key in required_structure if key not in study_config]\n",
        "    if missing_top_level:\n",
        "        raise KeyError(f\"STUDY_CONFIG is missing top-level sections: {missing_top_level}\")\n",
        "\n",
        "    # 2. Validate Sub-Keys\n",
        "    for section, subkeys in required_structure.items():\n",
        "        if not subkeys:\n",
        "            continue\n",
        "\n",
        "        current_section = study_config[section]\n",
        "        if not isinstance(current_section, dict):\n",
        "            raise KeyError(f\"Section '{section}' must be a dictionary.\")\n",
        "\n",
        "        missing_subkeys = [k for k in subkeys if k not in current_section]\n",
        "        if missing_subkeys:\n",
        "            raise KeyError(f\"Section '{section}' is missing required keys: {missing_subkeys}\")\n",
        "\n",
        "    # 3. Validate Deeply Nested Critical Keys (Specific Algorithm Requirements)\n",
        "    # Algorithm 1 requires 'topk_candidates' in econometrics and manipulation_module\n",
        "    if \"topk_candidates\" not in study_config[\"econometrics\"][\"cointegration\"]:\n",
        "        raise KeyError(\"Missing 'topk_candidates' in econometrics.cointegration\")\n",
        "    if \"topk_candidates\" not in study_config[\"manipulation_module\"][\"mixup_target_sampling\"]:\n",
        "        raise KeyError(\"Missing 'topk_candidates' in manipulation_module.mixup_target_sampling\")\n",
        "\n",
        "    # Algorithm 3 requires 'tau' dictionary\n",
        "    if not isinstance(study_config[\"scheduler\"].get(\"tau\"), dict):\n",
        "        raise KeyError(\"scheduler.tau must be a dictionary mapping models to pacing parameters.\")\n",
        "\n",
        "    logger.info(\"Task 2 Step 1: Config schema completeness validated.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 2, Step 2: Identify and log all REQUIRED_FROM_CODE entries\n",
        "# ------------------------------------------------------------------------------\n",
        "def identify_unresolved_parameters(\n",
        "    config_node: Union[Dict, List, Any],\n",
        "    path: str = \"\"\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Recursively traverses the configuration to identify parameters marked as\n",
        "    'REQUIRED_FROM_CODE'.\n",
        "\n",
        "    These parameters represent values not specified in the manuscript excerpt\n",
        "    and must be resolved from the authors' code for exact replication.\n",
        "\n",
        "    Args:\n",
        "        config_node (Union[Dict, List, Any]): The current node in the config traversal.\n",
        "        path (str): The dot-notation path to the current node (e.g., \"preprocessing.normalization\").\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of paths where the value is 'REQUIRED_FROM_CODE'.\n",
        "    \"\"\"\n",
        "    unresolved_paths = []\n",
        "    sentinel = \"REQUIRED_FROM_CODE\"\n",
        "\n",
        "    if isinstance(config_node, dict):\n",
        "        for key, value in config_node.items():\n",
        "            current_path = f\"{path}.{key}\" if path else key\n",
        "            unresolved_paths.extend(identify_unresolved_parameters(value, current_path))\n",
        "\n",
        "    elif isinstance(config_node, list):\n",
        "        for idx, item in enumerate(config_node):\n",
        "            current_path = f\"{path}[{idx}]\"\n",
        "            unresolved_paths.extend(identify_unresolved_parameters(item, current_path))\n",
        "\n",
        "    elif isinstance(config_node, str):\n",
        "        if config_node == sentinel:\n",
        "            unresolved_paths.append(path)\n",
        "\n",
        "    return unresolved_paths\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 2, Step 3: Validate cross-references between config sections\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_config_consistency(study_config: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Validates internal consistency constraints between different sections of the configuration.\n",
        "\n",
        "    Enforces:\n",
        "    1. Algorithm 1 Consistency: Cointegration candidate count k must match in econometrics and manipulation module.\n",
        "    2. Scheduler Consistency: Every task model must have a defined tau parameter.\n",
        "    3. RL Consistency: Valuation price field must be non-empty.\n",
        "\n",
        "    Args:\n",
        "        study_config (Dict[str, Any]): The master configuration dictionary.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If any consistency check fails.\n",
        "    \"\"\"\n",
        "    # 1. Algorithm 1 Consistency\n",
        "    # The candidate set size 'k' is used both for computing p-values (econometrics)\n",
        "    # and for sampling targets (manipulation). They must be identical.\n",
        "    k_econometrics = study_config[\"econometrics\"][\"cointegration\"][\"topk_candidates\"]\n",
        "    k_manipulation = study_config[\"manipulation_module\"][\"mixup_target_sampling\"][\"topk_candidates\"]\n",
        "\n",
        "    # Note: If both are \"REQUIRED_FROM_CODE\", they are technically equal strings, which is valid at this stage.\n",
        "    if k_econometrics != k_manipulation:\n",
        "        raise ValueError(\n",
        "            f\"Inconsistent 'topk_candidates' for Algorithm 1.\\n\"\n",
        "            f\"Econometrics: {k_econometrics}\\n\"\n",
        "            f\"Manipulation: {k_manipulation}\\n\"\n",
        "            f\"These must be identical.\"\n",
        "        )\n",
        "\n",
        "    # 2. Scheduler Consistency\n",
        "    # Every model defined in task_models (except 'common') needs a pacing parameter tau in the scheduler.\n",
        "    defined_models = set(study_config[\"task_models\"].keys()) - {\"common\"}\n",
        "    scheduled_models = set(study_config[\"scheduler\"][\"tau\"].keys())\n",
        "\n",
        "    missing_schedules = defined_models - scheduled_models\n",
        "    if missing_schedules:\n",
        "        raise ValueError(f\"Missing scheduler 'tau' parameters for models: {missing_schedules}\")\n",
        "\n",
        "    # 3. RL Consistency\n",
        "    # Valuation field is critical for the RL environment.\n",
        "    val_field = study_config[\"rl_environment\"].get(\"valuation_price_field\")\n",
        "    if not val_field or not isinstance(val_field, str):\n",
        "        raise ValueError(\"rl_environment.valuation_price_field must be a valid string.\")\n",
        "\n",
        "    logger.info(\"Task 2 Step 3: Internal config consistency validated.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 2, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_study_config(study_config: Dict[str, Any]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 2: Validates the study configuration dictionary.\n",
        "\n",
        "    Executes:\n",
        "    1. Schema completeness check.\n",
        "    2. Unresolved parameter identification (\"REQUIRED_FROM_CODE\").\n",
        "    3. Internal consistency cross-checks.\n",
        "\n",
        "    Args:\n",
        "        study_config (Dict[str, Any]): The master configuration dictionary.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: A list of dot-notation paths for all parameters that remain 'REQUIRED_FROM_CODE'.\n",
        "                   If this list is non-empty, the run is in \"Structural Replication\" mode.\n",
        "\n",
        "    Raises:\n",
        "        KeyError: If schema validation fails.\n",
        "        ValueError: If consistency checks fail.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 2: Validating STUDY_CONFIG...\")\n",
        "\n",
        "    # Step 1: Schema Completeness\n",
        "    validate_config_schema_completeness(study_config)\n",
        "\n",
        "    # Step 2: Identify Unresolved Parameters\n",
        "    unresolved_params = identify_unresolved_parameters(study_config)\n",
        "\n",
        "    if unresolved_params:\n",
        "        logger.warning(f\"Found {len(unresolved_params)} parameters marked 'REQUIRED_FROM_CODE'.\")\n",
        "        logger.warning(\"Run is in 'Structural Replication' mode. Exact reproduction requires resolving these values.\")\n",
        "        # Log first 5 for context\n",
        "        for p in unresolved_params[:5]:\n",
        "            logger.debug(f\"Unresolved: {p}\")\n",
        "    else:\n",
        "        logger.info(\"All parameters resolved. Run is in 'Exact Replication' mode.\")\n",
        "\n",
        "    # Step 3: Consistency Checks\n",
        "    validate_config_consistency(study_config)\n",
        "\n",
        "    logger.info(\"Task 2 completed successfully.\")\n",
        "    return unresolved_params\n"
      ],
      "metadata": {
        "id": "2b8R9WKP0NjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3 — Validate K-line financial realism constraints and positivity\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 3: Validate K-line financial realism constraints and positivity\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 3, Step 1: Validate positivity constraints for all price columns\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_price_volume_positivity(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Validates strict positivity for price columns and non-negativity for volume.\n",
        "\n",
        "    Enforces:\n",
        "    1. Open, High, Low, Close > 0\n",
        "    2. AdjClose > 0 (if present)\n",
        "    3. Volume >= 0\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A subset of df_raw containing rows that violate these constraints.\n",
        "    \"\"\"\n",
        "    violations = []\n",
        "\n",
        "    # 1. Price Columns (> 0)\n",
        "    price_cols = [\"Open\", \"High\", \"Low\", \"Close\"]\n",
        "    if \"AdjClose\" in df_raw.columns:\n",
        "        price_cols.append(\"AdjClose\")\n",
        "\n",
        "    for col in price_cols:\n",
        "        # Mask: True if violation (<= 0)\n",
        "        mask = df_raw[col] <= 0\n",
        "        if mask.any():\n",
        "            v_rows = df_raw[mask].copy()\n",
        "            v_rows[\"violation_type\"] = f\"{col}_non_positive\"\n",
        "            violations.append(v_rows)\n",
        "\n",
        "    # 2. Volume Column (>= 0)\n",
        "    if \"Volume\" in df_raw.columns:\n",
        "        mask_vol = df_raw[\"Volume\"] < 0\n",
        "        if mask_vol.any():\n",
        "            v_rows = df_raw[mask_vol].copy()\n",
        "            v_rows[\"violation_type\"] = \"Volume_negative\"\n",
        "            violations.append(v_rows)\n",
        "\n",
        "    if violations:\n",
        "        all_violations = pd.concat(violations)\n",
        "        logger.warning(f\"Task 3 Step 1: Found {len(all_violations)} rows violating positivity constraints.\")\n",
        "        return all_violations\n",
        "    else:\n",
        "        logger.info(\"Task 3 Step 1: All positivity constraints satisfied.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 3, Step 2: Validate the K-line ordering constraint\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_kline_consistency(df_raw: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Validates the K-line consistency constraint:\n",
        "    L_t <= min(O_t, C_t) <= max(O_t, C_t) <= H_t\n",
        "\n",
        "    This ensures that the High is the session maximum and Low is the session minimum.\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A subset of df_raw containing rows that violate the K-line constraint.\n",
        "    \"\"\"\n",
        "    # 1. Compute Min/Max of Open and Close\n",
        "    # We use numpy element-wise operations for speed\n",
        "    open_vals = df_raw[\"Open\"].values\n",
        "    close_vals = df_raw[\"Close\"].values\n",
        "    high_vals = df_raw[\"High\"].values\n",
        "    low_vals = df_raw[\"Low\"].values\n",
        "\n",
        "    min_oc = np.minimum(open_vals, close_vals)\n",
        "    max_oc = np.maximum(open_vals, close_vals)\n",
        "\n",
        "    # 2. Check Constraints\n",
        "    # Violation 1: Low > min(Open, Close)\n",
        "    # Violation 2: High < max(Open, Close)\n",
        "    # Violation 3: Low > High (implied by above, but explicit check covers bad data)\n",
        "    # We want rows where constraint fails.\n",
        "    # Constraint: Low <= min_oc AND High >= max_oc\n",
        "    # Violation: Low > min_oc OR High < max_oc\n",
        "    violation_mask = (low_vals > min_oc) | (high_vals < max_oc)\n",
        "\n",
        "    if np.any(violation_mask):\n",
        "        v_rows = df_raw[violation_mask].copy()\n",
        "        v_rows[\"violation_type\"] = \"KLine_inconsistency\"\n",
        "\n",
        "        # Add detail on specific failure\n",
        "        v_rows[\"Low_gt_minOC\"] = v_rows[\"Low\"] > np.minimum(v_rows[\"Open\"], v_rows[\"Close\"])\n",
        "        v_rows[\"High_lt_maxOC\"] = v_rows[\"High\"] < np.maximum(v_rows[\"Open\"], v_rows[\"Close\"])\n",
        "\n",
        "        logger.warning(f\"Task 3 Step 2: Found {len(v_rows)} rows violating K-line consistency.\")\n",
        "        return v_rows\n",
        "    else:\n",
        "        logger.info(\"Task 3 Step 2: K-line consistency validated.\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 3, Step 3: Validate frequency expectations per universe\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_frequency_integrity(\n",
        "    df_raw: pd.DataFrame,\n",
        "    universe: str\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Validates temporal frequency expectations.\n",
        "\n",
        "    - US_Stocks_Daily: Checks are lenient (gaps allowed for weekends/holidays).\n",
        "    - Crypto_Hourly: Checks are strict (expect 1H delta). Gaps are logged.\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "        universe (str): The universe identifier.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict[str, Any]]: A list of gap events found (if any).\n",
        "    \"\"\"\n",
        "    gaps = []\n",
        "\n",
        "    if universe == \"Crypto_Hourly\":\n",
        "        # Group by ticker to check time deltas within each series\n",
        "        for ticker, group in df_raw.groupby(level=\"ticker\"):\n",
        "            # Extract dates (level 0)\n",
        "            dates = group.index.get_level_values(\"date\").sort_values()\n",
        "\n",
        "            # Calculate diff\n",
        "            diffs = dates.to_series().diff().dropna()\n",
        "\n",
        "            # Expected delta: 1 hour\n",
        "            expected_delta = pd.Timedelta(hours=1)\n",
        "\n",
        "            # Find gaps (diff > expected)\n",
        "            # We allow a small tolerance for floating point seconds, though datetime64[ns] is exact.\n",
        "            gap_mask = diffs > expected_delta\n",
        "\n",
        "            if gap_mask.any():\n",
        "                gap_indices = diffs[gap_mask].index\n",
        "                for idx in gap_indices:\n",
        "                    # idx is the timestamp *after* the gap\n",
        "                    # previous timestamp is idx - diff\n",
        "                    gap_size = diffs[idx]\n",
        "                    prev_ts = idx - gap_size\n",
        "\n",
        "                    gaps.append({\n",
        "                        \"ticker\": ticker,\n",
        "                        \"gap_start\": prev_ts,\n",
        "                        \"gap_end\": idx,\n",
        "                        \"gap_duration\": gap_size,\n",
        "                        \"expected\": expected_delta\n",
        "                    })\n",
        "\n",
        "        if gaps:\n",
        "            logger.warning(f\"Task 3 Step 3: Found {len(gaps)} frequency gaps in Crypto_Hourly universe.\")\n",
        "            # Per instructions: \"raise a 'policy required' flag\" -> We log heavily.\n",
        "            # The prompt implies we detect and log here; Task 4 handles cleansing/policy.\n",
        "            for gap in gaps[:5]: # Log first 5\n",
        "                logger.warning(f\"Gap detected: {gap}\")\n",
        "        else:\n",
        "            logger.info(\"Task 3 Step 3: Crypto frequency integrity validated (no gaps).\")\n",
        "\n",
        "    elif universe == \"US_Stocks_Daily\":\n",
        "        logger.info(\"Task 3 Step 3: US Stocks frequency check skipped (gaps expected).\")\n",
        "\n",
        "    return gaps\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 3, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_financial_realism(\n",
        "    df_raw: pd.DataFrame,\n",
        "    universe: str\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 3: Validates financial realism constraints.\n",
        "\n",
        "    Executes:\n",
        "    1. Positivity check (Prices > 0, Volume >= 0).\n",
        "    2. K-Line consistency check (Low <= min(O,C) <= max(O,C) <= High).\n",
        "    3. Frequency integrity check (Crypto gaps).\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "        universe (str): The universe identifier.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A report containing violation DataFrames and gap lists.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 3: Validating financial realism...\")\n",
        "\n",
        "    # Step 1: Positivity\n",
        "    positivity_violations = validate_price_volume_positivity(df_raw)\n",
        "\n",
        "    # Step 2: K-Line Consistency\n",
        "    kline_violations = validate_kline_consistency(df_raw)\n",
        "\n",
        "    # Step 3: Frequency\n",
        "    frequency_gaps = validate_frequency_integrity(df_raw, universe)\n",
        "\n",
        "    # Summary\n",
        "    status = \"passed\"\n",
        "    if not positivity_violations.empty or not kline_violations.empty or frequency_gaps:\n",
        "        status = \"warnings_found\"\n",
        "\n",
        "    logger.info(f\"Task 3 completed with status: {status}\")\n",
        "\n",
        "    return {\n",
        "        \"status\": status,\n",
        "        \"positivity_violations\": positivity_violations,\n",
        "        \"kline_violations\": kline_violations,\n",
        "        \"frequency_gaps\": frequency_gaps\n",
        "    }\n"
      ],
      "metadata": {
        "id": "H7eBWyyD1HYc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 4 — Cleanse data: remove duplicates, handle missingness, and repair K-line violations\n",
        "\n",
        "# ==========================================================================================\n",
        "# Task 4: Cleanse data: remove duplicates, handle missingness, and repair K-line violations\n",
        "# ==========================================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 4, Step 1: Remove duplicates; handle NaN/Inf with a single leakage-safe policy\n",
        "# ------------------------------------------------------------------------------\n",
        "def cleanse_duplicates_and_missing(df_raw: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Cleanses the raw dataframe by removing duplicate index keys and rows with NaN/Inf values.\n",
        "\n",
        "    Policy:\n",
        "    1. Duplicates: Keep 'last' (assumes latest update is most accurate).\n",
        "    2. Missing/Inf: Drop row (strict fidelity, no imputation artifacts).\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, Dict[str, int]]: The cleansed dataframe and a dictionary of drop counts.\n",
        "    \"\"\"\n",
        "    initial_count = len(df_raw)\n",
        "    stats = {\"initial_rows\": initial_count}\n",
        "\n",
        "    # 1. Remove Duplicates\n",
        "    # We check for duplicates on the index (date, ticker)\n",
        "    if df_raw.index.duplicated().any():\n",
        "        # keep='last' preserves the last occurrence\n",
        "        df_dedup = df_raw[~df_raw.index.duplicated(keep='last')].copy()\n",
        "        duplicates_dropped = initial_count - len(df_dedup)\n",
        "        stats[\"duplicates_dropped\"] = duplicates_dropped\n",
        "        logger.info(f\"Dropped {duplicates_dropped} duplicate rows.\")\n",
        "    else:\n",
        "        df_dedup = df_raw.copy()\n",
        "        stats[\"duplicates_dropped\"] = 0\n",
        "\n",
        "    # 2. Handle Infinite Values\n",
        "    # Replace inf/-inf with NaN so they can be dropped by dropna\n",
        "    df_dedup.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # 3. Drop NaNs\n",
        "    # We drop if ANY required column is NaN.\n",
        "    # We assume all columns present are required for the tensor (OHLCV + Indicators).\n",
        "    df_clean = df_dedup.dropna(how='any')\n",
        "\n",
        "    nan_inf_dropped = len(df_dedup) - len(df_clean)\n",
        "    stats[\"nan_inf_dropped\"] = nan_inf_dropped\n",
        "    stats[\"final_rows\"] = len(df_clean)\n",
        "\n",
        "    if nan_inf_dropped > 0:\n",
        "        logger.info(f\"Dropped {nan_inf_dropped} rows containing NaN or Inf values.\")\n",
        "\n",
        "    return df_clean, stats\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 4, Step 2: Enforce K-line validity via deterministic curation\n",
        "# ------------------------------------------------------------------------------\n",
        "def curate_kline_validity(df_clean: pd.DataFrame) -> Tuple[pd.DataFrame, Dict[str, int]]:\n",
        "    \"\"\"\n",
        "    Enforces K-line consistency constraints via deterministic curation.\n",
        "\n",
        "    Algorithm:\n",
        "    H_t := max(O_t, H_t, L_t, C_t)\n",
        "    L_t := min(O_t, H_t, L_t, C_t)\n",
        "\n",
        "    After curation, any rows that still violate positivity or strict inequality constraints\n",
        "    (e.g. negative prices) are dropped.\n",
        "\n",
        "    Args:\n",
        "        df_clean (pd.DataFrame): The cleansed dataframe.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, Dict[str, int]]: The curated dataframe and curation statistics.\n",
        "    \"\"\"\n",
        "    df_curated = df_clean.copy()\n",
        "    stats = {}\n",
        "\n",
        "    # Extract arrays for vectorized operations\n",
        "    O = df_curated[\"Open\"].values\n",
        "    H = df_curated[\"High\"].values\n",
        "    L = df_curated[\"Low\"].values\n",
        "    C = df_curated[\"Close\"].values\n",
        "\n",
        "    # 1. Deterministic Curation\n",
        "    # Calculate new High and Low\n",
        "    # We use the original values for the set {O, H, L, C}\n",
        "    new_H = np.maximum.reduce([O, H, L, C])\n",
        "    new_L = np.minimum.reduce([O, H, L, C])\n",
        "\n",
        "    # Count how many rows were modified\n",
        "    modified_H = np.sum(new_H != H)\n",
        "    modified_L = np.sum(new_L != L)\n",
        "    stats[\"rows_modified_High\"] = int(modified_H)\n",
        "    stats[\"rows_modified_Low\"] = int(modified_L)\n",
        "\n",
        "    # Apply updates\n",
        "    df_curated[\"High\"] = new_H\n",
        "    df_curated[\"Low\"] = new_L\n",
        "\n",
        "    # 2. Final Validation (Positivity & Consistency)\n",
        "    # Even after curation, prices must be > 0.\n",
        "    # Curation ensures L <= min(O,C) <= max(O,C) <= H by definition,\n",
        "    # but if inputs were negative, outputs might be negative.\n",
        "    # Check positivity\n",
        "    positivity_mask = (\n",
        "        (df_curated[\"Open\"] > 0) &\n",
        "        (df_curated[\"High\"] > 0) &\n",
        "        (df_curated[\"Low\"] > 0) &\n",
        "        (df_curated[\"Close\"] > 0)\n",
        "    )\n",
        "\n",
        "    if \"AdjClose\" in df_curated.columns:\n",
        "        positivity_mask &= (df_curated[\"AdjClose\"] > 0)\n",
        "\n",
        "    # Volume >= 0\n",
        "    if \"Volume\" in df_curated.columns:\n",
        "        positivity_mask &= (df_curated[\"Volume\"] >= 0)\n",
        "\n",
        "    # Filter\n",
        "    df_final = df_curated[positivity_mask].copy()\n",
        "    dropped_post_curation = len(df_curated) - len(df_final)\n",
        "    stats[\"dropped_post_curation\"] = dropped_post_curation\n",
        "\n",
        "    if dropped_post_curation > 0:\n",
        "        logger.warning(f\"Dropped {dropped_post_curation} rows after curation due to positivity violations.\")\n",
        "\n",
        "    return df_final, stats\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 4, Step 3: Define AdjClose for crypto if absent\n",
        "# ------------------------------------------------------------------------------\n",
        "def ensure_adj_close_presence(df_curated: pd.DataFrame, universe: str) -> Tuple[pd.DataFrame, Dict[str, bool]]:\n",
        "    \"\"\"\n",
        "    Ensures 'AdjClose' column exists. For Crypto_Hourly, if missing, it is defined as 'Close'.\n",
        "    For US_Stocks_Daily, it must already exist (validated in Task 1).\n",
        "\n",
        "    Args:\n",
        "        df_curated (pd.DataFrame): The curated dataframe.\n",
        "        universe (str): The universe identifier.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, Dict[str, bool]]: The dataframe with AdjClose and a provenance flag.\n",
        "    \"\"\"\n",
        "    df_out = df_curated.copy()\n",
        "    provenance = {\"AdjClose_defined_as_Close\": False}\n",
        "\n",
        "    if universe == \"Crypto_Hourly\":\n",
        "        if \"AdjClose\" not in df_out.columns:\n",
        "            logger.info(\"Crypto_Hourly: 'AdjClose' missing. Creating 'AdjClose' := 'Close'.\")\n",
        "            df_out[\"AdjClose\"] = df_out[\"Close\"]\n",
        "            provenance[\"AdjClose_defined_as_Close\"] = True\n",
        "        elif df_out[\"AdjClose\"].isnull().all():\n",
        "             # If it exists but is all NaN (edge case from ingestion)\n",
        "            logger.info(\"Crypto_Hourly: 'AdjClose' is all NaN. Overwriting with 'Close'.\")\n",
        "            df_out[\"AdjClose\"] = df_out[\"Close\"]\n",
        "            provenance[\"AdjClose_defined_as_Close\"] = True\n",
        "\n",
        "    return df_out, provenance\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 4, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def cleanse_and_curate_data(\n",
        "    df_raw: pd.DataFrame,\n",
        "    universe: str\n",
        ") -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 4: Cleanse, Curate, and Standardize Schema.\n",
        "\n",
        "    Executes:\n",
        "    1. Duplicate removal and NaN/Inf dropping.\n",
        "    2. Deterministic K-line curation.\n",
        "    3. AdjClose definition for Crypto.\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "        universe (str): The universe identifier.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.DataFrame, Dict[str, Any]]: The final clean dataframe and a metadata dictionary.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 4: Data cleansing and curation...\")\n",
        "\n",
        "    # Step 1: Cleanse\n",
        "    df_clean, cleanse_stats = cleanse_duplicates_and_missing(df_raw)\n",
        "\n",
        "    # Step 2: Curate\n",
        "    df_curated, curation_stats = curate_kline_validity(df_clean)\n",
        "\n",
        "    # Step 3: AdjClose\n",
        "    df_final, adj_provenance = ensure_adj_close_presence(df_curated, universe)\n",
        "\n",
        "    # Compile Metadata\n",
        "    metadata = {\n",
        "        \"cleanse_stats\": cleanse_stats,\n",
        "        \"curation_stats\": curation_stats,\n",
        "        \"provenance\": adj_provenance,\n",
        "        \"final_shape\": df_final.shape\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Task 4 completed. Final shape: {df_final.shape}\")\n",
        "    return df_final, metadata\n"
      ],
      "metadata": {
        "id": "xIzLEqYP2DGk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 5 — Resolve REQUIRED_FROM_CODE parameters from authors' implementation\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 5: Resolve REQUIRED_FROM_CODE parameters from authors' implementation\n",
        "# ==============================================================================\n",
        "\n",
        "# -----------------------------------------------------------------------------------\n",
        "# Task 5, Step 1: Retrieve authors’ released code and extract missing specifications\n",
        "# -----------------------------------------------------------------------------------\n",
        "def extract_resolved_specifications() -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Simulates the extraction of missing parameter specifications from the authors'\n",
        "    codebase or defines robust, methodologically consistent defaults where the\n",
        "    code is inaccessible.\n",
        "\n",
        "    These values replace 'REQUIRED_FROM_CODE' placeholders to enable a\n",
        "    deterministic, functional pipeline.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: A dictionary mapping dot-notation config paths to resolved values.\n",
        "    \"\"\"\n",
        "    # Here, we define the \"Ground Truth\" defaults based on standard Quant Finance practices\n",
        "    # and the paper's context.\n",
        "    resolved_specs = {\n",
        "        # Reproducibility\n",
        "        \"reproducibility.random_seed\": 42,\n",
        "\n",
        "        # Data Schemas - US Stocks\n",
        "        # Using a representative subset of DJIA if exact list is unknown,\n",
        "        # but for \"Exact Replication\" we'd need the file.\n",
        "        # We'll assume the user provides the file or we use a placeholder list for structural validity.\n",
        "        \"data_schemas.US_Stocks_Daily.required_tickers\": [\n",
        "            \"AAPL\", \"MSFT\", \"JPM\", \"V\", \"PG\", \"JNJ\", \"WMT\", \"DIS\", \"GS\", \"IBM\",\n",
        "            \"INTC\", \"CSCO\", \"MRK\", \"UNH\", \"KO\", \"NKE\", \"MCD\", \"AXP\", \"CAT\", \"BA\",\n",
        "            \"CVX\", \"XOM\", \"HD\", \"VZ\", \"MMM\", \"PFE\", \"TRV\" # 27 tickers\n",
        "        ],\n",
        "\n",
        "        # Technical Indicators (Standard set for financial ML)\n",
        "        \"data_schemas.US_Stocks_Daily.columns.technical_indicators\": [\n",
        "            \"RSI_14\", \"MACD\", \"MACD_Signal\", \"ATR_14\", \"CCI_14\", \"MOM_10\", \"ROC_10\"\n",
        "        ],\n",
        "        \"data_schemas.Crypto_Hourly.columns.technical_indicators\": [\n",
        "            \"RSI_14\", \"MACD\", \"MACD_Signal\", \"ATR_14\", \"CCI_14\", \"MOM_10\", \"ROC_10\"\n",
        "        ],\n",
        "\n",
        "        # Preprocessing\n",
        "        \"preprocessing.normalization.scope\": \"rolling\",\n",
        "        \"preprocessing.normalization.rolling_window\": 252, # 1 trading year\n",
        "        \"preprocessing.alignment_policy.timestamp_join\": \"intersection\",\n",
        "        \"preprocessing.alignment_policy.missing_data_policy\": \"drop\",\n",
        "\n",
        "        # Econometrics\n",
        "        \"econometrics.cointegration.method\": \"engle-granger\",\n",
        "        \"econometrics.cointegration.transform\": \"log\",\n",
        "        \"econometrics.cointegration.topk_candidates\": 5, # k for Algorithm 1\n",
        "\n",
        "        # Task Models (Architecture Details)\n",
        "        \"task_models.GRU.architecture_details\": {\"layers\": 2, \"dropout\": 0.1},\n",
        "        \"task_models.LSTM.architecture_details\": {\"layers\": 2, \"dropout\": 0.1},\n",
        "        \"task_models.TCN.architecture_details\": {\"kernel_size\": 3, \"dropout\": 0.1, \"dilations\": [1, 2, 4, 8]},\n",
        "        \"task_models.Transformer.architecture_details\": {\"layers\": 2, \"heads\": 4, \"dropout\": 0.1},\n",
        "        \"task_models.DLinear.architecture_details\": {\"individual\": False},\n",
        "\n",
        "        # Planner\n",
        "        \"planner.state_features.descriptor_scope\": \"channel_mean\", # Aggregate descriptors across features\n",
        "\n",
        "        # Scheduler\n",
        "        \"scheduler.early_stopping.definition\": \"patience_counter\",\n",
        "        \"scheduler.early_stopping.improvement_threshold\": 1e-4,\n",
        "\n",
        "        # Manipulation Module\n",
        "        \"manipulation_module.operation_parameterization\": \"linear_map\", # Map lambda to op params linearly\n",
        "        \"manipulation_module.mixup_target_sampling.topk_candidates\": 5, # Must match econometrics\n",
        "        \"manipulation_module.binary_mix.mi_estimator\": \"binning\",\n",
        "        \"manipulation_module.binary_mix.mi_estimator_params\": {\"bins\": 10},\n",
        "\n",
        "        # Evaluation\n",
        "        \"evaluation.proximity_metrics.psi.bins_k\": 10,\n",
        "        \"evaluation.proximity_metrics.ks.mode\": \"average_per_feature\",\n",
        "        \"evaluation.proximity_metrics.mmd.bandwidth\": 1.0,\n",
        "        \"evaluation.discriminative_score.classifier_architecture\": \"GRU_Classifier\",\n",
        "        \"evaluation.stylized_facts.acf_lags\": [1, 5, 10, 20, 50],\n",
        "        \"evaluation.stylized_facts.leverage_volatility_proxy\": \"rolling_std_20\",\n",
        "        \"evaluation.tsne.random_state\": 42\n",
        "    }\n",
        "\n",
        "    return resolved_specs\n",
        "\n",
        "\n",
        "# --------------------------------------------------------------------------------------------\n",
        "# Task 5, Step 2: Update STUDY_CONFIG to replace all REQUIRED_FROM_CODE with fixed constants\n",
        "# --------------------------------------------------------------------------------------------\n",
        "def apply_resolved_specifications(\n",
        "    study_config: Dict[str, Any],\n",
        "    resolved_specs: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Creates a deep copy of the study configuration and updates it with the resolved\n",
        "    specifications.\n",
        "\n",
        "    Args:\n",
        "        study_config (Dict[str, Any]): The original configuration with placeholders.\n",
        "        resolved_specs (Dict[str, Any]): The dictionary of resolved values.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: The fully resolved configuration dictionary.\n",
        "    \"\"\"\n",
        "    config_copy = copy.deepcopy(study_config)\n",
        "\n",
        "    for path, value in resolved_specs.items():\n",
        "        # Navigate to the key location\n",
        "        keys = path.split('.')\n",
        "        current = config_copy\n",
        "\n",
        "        # Traverse to the parent dict\n",
        "        for key in keys[:-1]:\n",
        "            # Handle list indexing if necessary (e.g., \"list[0]\")\n",
        "            # For simplicity in this schema, we assume dict keys, but robust code handles lists.\n",
        "            if '[' in key and ']' in key:\n",
        "                k, idx = key[:-1].split('[')\n",
        "                current = current[k][int(idx)]\n",
        "            else:\n",
        "                current = current[key]\n",
        "\n",
        "        # Set the value\n",
        "        last_key = keys[-1]\n",
        "        current[last_key] = value\n",
        "\n",
        "    return config_copy\n",
        "\n",
        "\n",
        "def compute_config_hash(study_config: Dict[str, Any]) -> str:\n",
        "    \"\"\"\n",
        "    Computes a SHA256 hash of the configuration dictionary to serve as a unique\n",
        "    run identifier for provenance.\n",
        "\n",
        "    Args:\n",
        "        study_config (Dict[str, Any]): The configuration dictionary.\n",
        "\n",
        "    Returns:\n",
        "        str: The hexadecimal hash string.\n",
        "    \"\"\"\n",
        "    # Sort keys to ensure deterministic hashing\n",
        "    config_str = json.dumps(study_config, sort_keys=True, default=str)\n",
        "    return hashlib.sha256(config_str.encode('utf-8')).hexdigest()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 5, Step 3: Declare reproducibility boundary\n",
        "# ------------------------------------------------------------------------------\n",
        "def verify_resolution_completeness(study_config: Dict[str, Any]) -> None:\n",
        "    \"\"\"\n",
        "    Verifies that no 'REQUIRED_FROM_CODE' placeholders remain in the configuration.\n",
        "\n",
        "    Args:\n",
        "        study_config (Dict[str, Any]): The resolved configuration.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If unresolved parameters remain.\n",
        "    \"\"\"\n",
        "    # Verify that no 'REQUIRED_FROM_CODE' placeholders remain in the configuration.\n",
        "    def find_unresolved(node, path=\"\"):\n",
        "        unresolved = []\n",
        "        if isinstance(node, dict):\n",
        "            for k, v in node.items():\n",
        "                unresolved.extend(find_unresolved(v, f\"{path}.{k}\" if path else k))\n",
        "        elif isinstance(node, list):\n",
        "            for i, v in enumerate(node):\n",
        "                unresolved.extend(find_unresolved(v, f\"{path}[{i}]\"))\n",
        "        elif isinstance(node, str) and node == \"REQUIRED_FROM_CODE\":\n",
        "            unresolved.append(path)\n",
        "        return unresolved\n",
        "\n",
        "    unresolved = find_unresolved(study_config)\n",
        "\n",
        "    if unresolved:\n",
        "        error_msg = f\"Configuration still contains {len(unresolved)} unresolved parameters: {unresolved[:5]}...\"\n",
        "        logger.error(error_msg)\n",
        "        raise ValueError(error_msg)\n",
        "\n",
        "    logger.info(\"Reproducibility Boundary Check: PASSED. All parameters resolved.\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 5, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def resolve_study_configuration(study_config: Dict[str, Any]) -> Tuple[Dict[str, Any], str]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 5: Resolves missing parameters and freezes the configuration.\n",
        "\n",
        "    Executes:\n",
        "    1. Extraction of resolved specifications (defaults/ground truth).\n",
        "    2. Application of specifications to the config.\n",
        "    3. Hashing of the final config for provenance.\n",
        "    4. Verification of completeness.\n",
        "\n",
        "    Args:\n",
        "        study_config (Dict[str, Any]): The initial configuration with placeholders.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[Dict[str, Any], str]: The resolved configuration and its SHA256 hash.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 5: Resolving configuration parameters...\")\n",
        "\n",
        "    # Step 1: Extract Specs\n",
        "    resolved_specs = extract_resolved_specifications()\n",
        "\n",
        "    # Step 2: Apply Specs\n",
        "    resolved_config = apply_resolved_specifications(study_config, resolved_specs)\n",
        "\n",
        "    # Step 3: Verify\n",
        "    verify_resolution_completeness(resolved_config)\n",
        "\n",
        "    # Step 4: Hash\n",
        "    config_hash = compute_config_hash(resolved_config)\n",
        "\n",
        "    logger.info(f\"Task 5 completed. Config Hash: {config_hash}\")\n",
        "\n",
        "    return resolved_config, config_hash\n"
      ],
      "metadata": {
        "id": "Iz-8FMEf216R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 6 — Compute forecasting targets exactly as defined in the paper\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 6: Compute forecasting targets exactly as defined in the paper\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 6, Step 1: Compute one-step close-to-close return y_t per ticker\n",
        "# ------------------------------------------------------------------------------\n",
        "def calculate_one_step_return(df_final: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Computes the one-step close-to-close return target y_t.\n",
        "\n",
        "    Equation:\n",
        "    y_t = (C_{t+1} - C_t) / C_t\n",
        "\n",
        "    This target is aligned to time t, representing the return realized at t+1.\n",
        "\n",
        "    Args:\n",
        "        df_final (pd.DataFrame): The cleansed and curated dataframe with MultiIndex (date, ticker).\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: The dataframe with a new 'target_return' column.\n",
        "    \"\"\"\n",
        "    # Ensure sorted by ticker then date for correct shifting\n",
        "    # Note: df_final index is (date, ticker). We sort by ticker, date.\n",
        "    df_sorted = df_final.sort_index(level=[\"ticker\", \"date\"])\n",
        "\n",
        "    # Group by ticker to isolate series\n",
        "    # shift(-1) gets C_{t+1} aligned at t\n",
        "    # We use the 'Close' column as specified in the manuscript equation.\n",
        "    # Note: Even if AdjClose exists, the manuscript specifies Close-to-Close for y_t.\n",
        "    # (Unless resolved otherwise in Task 5, but we stick to the explicit equation here).\n",
        "    # Define a helper to apply per group\n",
        "    def compute_return(group):\n",
        "        c_t = group[\"Close\"]\n",
        "        c_t_plus_1 = group[\"Close\"].shift(-1)\n",
        "        return (c_t_plus_1 - c_t) / c_t\n",
        "\n",
        "    # Apply transformation\n",
        "    # This returns a Series with the same index as df_sorted\n",
        "    target_series = df_sorted.groupby(level=\"ticker\", group_keys=False).apply(compute_return)\n",
        "\n",
        "    # Assign back\n",
        "    df_with_target = df_sorted.copy()\n",
        "    df_with_target[\"target_return\"] = target_series\n",
        "\n",
        "    return df_with_target\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 6, Step 2: Align targets with feature windows ensuring no look-ahead leakage\n",
        "# ------------------------------------------------------------------------------\n",
        "def align_targets_and_drop_invalid(df_with_target: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Aligns targets and drops rows where the target is undefined (i.e., the last observation).\n",
        "\n",
        "    Since y_t depends on C_{t+1}, the last row of each ticker has a NaN target.\n",
        "    These rows cannot be used for training (as samples ending at t) because y_t is unknown.\n",
        "\n",
        "    Args:\n",
        "        df_with_target (pd.DataFrame): Dataframe with 'target_return'.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Dataframe with invalid target rows removed.\n",
        "    \"\"\"\n",
        "    initial_count = len(df_with_target)\n",
        "\n",
        "    # Drop rows where target_return is NaN\n",
        "    df_valid = df_with_target.dropna(subset=[\"target_return\"])\n",
        "\n",
        "    dropped_count = initial_count - len(df_valid)\n",
        "    logger.info(f\"Dropped {dropped_count} rows (terminal observations) with undefined targets.\")\n",
        "\n",
        "    return df_valid\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 6, Step 3: Store targets in a structure aligned with the feature tensor\n",
        "# ------------------------------------------------------------------------------\n",
        "def extract_canonical_targets(df_valid: pd.DataFrame) -> Tuple[pd.Series, List[Tuple[str, pd.Timestamp]]]:\n",
        "    \"\"\"\n",
        "    Extracts the target series and generates the canonical sample keys.\n",
        "\n",
        "    Canonical Key: (ticker, t_end_date)\n",
        "    This key uniquely identifies a sample: the window ending at t_end_date for ticker.\n",
        "\n",
        "    Args:\n",
        "        df_valid (pd.DataFrame): Dataframe with valid targets.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.Series, List[Tuple[str, pd.Timestamp]]]:\n",
        "            - The target series indexed by (ticker, date).\n",
        "            - A list of valid sample keys.\n",
        "    \"\"\"\n",
        "    # We require canonical keys as (ticker, t_end_date).\n",
        "    # df_valid is currently indexed by (date, ticker) or (ticker, date) depending on sort.\n",
        "    # We enforce (ticker, date) index for the output series.\n",
        "    if df_valid.index.names == [\"date\", \"ticker\"]:\n",
        "        df_reindexed = df_valid.swaplevel(\"date\", \"ticker\")\n",
        "    else:\n",
        "        df_reindexed = df_valid\n",
        "\n",
        "    df_reindexed = df_reindexed.sort_index(level=[\"ticker\", \"date\"])\n",
        "\n",
        "    target_series = df_reindexed[\"target_return\"]\n",
        "\n",
        "    # Generate keys list\n",
        "    # Index is (ticker, date)\n",
        "    keys = list(target_series.index)\n",
        "\n",
        "    return target_series, keys\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 6, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_forecasting_targets(df_final: pd.DataFrame) -> Tuple[pd.Series, Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 6: Compute forecasting targets.\n",
        "\n",
        "    Executes:\n",
        "    1. Calculation of y_t = (C_{t+1} - C_t) / C_t.\n",
        "    2. Removal of terminal rows (undefined targets).\n",
        "    3. Extraction of canonical target series and keys.\n",
        "\n",
        "    Args:\n",
        "        df_final (pd.DataFrame): The cleansed and curated dataframe.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[pd.Series, Dict[str, Any]]:\n",
        "            - Target series y indexed by (ticker, date).\n",
        "            - Metadata dict containing valid keys list and stats.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 6: Computing forecasting targets...\")\n",
        "\n",
        "    # Step 1: Calculate\n",
        "    df_with_target = calculate_one_step_return(df_final)\n",
        "\n",
        "    # Step 2: Align/Drop\n",
        "    df_valid = align_targets_and_drop_invalid(df_with_target)\n",
        "\n",
        "    # Step 3: Extract\n",
        "    y, valid_keys = extract_canonical_targets(df_valid)\n",
        "\n",
        "    metadata = {\n",
        "        \"total_valid_samples\": len(y),\n",
        "        \"valid_keys\": valid_keys,\n",
        "        \"tickers_count\": len(y.index.get_level_values(\"ticker\").unique())\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Task 6 completed. Generated {len(y)} valid targets.\")\n",
        "\n",
        "    return y, metadata\n"
      ],
      "metadata": {
        "id": "1ScFiQhz4Nmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 7 — Build lookback windows and construct the feature tensor\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 7: Build lookback windows and construct the feature tensor\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 7, Step 1: Define and implement window construction with L=60\n",
        "# ------------------------------------------------------------------------------\n",
        "def build_sliding_windows(\n",
        "    df_final: pd.DataFrame,\n",
        "    target_series: pd.Series,\n",
        "    lookback_window: int\n",
        ") -> Tuple[np.ndarray, np.ndarray, List[Tuple[str, pd.Timestamp]], List[str]]:\n",
        "    \"\"\"\n",
        "    Constructs sliding window features and aligned targets for forecasting.\n",
        "\n",
        "    Equation:\n",
        "    x_{t-L+1:t} \\in R^{d x L}\n",
        "    y_t aligned to window ending at t.\n",
        "\n",
        "    Args:\n",
        "        df_final (pd.DataFrame): The cleansed dataframe (features).\n",
        "        target_series (pd.Series): The target series y_t.\n",
        "        lookback_window (int): Window length L (e.g., 60).\n",
        "\n",
        "    Returns:\n",
        "        Tuple:\n",
        "            - X_windows (np.ndarray): Shape (N, L, F)\n",
        "            - y (np.ndarray): Shape (N,)\n",
        "            - sample_keys (List[Tuple[str, pd.Timestamp]]): List of (ticker, date) keys.\n",
        "            - feature_names (List[str]): List of feature column names.\n",
        "    \"\"\"\n",
        "    # 1. Align Features and Targets\n",
        "    # We only want windows where we have a valid target.\n",
        "    # target_series index is (ticker, date).\n",
        "    # df_final index is (date, ticker).\n",
        "    # Ensure df_final is sorted by ticker, date to match target_series structure\n",
        "    if df_final.index.names == [\"date\", \"ticker\"]:\n",
        "        df_sorted = df_final.swaplevel(\"date\", \"ticker\").sort_index()\n",
        "    else:\n",
        "        df_sorted = df_final.sort_index()\n",
        "\n",
        "    feature_names = list(df_sorted.columns)\n",
        "\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "    keys_list = []\n",
        "\n",
        "    # Iterate by ticker to respect boundaries\n",
        "    for ticker, group in df_sorted.groupby(level=\"ticker\"):\n",
        "        # Get targets for this ticker\n",
        "        if ticker in target_series.index.get_level_values(\"ticker\"):\n",
        "            # Extract target subset\n",
        "            # target_series is indexed by (ticker, date), so loc[ticker] gives Series indexed by date\n",
        "            ticker_targets = target_series.loc[ticker]\n",
        "\n",
        "            # Align dates: We need L history for each target.\n",
        "            # group index is (ticker, date). We drop ticker level for alignment.\n",
        "            group_features = group.droplevel(\"ticker\")\n",
        "\n",
        "            # Convert to numpy\n",
        "            feat_vals = group_features.values # (T_ticker, F)\n",
        "            dates = group_features.index\n",
        "\n",
        "            # Use stride_tricks to create windows\n",
        "            # Shape: (T_ticker - L + 1, L, F)\n",
        "            if len(feat_vals) < lookback_window:\n",
        "                continue\n",
        "\n",
        "            windows = sliding_window_view(feat_vals, window_shape=lookback_window, axis=0)\n",
        "\n",
        "            # The window at index i ends at original index i + L - 1\n",
        "            # We need targets at dates[i + L - 1]\n",
        "            valid_indices = []\n",
        "            valid_windows = []\n",
        "            valid_targets = []\n",
        "            valid_keys = []\n",
        "\n",
        "            # Iterate through generated windows to check target existence\n",
        "            # Optimization: Vectorize if possible, but alignment is tricky with missing targets.\n",
        "            # Given targets are already filtered for validity (Task 6), we intersect.\n",
        "            # Window i corresponds to end_date = dates[i + lookback_window - 1]\n",
        "            # We need target at end_date.\n",
        "            # Construct array of end_dates for the windows\n",
        "            window_end_dates = dates[lookback_window - 1:]\n",
        "\n",
        "            # Intersect with target dates\n",
        "            common_dates = window_end_dates.intersection(ticker_targets.index)\n",
        "\n",
        "            if len(common_dates) == 0:\n",
        "                continue\n",
        "\n",
        "            # Find integer indices in window_end_dates that match common_dates\n",
        "            # This allows us to slice 'windows' array\n",
        "            # pd.Index.get_indexer returns -1 for missing, but we know they exist\n",
        "            indices = window_end_dates.get_indexer(common_dates)\n",
        "\n",
        "            # Select windows\n",
        "            selected_windows = windows[indices] # (N_valid, L, F)\n",
        "\n",
        "            # Select targets\n",
        "            selected_targets = ticker_targets.loc[common_dates].values\n",
        "\n",
        "            # Create keys\n",
        "            selected_keys = [(ticker, d) for d in common_dates]\n",
        "\n",
        "            X_list.append(selected_windows)\n",
        "            y_list.append(selected_targets)\n",
        "            keys_list.extend(selected_keys)\n",
        "\n",
        "    if not X_list:\n",
        "        raise ValueError(\"No valid windows constructed. Check data alignment.\")\n",
        "\n",
        "    # Concatenate\n",
        "    X_windows = np.concatenate(X_list, axis=0)\n",
        "    y = np.concatenate(y_list, axis=0)\n",
        "\n",
        "    return X_windows, y, keys_list, feature_names\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 7, Step 2: Handle cross-sectional alignment and tensorization\n",
        "# ------------------------------------------------------------------------------\n",
        "def construct_aligned_tensor(\n",
        "    df_final: pd.DataFrame,\n",
        "    alignment_policy: str = \"intersection\"\n",
        ") -> Tuple[np.ndarray, pd.Index, pd.Index, List[str]]:\n",
        "    \"\"\"\n",
        "    Constructs a dense tensor (T, S, F) for multi-stock operations.\n",
        "\n",
        "    Args:\n",
        "        df_final (pd.DataFrame): Features dataframe.\n",
        "        alignment_policy (str): 'intersection' or 'union'.\n",
        "\n",
        "    Returns:\n",
        "        Tuple:\n",
        "            - tensor (np.ndarray): Shape (T, S, F)\n",
        "            - timestamp_index (pd.Index): The common timestamps.\n",
        "            - ticker_index (pd.Index): The ordered tickers.\n",
        "            - feature_names (List[str]): Feature names.\n",
        "    \"\"\"\n",
        "    # Pivot to (Date, Ticker, Feature)\n",
        "    # df_final index is (date, ticker)\n",
        "    # Unstack ticker level -> Columns become MultiIndex (Feature, Ticker)\n",
        "    df_unstacked = df_final.unstack(level=\"ticker\")\n",
        "\n",
        "    # Handle alignment\n",
        "    if alignment_policy == \"intersection\":\n",
        "        df_aligned = df_unstacked.dropna(how='any') # Drop rows (dates) where any ticker is missing any feature\n",
        "    elif alignment_policy == \"union\":\n",
        "        df_aligned = df_unstacked # Keep NaNs\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown alignment policy: {alignment_policy}\")\n",
        "\n",
        "    # Reshape to (T, S, F)\n",
        "    # Current columns: (Feature, Ticker)\n",
        "    # We want to extract numpy array such that axis 0=Time, axis 1=Ticker, axis 2=Feature\n",
        "    # Swap levels to (Ticker, Feature) and sort\n",
        "    df_aligned.columns = df_aligned.columns.swaplevel(0, 1)\n",
        "    df_aligned = df_aligned.sort_index(axis=1)\n",
        "\n",
        "    # Extract dimensions\n",
        "    timestamps = df_aligned.index\n",
        "    tickers = df_aligned.columns.levels[0]\n",
        "    features = df_aligned.columns.levels[1]\n",
        "\n",
        "    T = len(timestamps)\n",
        "    S = len(tickers)\n",
        "    F = len(features)\n",
        "\n",
        "    # Reshape\n",
        "    # values is (T, S*F)\n",
        "    # We need to ensure the column order matches S, F\n",
        "    # Sort ensures Ticker 1 (all feats), Ticker 2 (all feats)...\n",
        "    raw_values = df_aligned.values\n",
        "    tensor = raw_values.reshape(T, S, F)\n",
        "\n",
        "    return tensor, timestamps, tickers, list(features)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 7, Step 3: Define RL state representation\n",
        "# ------------------------------------------------------------------------------\n",
        "def prepare_rl_trajectories(\n",
        "    X_windows: np.ndarray,\n",
        "    sample_keys: List[Tuple[str, pd.Timestamp]]\n",
        ") -> Dict[str, Dict[pd.Timestamp, np.ndarray]]:\n",
        "    \"\"\"\n",
        "    Organizes windowed data into a structure suitable for RL environment replay.\n",
        "\n",
        "    RL State s_t = [x_{t-L+1:t}, p_t].\n",
        "    This function prepares the x component, indexed by ticker and time.\n",
        "\n",
        "    Args:\n",
        "        X_windows (np.ndarray): The windowed features.\n",
        "        sample_keys (List[Tuple[str, pd.Timestamp]]): Corresponding keys.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Dict[pd.Timestamp, np.ndarray]]: Nested dict {ticker: {date: window}}.\n",
        "    \"\"\"\n",
        "    rl_data = {}\n",
        "\n",
        "    # Organize windowed data into a structure suitable for RL environment replay\n",
        "    for i, (ticker, date) in enumerate(sample_keys):\n",
        "        if ticker not in rl_data:\n",
        "            rl_data[ticker] = {}\n",
        "        rl_data[ticker][date] = X_windows[i]\n",
        "\n",
        "    return rl_data\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 7, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def construct_feature_tensors(\n",
        "    df_final: pd.DataFrame,\n",
        "    target_series: pd.Series,\n",
        "    study_config: Dict[str, Any]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 7: Feature Tensor Construction.\n",
        "\n",
        "    Executes:\n",
        "    1. Sliding window generation (N, L, F).\n",
        "    2. Cross-sectional alignment (T, S, F).\n",
        "    3. RL trajectory preparation.\n",
        "\n",
        "    Args:\n",
        "        df_final (pd.DataFrame): Cleansed features.\n",
        "        target_series (pd.Series): Targets.\n",
        "        study_config (Dict[str, Any]): Config.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Dictionary containing all tensor artifacts and metadata.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 7: Constructing feature tensors...\")\n",
        "\n",
        "    lookback = study_config[\"preprocessing\"][\"lookback_window\"]\n",
        "    align_policy = study_config[\"preprocessing\"][\"alignment_policy\"][\"timestamp_join\"]\n",
        "\n",
        "    # Step 1: Windows\n",
        "    X_windows, y, sample_keys, feature_names = build_sliding_windows(\n",
        "        df_final, target_series, lookback\n",
        "    )\n",
        "\n",
        "    # Step 2: Aligned Tensor\n",
        "    aligned_tensor, timestamps, tickers, aligned_feats = construct_aligned_tensor(\n",
        "        df_final, align_policy\n",
        "    )\n",
        "\n",
        "    # Step 3: RL Data\n",
        "    rl_data = prepare_rl_trajectories(X_windows, sample_keys)\n",
        "\n",
        "    # Verify feature consistency\n",
        "    if feature_names != aligned_feats:\n",
        "        logger.warning(\"Feature order mismatch between windowed and aligned tensors. Check sorting.\")\n",
        "\n",
        "    logger.info(f\"Task 7 completed. Windowed shape: {X_windows.shape}, Aligned shape: {aligned_tensor.shape}\")\n",
        "\n",
        "    return {\n",
        "        \"X_windows\": X_windows,\n",
        "        \"y\": y,\n",
        "        \"sample_keys\": sample_keys,\n",
        "        \"feature_names\": feature_names,\n",
        "        \"aligned_tensor\": aligned_tensor,\n",
        "        \"aligned_timestamps\": timestamps,\n",
        "        \"aligned_tickers\": tickers,\n",
        "        \"rl_data\": rl_data\n",
        "    }\n"
      ],
      "metadata": {
        "id": "Ch4MSOtr5I97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 8 — Create chronological Train/Valid/Test splits without leakage\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 8: Create chronological Train/Valid/Test splits without leakage\n",
        "# ==============================================================================\n",
        "\n",
        "@dataclass\n",
        "class SplitMetadata:\n",
        "    \"\"\"\n",
        "    A container for managing chronological split boundaries and enforcing leakage prevention logic.\n",
        "\n",
        "    This dataclass encapsulates the indices and timestamp ranges for Training, Validation, and Test sets,\n",
        "    as well as the definitions for rolling folds used in proximity analysis. It serves as the single\n",
        "    source of truth for data partitioning throughout the pipeline, ensuring that no future information\n",
        "    leaks into training-only estimators (e.g., normalization, cointegration).\n",
        "\n",
        "    Attributes:\n",
        "        train_range (Tuple[pd.Timestamp, pd.Timestamp]): The start and end timestamps of the training partition.\n",
        "        valid_range (Tuple[pd.Timestamp, pd.Timestamp]): The start and end timestamps of the validation partition.\n",
        "        test_range (Tuple[pd.Timestamp, pd.Timestamp]): The start and end timestamps of the test partition.\n",
        "        train_indices (np.ndarray): An array of integer indices corresponding to the training set in the global aligned tensor.\n",
        "        valid_indices (np.ndarray): An array of integer indices corresponding to the validation set in the global aligned tensor.\n",
        "        test_indices (np.ndarray): An array of integer indices corresponding to the test set in the global aligned tensor.\n",
        "        rolling_folds (List[Dict[str, Any]]): A list of dictionaries, where each dictionary defines a rolling fold\n",
        "                                              (indices and ranges) for proximity analysis as per the manuscript's protocol.\n",
        "    \"\"\"\n",
        "    train_range: Tuple[pd.Timestamp, pd.Timestamp]\n",
        "    valid_range: Tuple[pd.Timestamp, pd.Timestamp]\n",
        "    test_range: Tuple[pd.Timestamp, pd.Timestamp]\n",
        "    train_indices: np.ndarray\n",
        "    valid_indices: np.ndarray\n",
        "    test_indices: np.ndarray\n",
        "    rolling_folds: List[Dict[str, Any]]\n",
        "\n",
        "    def assert_train_only(self, timestamps: pd.Index) -> None:\n",
        "        \"\"\"\n",
        "        Asserts that the provided timestamps fall strictly within the defined training range.\n",
        "\n",
        "        This method acts as a runtime guardrail to prevent look-ahead bias. It is invoked before\n",
        "        fitting any estimator (e.g., Normalizer, Cointegration Test) to ensure that the data\n",
        "        being used does not extend beyond the training cutoff.\n",
        "\n",
        "        Args:\n",
        "            timestamps (pd.Index): The index of timestamps associated with the data being checked.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the maximum timestamp in the input exceeds the training range's end date.\n",
        "        \"\"\"\n",
        "        # Check if the latest timestamp in the input is strictly within the training horizon.\n",
        "        # Equation/Logic: max(t_input) <= max(t_train)\n",
        "        if timestamps.max() > self.train_range[1]:\n",
        "            raise ValueError(\n",
        "                f\"Leakage detected! Data contains timestamps up to {timestamps.max()}, \"\n",
        "                f\"which is beyond the training cutoff {self.train_range[1]}.\"\n",
        "            )\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 8, Step 1: Implement single chronological split 0.6/0.2/0.2\n",
        "# ------------------------------------------------------------------------------\n",
        "def generate_main_split(\n",
        "    timestamps: pd.Index,\n",
        "    ratios: Dict[str, float]\n",
        ") -> Tuple[np.ndarray, np.ndarray, np.ndarray, Dict[str, Tuple[pd.Timestamp, pd.Timestamp]]]:\n",
        "    \"\"\"\n",
        "    Generates indices for the main chronological split (Train/Valid/Test).\n",
        "\n",
        "    Args:\n",
        "        timestamps (pd.Index): Sorted global timestamps.\n",
        "        ratios (Dict[str, float]): Split ratios (e.g., {'train': 0.6, 'valid': 0.2, 'test': 0.2}).\n",
        "\n",
        "    Returns:\n",
        "        Tuple: train_idx, valid_idx, test_idx, ranges_dict\n",
        "    \"\"\"\n",
        "    n_total = len(timestamps)\n",
        "    n_train = int(n_total * ratios[\"train\"])\n",
        "    n_valid = int(n_total * ratios[\"valid\"])\n",
        "\n",
        "    # Test gets the remainder to ensure sum is n_total\n",
        "    n_test = n_total - n_train - n_valid\n",
        "\n",
        "    if n_train == 0 or n_valid == 0 or n_test == 0:\n",
        "        raise ValueError(f\"Insufficient data for split. Total: {n_total}, Ratios: {ratios}\")\n",
        "\n",
        "    # Generate indices\n",
        "    # Assumes timestamps are sorted (enforced in orchestrator)\n",
        "    train_idx = np.arange(0, n_train)\n",
        "    valid_idx = np.arange(n_train, n_train + n_valid)\n",
        "    test_idx = np.arange(n_train + n_valid, n_total)\n",
        "\n",
        "    # Extract ranges\n",
        "    ranges = {\n",
        "        \"train\": (timestamps[train_idx[0]], timestamps[train_idx[-1]]),\n",
        "        \"valid\": (timestamps[valid_idx[0]], timestamps[valid_idx[-1]]),\n",
        "        \"test\": (timestamps[test_idx[0]], timestamps[test_idx[-1]])\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Main Split: Train {len(train_idx)} | Valid {len(valid_idx)} | Test {len(test_idx)}\")\n",
        "    logger.info(f\"Train Range: {ranges['train'][0]} -> {ranges['train'][1]}\")\n",
        "\n",
        "    return train_idx, valid_idx, test_idx, ranges\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 8, Step 2: Implement rolling-year / rolling-month protocols\n",
        "# ------------------------------------------------------------------------------\n",
        "def generate_rolling_folds(\n",
        "    timestamps: pd.Index,\n",
        "    universe: str,\n",
        "    ratios: Dict[str, float]\n",
        ") -> List[Dict[str, Any]]:\n",
        "    \"\"\"\n",
        "    Generates rolling window folds for proximity analysis.\n",
        "\n",
        "    Protocol:\n",
        "    - Stocks: Expand by 1 year. Base window 2000-2010 (approx).\n",
        "    - Crypto: Expand by 1 month.\n",
        "\n",
        "    Inside each fold, we apply the 0.6/0.2/0.2 split to the *current cumulative window*.\n",
        "\n",
        "    Args:\n",
        "        timestamps (pd.Index): Global timestamps.\n",
        "        universe (str): 'US_Stocks_Daily' or 'Crypto_Hourly'.\n",
        "        ratios (Dict[str, float]): Split ratios.\n",
        "\n",
        "    Returns:\n",
        "        List[Dict]: List of fold definitions (indices and ranges).\n",
        "    \"\"\"\n",
        "    folds = []\n",
        "\n",
        "    start_date = timestamps.min()\n",
        "    end_date = timestamps.max()\n",
        "\n",
        "    # Define step size and initial window based on universe/manuscript\n",
        "    if universe == \"US_Stocks_Daily\":\n",
        "        step = pd.DateOffset(years=1)\n",
        "        # Manuscript: \"splitting all samples from 2000 to (2010 + k)\"\n",
        "        # We assume the dataset starts around 2000.\n",
        "        # Initial end: 2010-01-01.\n",
        "        current_end = pd.Timestamp(\"2010-01-01\")\n",
        "        if current_end < start_date:\n",
        "             # Fallback if data starts later\n",
        "            current_end = start_date + pd.DateOffset(years=10)\n",
        "    elif universe == \"Crypto_Hourly\":\n",
        "        step = pd.DateOffset(months=1)\n",
        "        # Let's define base as first 6 months.\n",
        "        current_end = start_date + pd.DateOffset(months=6)\n",
        "    else:\n",
        "        return [] # Should not happen given validation\n",
        "\n",
        "    fold_id = 0\n",
        "\n",
        "    while current_end <= end_date:\n",
        "        # Select data for this fold: [start_date, current_end]\n",
        "        # We use searchsorted for efficiency\n",
        "        # timestamps is sorted\n",
        "        cutoff_idx = timestamps.searchsorted(current_end)\n",
        "\n",
        "        if cutoff_idx < 100: # Skip if too few samples\n",
        "            current_end += step\n",
        "            continue\n",
        "\n",
        "        # Indices for this fold's total data\n",
        "        fold_timestamps = timestamps[:cutoff_idx]\n",
        "\n",
        "        # Apply split logic to this subset\n",
        "        # We reuse the logic from Step 1 but on the subset\n",
        "        n_total = len(fold_timestamps)\n",
        "        n_train = int(n_total * ratios[\"train\"])\n",
        "        n_valid = int(n_total * ratios[\"valid\"])\n",
        "        n_test = n_total - n_train - n_valid\n",
        "\n",
        "        if n_train > 0 and n_valid > 0 and n_test > 0:\n",
        "            train_idx = np.arange(0, n_train)\n",
        "            valid_idx = np.arange(n_train, n_train + n_valid)\n",
        "            test_idx = np.arange(n_train + n_valid, n_total)\n",
        "\n",
        "            folds.append({\n",
        "                \"fold_id\": fold_id,\n",
        "                \"cutoff_date\": current_end,\n",
        "                \"train_idx\": train_idx,\n",
        "                \"valid_idx\": valid_idx,\n",
        "                \"test_idx\": test_idx,\n",
        "                \"train_range\": (fold_timestamps[train_idx[0]], fold_timestamps[train_idx[-1]]),\n",
        "                \"valid_range\": (fold_timestamps[valid_idx[0]], fold_timestamps[valid_idx[-1]]),\n",
        "                \"test_range\": (fold_timestamps[test_idx[0]], fold_timestamps[test_idx[-1]])\n",
        "            })\n",
        "            fold_id += 1\n",
        "\n",
        "        current_end += step\n",
        "\n",
        "    logger.info(f\"Generated {len(folds)} rolling folds for proximity analysis.\")\n",
        "    return folds\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 8, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def create_chronological_splits(\n",
        "    timestamps: pd.Index,\n",
        "    universe: str,\n",
        "    study_config: Dict[str, Any]\n",
        ") -> SplitMetadata:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 8: Create chronological splits and leakage guards.\n",
        "\n",
        "    Executes:\n",
        "    1. Main 0.6/0.2/0.2 split generation.\n",
        "    2. Rolling fold generation for proximity analysis.\n",
        "    3. Construction of SplitMetadata object.\n",
        "\n",
        "    Args:\n",
        "        timestamps (pd.Index): Sorted global timestamps from the aligned tensor.\n",
        "        universe (str): Universe identifier.\n",
        "        study_config (Dict[str, Any]): Configuration dict.\n",
        "\n",
        "    Returns:\n",
        "        SplitMetadata: The split definitions and enforcement logic.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 8: Creating chronological splits...\")\n",
        "\n",
        "    # Ensure sorted\n",
        "    if not timestamps.is_monotonic_increasing:\n",
        "        raise ValueError(\"Timestamps must be sorted for chronological splitting.\")\n",
        "\n",
        "    ratios = study_config[\"preprocessing\"][\"split_ratios\"]\n",
        "\n",
        "    # Step 1: Main Split\n",
        "    train_idx, valid_idx, test_idx, ranges = generate_main_split(timestamps, ratios)\n",
        "\n",
        "    # Step 2: Rolling Folds\n",
        "    folds = generate_rolling_folds(timestamps, universe, ratios)\n",
        "\n",
        "    # Step 3: Metadata Object\n",
        "    metadata = SplitMetadata(\n",
        "        train_range=ranges[\"train\"],\n",
        "        valid_range=ranges[\"valid\"],\n",
        "        test_range=ranges[\"test\"],\n",
        "        train_indices=train_idx,\n",
        "        valid_indices=valid_idx,\n",
        "        test_indices=test_idx,\n",
        "        rolling_folds=folds\n",
        "    )\n",
        "\n",
        "    logger.info(\"Task 8 completed. SplitMetadata created.\")\n",
        "    return metadata\n"
      ],
      "metadata": {
        "id": "cfpyQfI36aab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 9 — Implement normalization using train-only statistics\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 9: Implement normalization using train-only statistics\n",
        "# ==============================================================================\n",
        "\n",
        "@dataclass\n",
        "class Normalizer:\n",
        "    \"\"\"\n",
        "    Artifact storing normalization parameters fitted on the training set.\n",
        "\n",
        "    Attributes:\n",
        "        mean (np.ndarray): Mean values of shape (1, S, F).\n",
        "        std (np.ndarray): Standard deviation values of shape (1, S, F).\n",
        "        feature_names (List[str]): List of feature names for reference.\n",
        "        epsilon (float): Small constant to prevent division by zero.\n",
        "    \"\"\"\n",
        "    mean: np.ndarray\n",
        "    std: np.ndarray\n",
        "    feature_names: List[str]\n",
        "    epsilon: float = 1e-8\n",
        "\n",
        "    def normalize(self, x: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies Z-score normalization: (x - mean) / std.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): Input tensor of shape (..., S, F).\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Normalized tensor.\n",
        "        \"\"\"\n",
        "        # Broadcasting handles dimensions (T, S, F) against (1, S, F)\n",
        "        return (x - self.mean) / (self.std + self.epsilon)\n",
        "\n",
        "    def denormalize(self, x_norm: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies inverse Z-score normalization: x_norm * std + mean.\n",
        "\n",
        "        Args:\n",
        "            x_norm (np.ndarray): Normalized tensor of shape (..., S, F).\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Original scale tensor.\n",
        "        \"\"\"\n",
        "        return x_norm * (self.std + self.epsilon) + self.mean\n",
        "\n",
        "    def denormalize_feature(self, x_feat: np.ndarray, feature_idx: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Denormalizes a specific feature channel.\n",
        "\n",
        "        Args:\n",
        "            x_feat (np.ndarray): Normalized feature array of shape (..., S).\n",
        "            feature_idx (int): Index of the feature in the original tensor.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Denormalized feature array.\n",
        "        \"\"\"\n",
        "        # Extract params for this feature: shape (1, S)\n",
        "        feat_mean = self.mean[..., feature_idx]\n",
        "        feat_std = self.std[..., feature_idx]\n",
        "\n",
        "        return x_feat * (feat_std + self.epsilon) + feat_mean\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 9, Step 1: Compute normalization parameters on training segment only\n",
        "# ------------------------------------------------------------------------------\n",
        "def fit_normalizer(\n",
        "    tensor: np.ndarray,\n",
        "    train_indices: np.ndarray,\n",
        "    feature_names: List[str]\n",
        ") -> Normalizer:\n",
        "    \"\"\"\n",
        "    Computes mean and standard deviation using only the training subset of the tensor.\n",
        "\n",
        "    Args:\n",
        "        tensor (np.ndarray): The global aligned tensor of shape (T, S, F).\n",
        "        train_indices (np.ndarray): Integer indices corresponding to the training set.\n",
        "        feature_names (List[str]): Names of the features (last dimension).\n",
        "\n",
        "    Returns:\n",
        "        Normalizer: An initialized Normalizer object with fitted parameters.\n",
        "    \"\"\"\n",
        "    # Select training data: (N_train, S, F)\n",
        "    train_data = tensor[train_indices]\n",
        "\n",
        "    # Compute stats along time axis (axis 0)\n",
        "    # Result shape: (S, F)\n",
        "    mean_vals = np.nanmean(train_data, axis=0)\n",
        "    std_vals = np.nanstd(train_data, axis=0)\n",
        "\n",
        "    # Reshape to (1, S, F) for broadcasting against (T, S, F)\n",
        "    mean_reshaped = mean_vals[np.newaxis, :, :]\n",
        "    std_reshaped = std_vals[np.newaxis, :, :]\n",
        "\n",
        "    # Handle near-zero std to avoid explosion\n",
        "    # We don't modify the data, just the divisor in the Normalizer class via epsilon,\n",
        "    # but we can also clamp here if strictly needed.\n",
        "\n",
        "    logger.info(f\"Fitted normalizer on {len(train_indices)} time steps.\")\n",
        "\n",
        "    return Normalizer(\n",
        "        mean=mean_reshaped,\n",
        "        std=std_reshaped,\n",
        "        feature_names=feature_names\n",
        "    )\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 9, Step 2: Apply normalization to Train/Valid/Test using training parameters\n",
        "# ------------------------------------------------------------------------------\n",
        "def apply_normalization(\n",
        "    tensor: np.ndarray,\n",
        "    normalizer: Normalizer\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies the fitted normalization to the entire tensor.\n",
        "\n",
        "    Args:\n",
        "        tensor (np.ndarray): The global aligned tensor (T, S, F).\n",
        "        normalizer (Normalizer): The fitted normalizer.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The normalized tensor.\n",
        "    \"\"\"\n",
        "    # The normalizer handles broadcasting\n",
        "    normalized_tensor = normalizer.normalize(tensor)\n",
        "\n",
        "    return normalized_tensor\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 9, Step 3: Implement denormalization for the manipulation pipeline\n",
        "# ------------------------------------------------------------------------------\n",
        "# Note: This step is implemented as methods within the Normalizer class above.\n",
        "# The 'denormalize' and 'denormalize_feature' methods fulfill this requirement.\n",
        "# We provide a standalone wrapper for clarity if needed by the orchestrator.\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 9, Step 3: Implement denormalization for the manipulation pipeline\n",
        "# ------------------------------------------------------------------------------\n",
        "def denormalize_tensor(\n",
        "    normalized_tensor: np.ndarray,\n",
        "    normalizer: Normalizer\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Reverts the Z-score normalization applied to a tensor, restoring the data to its original scale.\n",
        "\n",
        "    This wrapper function invokes the `denormalize` method of the provided `Normalizer` artifact.\n",
        "    It is essential for the manipulation pipeline, specifically after mix-up operations (which occur\n",
        "    in normalized space) and before final curation or output, to ensuring that the synthesized data\n",
        "    returns to the meaningful financial domain (e.g., price levels).\n",
        "\n",
        "    Equation:\n",
        "        x = \\tilde{x} \\cdot \\sigma_{\\text{train}} + \\mu_{\\text{train}}\n",
        "\n",
        "    Args:\n",
        "        normalized_tensor (np.ndarray): The input tensor containing normalized data.\n",
        "                                        Expected shape: (..., S, F), where S is stocks and F is features.\n",
        "        normalizer (Normalizer): The fitted Normalizer object containing the training set's\n",
        "                                 mean (\\mu) and standard deviation (\\sigma) parameters.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The denormalized tensor with the same shape as the input, containing values\n",
        "                    scaled back to the original distribution.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If the dimensions of the input tensor do not align with the normalizer's parameters\n",
        "                    for broadcasting.\n",
        "    \"\"\"\n",
        "    # Validate input shape compatibility (basic check against feature dimension)\n",
        "    if normalized_tensor.shape[-1] != normalizer.mean.shape[-1]:\n",
        "        raise ValueError(\n",
        "            f\"Input tensor feature dimension ({normalized_tensor.shape[-1]}) \"\n",
        "            f\"does not match normalizer feature dimension ({normalizer.mean.shape[-1]}).\"\n",
        "        )\n",
        "\n",
        "    return normalizer.denormalize(normalized_tensor)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 9, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def normalize_data(\n",
        "    aligned_tensor: np.ndarray,\n",
        "    split_metadata: Any, # SplitMetadata type\n",
        "    feature_names: List[str]\n",
        ") -> Tuple[np.ndarray, Normalizer]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 9: Normalization.\n",
        "\n",
        "    Executes:\n",
        "    1. Fitting of normalizer on training indices.\n",
        "    2. Transformation of the full tensor.\n",
        "\n",
        "    Args:\n",
        "        aligned_tensor (np.ndarray): Shape (T, S, F).\n",
        "        split_metadata (SplitMetadata): Contains train_indices.\n",
        "        feature_names (List[str]): Feature names.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, Normalizer]: Normalized tensor and the artifact.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 9: Normalizing data...\")\n",
        "\n",
        "    # Step 1: Fit\n",
        "    normalizer = fit_normalizer(\n",
        "        aligned_tensor,\n",
        "        split_metadata.train_indices,\n",
        "        feature_names\n",
        "    )\n",
        "\n",
        "    # Step 2: Transform\n",
        "    normalized_tensor = apply_normalization(aligned_tensor, normalizer)\n",
        "\n",
        "    # Sanity Check\n",
        "    train_subset = normalized_tensor[split_metadata.train_indices]\n",
        "    train_mean = np.nanmean(train_subset)\n",
        "    train_std = np.nanstd(train_subset)\n",
        "    logger.info(f\"Normalized Training Subset - Global Mean: {train_mean:.4f}, Global Std: {train_std:.4f}\")\n",
        "\n",
        "    logger.info(\"Task 9 completed.\")\n",
        "    return normalized_tensor, normalizer\n"
      ],
      "metadata": {
        "id": "3bOjp0oe7trN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 10 — Compute cointegration p-values on training data for Algorithm 1\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 10: Compute cointegration p-values on training data for Algorithm 1\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 10, Step 1: Configure cointegration test\n",
        "# ------------------------------------------------------------------------------\n",
        "def get_cointegration_config(study_config: Dict[str, Any]) -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Extracts and validates cointegration settings.\n",
        "\n",
        "    Args:\n",
        "        study_config (Dict[str, Any]): The resolved configuration.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Validated settings (method, transform, price_field).\n",
        "    \"\"\"\n",
        "    econ_config = study_config[\"econometrics\"][\"cointegration\"]\n",
        "\n",
        "    method = econ_config.get(\"method\", \"engle-granger\").lower()\n",
        "    transform = econ_config.get(\"transform\", \"log\").lower()\n",
        "    price_field = econ_config.get(\"price_field\", \"Close\")\n",
        "\n",
        "    if method not in [\"engle-granger\"]:\n",
        "        # Johansen not implemented in this snippet; fallback or raise\n",
        "        # We implement EG as the standard pairwise method.\n",
        "        logger.warning(f\"Cointegration method '{method}' requested. Defaulting to 'engle-granger' for pairwise matrix.\")\n",
        "        method = \"engle-granger\"\n",
        "\n",
        "    return {\n",
        "        \"method\": method,\n",
        "        \"transform\": transform,\n",
        "        \"price_field\": price_field\n",
        "    }\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 10, Step 2: Compute pairwise cointegration p-value matrix\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_pairwise_pvalues(\n",
        "    tensor: np.ndarray,\n",
        "    train_indices: np.ndarray,\n",
        "    feature_names: List[str],\n",
        "    config: Dict[str, Any]\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the pairwise cointegration p-value matrix on training data.\n",
        "\n",
        "    Matrix P where P[i, j] is the p-value of cointegration between source i and target j.\n",
        "    Low p-value implies strong cointegration (reject null of no cointegration).\n",
        "\n",
        "    Args:\n",
        "        tensor (np.ndarray): Aligned tensor (T, S, F).\n",
        "        train_indices (np.ndarray): Indices for training set.\n",
        "        feature_names (List[str]): Feature names to locate price column.\n",
        "        config (Dict[str, Any]): Cointegration settings.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Matrix of shape (S, S).\n",
        "    \"\"\"\n",
        "    # 1. Extract Training Prices\n",
        "    # Locate price feature\n",
        "    price_field = config[\"price_field\"]\n",
        "    try:\n",
        "        feat_idx = feature_names.index(price_field)\n",
        "    except ValueError:\n",
        "        raise ValueError(f\"Price field '{price_field}' not found in features: {feature_names}\")\n",
        "\n",
        "    # Shape: (N_train, S)\n",
        "    prices = tensor[train_indices, :, feat_idx]\n",
        "\n",
        "    # 2. Apply Transform\n",
        "    if config[\"transform\"] == \"log\":\n",
        "        # Handle zeros/negatives if any slipped through (though Task 3 checked)\n",
        "        # Add epsilon just in case or rely on Task 3 validity\n",
        "        prices = np.log(prices + 1e-8)\n",
        "\n",
        "    S = prices.shape[1]\n",
        "    p_matrix = np.full((S, S), np.nan)\n",
        "\n",
        "    # 3. Compute Pairwise Tests\n",
        "    # O(S^2) loop. For S=27, 729 iterations. Fast enough.\n",
        "    for i in range(S):\n",
        "        for j in range(S):\n",
        "            if i == j:\n",
        "                continue\n",
        "\n",
        "            series_i = prices[:, i]\n",
        "            series_j = prices[:, j]\n",
        "\n",
        "            # Check for constant series (variance ~ 0)\n",
        "            if np.var(series_i) < 1e-8 or np.var(series_j) < 1e-8:\n",
        "                p_matrix[i, j] = 1.0 # Cannot reject null of no cointegration\n",
        "                continue\n",
        "\n",
        "            try:\n",
        "                # coint(y, x) -> tests residuals of y = ax + b\n",
        "                # We use i as source (y) and j as target (x)\n",
        "                # Returns: t-stat, p-value, crit-vals\n",
        "                _, p_val, _ = coint(series_i, series_j, autolag='AIC')\n",
        "                p_matrix[i, j] = p_val\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Cointegration test failed for pair ({i}, {j}): {e}\")\n",
        "                p_matrix[i, j] = 1.0 # Fail safe: assume no cointegration\n",
        "\n",
        "    return p_matrix\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 10, Step 3: Validate p-values and handle invalid entries\n",
        "# ------------------------------------------------------------------------------\n",
        "def validate_p_matrix(p_matrix: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Validates and cleans the p-value matrix.\n",
        "\n",
        "    Args:\n",
        "        p_matrix (np.ndarray): Raw p-values.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Validated matrix with diagonal NaN and off-diagonal in [0, 1].\n",
        "    \"\"\"\n",
        "    S = p_matrix.shape[0]\n",
        "\n",
        "    # Ensure diagonal is NaN (self-pairs excluded)\n",
        "    np.fill_diagonal(p_matrix, np.nan)\n",
        "\n",
        "    # Clip valid range [0, 1] (statsmodels usually returns this, but safety first)\n",
        "    # NaNs are preserved\n",
        "    # We use where to avoid warning on NaNs\n",
        "    mask = ~np.isnan(p_matrix)\n",
        "    p_matrix[mask] = np.clip(p_matrix[mask], 0.0, 1.0)\n",
        "\n",
        "    # Check for excessive NaNs off-diagonal\n",
        "    n_nans = np.isnan(p_matrix).sum() - S # Subtract diagonal\n",
        "    if n_nans > 0:\n",
        "        logger.warning(f\"Found {n_nans} NaN p-values off-diagonal. Filling with 1.0 (no cointegration).\")\n",
        "        p_matrix[np.isnan(p_matrix)] = 1.0\n",
        "        np.fill_diagonal(p_matrix, np.nan) # Restore diagonal\n",
        "\n",
        "    return p_matrix\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 10, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_cointegration_matrix(\n",
        "    tensor: np.ndarray,\n",
        "    split_metadata: Any, # SplitMetadata\n",
        "    study_config: Dict[str, Any],\n",
        "    feature_names: List[str]\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 10: Cointegration Analysis.\n",
        "\n",
        "    Executes:\n",
        "    1. Config extraction.\n",
        "    2. Pairwise p-value computation on training data.\n",
        "    3. Validation.\n",
        "\n",
        "    Args:\n",
        "        tensor (np.ndarray): Aligned tensor (T, S, F).\n",
        "        split_metadata (SplitMetadata): Training indices.\n",
        "        study_config (Dict[str, Any]): Config.\n",
        "        feature_names (List[str]): Feature names.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The (S, S) p-value matrix.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Task 10: Computing cointegration matrix...\")\n",
        "\n",
        "    # Step 1: Config\n",
        "    coint_config = get_cointegration_config(study_config)\n",
        "\n",
        "    # Step 2: Compute\n",
        "    # Ensure we don't leak: use split_metadata.train_indices\n",
        "    p_matrix_raw = compute_pairwise_pvalues(\n",
        "        tensor,\n",
        "        split_metadata.train_indices,\n",
        "        feature_names,\n",
        "        coint_config\n",
        "    )\n",
        "\n",
        "    # Step 3: Validate\n",
        "    p_matrix = validate_p_matrix(p_matrix_raw)\n",
        "\n",
        "    # Stats\n",
        "    valid_vals = p_matrix[~np.isnan(p_matrix)]\n",
        "    logger.info(f\"Cointegration P-Values - Mean: {np.mean(valid_vals):.4f}, Min: {np.min(valid_vals):.4f}\")\n",
        "\n",
        "    logger.info(\"Task 10 completed.\")\n",
        "    return p_matrix\n"
      ],
      "metadata": {
        "id": "OSUoTSLR9NcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 11 — Implement single-stock transformation operations for (\\mathcal{M})\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 11: Implement single-stock transformation operations for M\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 11, Step 1: Implement Jittering (noise injection)\n",
        "# ------------------------------------------------------------------------------\n",
        "def op_jitter(x: np.ndarray, strength: float, rng: np.random.Generator) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies Jittering: Adds Gaussian noise to the input series.\n",
        "\n",
        "    Equation:\n",
        "        x' = x + \\epsilon, where \\epsilon ~ N(0, \\sigma)\n",
        "        \\sigma = \\lambda * std(x)\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input window of shape (L, F).\n",
        "        strength (float): Manipulation strength \\lambda \\in [0, 1].\n",
        "        rng (np.random.Generator): Random number generator.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Jittered series.\n",
        "    \"\"\"\n",
        "    # Compute standard deviation per feature to scale noise appropriately\n",
        "    # Add epsilon to avoid zero std\n",
        "    stds = np.std(x, axis=0, keepdims=True) + 1e-8\n",
        "\n",
        "    # Noise scale is proportional to strength and feature volatility\n",
        "    noise_scale = strength * stds\n",
        "\n",
        "    noise = rng.normal(loc=0.0, scale=noise_scale, size=x.shape)\n",
        "\n",
        "    return x + noise\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 11, Step 2: Implement Scaling and Magnitude Warping\n",
        "# ------------------------------------------------------------------------------\n",
        "def op_scaling(x: np.ndarray, strength: float, rng: np.random.Generator) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies Scaling: Multiplies the series by a random scalar.\n",
        "\n",
        "    Equation:\n",
        "        x' = x * (1 + \\alpha)\n",
        "        \\alpha ~ N(0, \\lambda^2) (or similar scaling)\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input window (L, F).\n",
        "        strength (float): \\lambda.\n",
        "        rng (np.random.Generator): RNG.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Scaled series.\n",
        "    \"\"\"\n",
        "    # Sample a scaling factor centered at 1\n",
        "    # Strength determines the variance of the scaling factor\n",
        "    # We use a clipped normal to avoid extreme scaling or sign flips (though curation handles negatives)\n",
        "    factor = rng.normal(loc=1.0, scale=strength * 0.1)\n",
        "\n",
        "    return x * factor\n",
        "\n",
        "\n",
        "def op_magnitude_warping(x: np.ndarray, strength: float, rng: np.random.Generator) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies Magnitude Warping: Multiplies the series by a smooth curve generated via cubic splines.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input window (L, F).\n",
        "        strength (float): \\lambda.\n",
        "        rng (np.random.Generator): RNG.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Warped series.\n",
        "    \"\"\"\n",
        "    L, F = x.shape\n",
        "\n",
        "    # Number of knots. A reasonable default is 4-5 for a window of 60.\n",
        "    # We can make knots dependent on strength, but usually strength controls magnitude.\n",
        "    n_knots = 4\n",
        "\n",
        "    # Generate random knot values around 1.0\n",
        "    # Strength controls the deviation from 1.0\n",
        "    knot_values = rng.normal(loc=1.0, scale=strength * 0.2, size=(n_knots, F))\n",
        "\n",
        "    # Generate knot positions (time indices)\n",
        "    knot_indices = np.linspace(0, L-1, n_knots)\n",
        "\n",
        "    # Interpolate to full window length\n",
        "    time_indices = np.arange(L)\n",
        "    warping_curves = np.zeros((L, F))\n",
        "\n",
        "    for f in range(F):\n",
        "        cs = CubicSpline(knot_indices, knot_values[:, f])\n",
        "        warping_curves[:, f] = cs(time_indices)\n",
        "\n",
        "    return x * warping_curves\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 11, Step 3: Implement Permutation and STL Augmentation\n",
        "# ------------------------------------------------------------------------------\n",
        "def op_permutation(x: np.ndarray, strength: float, rng: np.random.Generator) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies Permutation: Splits the sequence into segments and permutes them.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input window (L, F).\n",
        "        strength (float): \\lambda.\n",
        "        rng (np.random.Generator): RNG.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Permuted series.\n",
        "    \"\"\"\n",
        "    L = x.shape[0]\n",
        "\n",
        "    # Determine number of segments based on strength\n",
        "    # Min 1 (no change), Max L (full shuffle)\n",
        "    # Map lambda [0, 1] to [1, 10] segments (arbitrary reasonable cap for L=60)\n",
        "    max_segments = 10\n",
        "    n_segments = int(1 + strength * (max_segments - 1))\n",
        "\n",
        "    if n_segments <= 1:\n",
        "        return x\n",
        "\n",
        "    # Split indices\n",
        "    split_points = np.linspace(0, L, n_segments + 1, dtype=int)\n",
        "\n",
        "    segments = []\n",
        "    for i in range(n_segments):\n",
        "        start, end = split_points[i], split_points[i+1]\n",
        "        segments.append(x[start:end])\n",
        "\n",
        "    # Shuffle segments\n",
        "    # Note: We shuffle the order of segments, but keep data within segments contiguous\n",
        "    permuted_indices = rng.permutation(n_segments)\n",
        "\n",
        "    shuffled_segments = [segments[i] for i in permuted_indices]\n",
        "\n",
        "    return np.concatenate(shuffled_segments, axis=0)\n",
        "\n",
        "\n",
        "def op_stl_augmentation(x: np.ndarray, strength: float, rng: np.random.Generator) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies STL Augmentation: Decomposes into Trend+Seasonal+Resid, bootstraps Resid, recombines.\n",
        "\n",
        "    Simplified implementation for efficiency:\n",
        "    - Trend: Moving average\n",
        "    - Seasonal: Ignored (or simple diff) given short window L=60 and likely non-seasonal daily data.\n",
        "    - Residual: x - Trend\n",
        "    - Augmentation: x' = Trend + (Residual * (1 + noise))\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input window (L, F).\n",
        "        strength (float): \\lambda.\n",
        "        rng (np.random.Generator): RNG.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Augmented series.\n",
        "    \"\"\"\n",
        "    L = x.shape[0]\n",
        "\n",
        "    # Period for trend extraction. Map lambda to window size?\n",
        "    # Or just use a fixed reasonable period for daily data (e.g. 5 days).\n",
        "    # Manuscript says \"lambda controls its period\".\n",
        "    # Map lambda [0, 1] to period [2, 20]\n",
        "    period = int(2 + strength * 18)\n",
        "\n",
        "    # Compute Trend via moving average\n",
        "    # We need to handle edges. 'valid' convolution shrinks size.\n",
        "    # We'll use uniform filter (nearest padding) or simple loop.\n",
        "    # For speed/simplicity in numpy:\n",
        "\n",
        "    trend = np.zeros_like(x)\n",
        "    for f in range(x.shape[1]):\n",
        "        trend[:, f] = np.convolve(x[:, f], np.ones(period)/period, mode='same')\n",
        "\n",
        "    # Residual\n",
        "    residual = x - trend\n",
        "\n",
        "    # Bootstrap/Perturb Residual\n",
        "    # For efficiency and robustness, we'll scale residuals by a random factor\n",
        "    # centered at 1, variance controlled by strength.\n",
        "    resid_scale = rng.normal(loc=1.0, scale=strength * 0.5, size=x.shape)\n",
        "\n",
        "    return trend + (residual * resid_scale)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 11, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "class SingleStockTransformations:\n",
        "    \"\"\"\n",
        "    A registry and dispatcher for single-stock transformation operations used within the\n",
        "    Data Manipulation Module (M).\n",
        "\n",
        "    This class encapsulates the logic for selecting and applying specific augmentation\n",
        "    techniques (Jittering, Scaling, Magnitude Warping, Permutation, STL Augmentation)\n",
        "    to a financial time-series window. It ensures that each operation is applied\n",
        "    deterministically given a random seed, facilitating provenance-aware replay.\n",
        "\n",
        "    Attributes:\n",
        "        ops (Dict[str, Callable]): A mapping from operation names to their corresponding\n",
        "                                   implementation functions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the transformation registry with supported operations.\n",
        "        \"\"\"\n",
        "        self.ops: Dict[str, Callable[[np.ndarray, float, np.random.Generator], np.ndarray]] = {\n",
        "            \"Jittering\": op_jitter,\n",
        "            \"Scaling\": op_scaling,\n",
        "            \"MagnitudeWarping\": op_magnitude_warping,\n",
        "            \"Permutation\": op_permutation,\n",
        "            \"STL_Augmentation\": op_stl_augmentation\n",
        "        }\n",
        "\n",
        "    def apply(\n",
        "        self,\n",
        "        x: np.ndarray,\n",
        "        op_name: str,\n",
        "        strength: float,\n",
        "        seed: int\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies a named single-stock transformation operation to the input window.\n",
        "\n",
        "        This method retrieves the requested operation from the registry and executes it\n",
        "        using a locally instantiated random number generator seeded with the provided value.\n",
        "        This ensures that the transformation is deterministic and isolated from the global\n",
        "        random state, which is critical for the reproducibility of the adaptive dataflow.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): The input time-series window.\n",
        "                            Expected shape: (L, F), where L is the lookback window length\n",
        "                            and F is the number of features.\n",
        "            op_name (str): The name of the operation to apply (e.g., \"Jittering\").\n",
        "                           Must be a key in `self.ops`.\n",
        "            strength (float): The manipulation strength parameter \\lambda \\in [0, 1],\n",
        "                              which controls the intensity of the augmentation.\n",
        "            seed (int): An integer seed to initialize the local random number generator\n",
        "                        for this specific operation application.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: The transformed time-series window with the same shape as the input (L, F).\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If `op_name` is not found in the registry of supported operations.\n",
        "        \"\"\"\n",
        "        # Validate that the requested operation exists in the registry\n",
        "        if op_name not in self.ops:\n",
        "            raise ValueError(f\"Unknown operation: {op_name}. Supported operations: {list(self.ops.keys())}\")\n",
        "\n",
        "        # Create a local RNG for this operation to ensure determinism independent of global state\n",
        "        # This is crucial for the 'provenance-aware replay' requirement of the system.\n",
        "        rng = np.random.Generator(np.random.PCG64(seed))\n",
        "\n",
        "        # Execute the operation\n",
        "        # Equation: x_transformed = Op(x, \\lambda, \\xi), where \\xi is randomness from rng\n",
        "        return self.ops[op_name](x, strength, rng)\n",
        "\n",
        "def apply_single_stock_transformations(\n",
        "    x_batch: np.ndarray,\n",
        "    p_matrix: np.ndarray,\n",
        "    lambda_matrix: np.ndarray,\n",
        "    ops_list: List[str],\n",
        "    base_seed: int\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Orchestrator for applying single-stock transformations to a batch.\n",
        "\n",
        "    Note: In the bi-level optimization scheme, p and lambda are provided by the planner.\n",
        "    For a batch, we might sample one op per sample based on p, or apply weighted sum (for planner update).\n",
        "\n",
        "    This function implements the SAMPLING path (for Inner Loop / Task Model Training).\n",
        "\n",
        "    Args:\n",
        "        x_batch (np.ndarray): Batch of windows (B, L, F).\n",
        "        p_matrix (np.ndarray): Probabilities (B, n_ops) or (n_ops,).\n",
        "        lambda_matrix (np.ndarray): Strengths (B, n_ops) or (n_ops,).\n",
        "        ops_list (List[str]): List of operation names corresponding to p/lambda columns.\n",
        "        base_seed (int): Base seed for RNG.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Transformed batch.\n",
        "    \"\"\"\n",
        "    B = x_batch.shape[0]\n",
        "    transformer = SingleStockTransformations()\n",
        "    x_out = x_batch.copy()\n",
        "\n",
        "    rng = np.random.Generator(np.random.PCG64(base_seed))\n",
        "\n",
        "    # Handle broadcasting if p/lambda are global (1, n_ops)\n",
        "    if p_matrix.ndim == 1:\n",
        "        p_matrix = np.tile(p_matrix, (B, 1))\n",
        "    if lambda_matrix.ndim == 1:\n",
        "        lambda_matrix = np.tile(lambda_matrix, (B, 1))\n",
        "\n",
        "    # For each sample, select an operation\n",
        "    # We assume p_matrix rows sum to 1 (or we normalize)\n",
        "    for i in range(B):\n",
        "        # Sample op index\n",
        "        p_i = p_matrix[i]\n",
        "        p_i = p_i / np.sum(p_i) # Ensure sum to 1\n",
        "        op_idx = rng.choice(len(ops_list), p=p_i)\n",
        "\n",
        "        op_name = ops_list[op_idx]\n",
        "        strength = lambda_matrix[i, op_idx]\n",
        "\n",
        "        # Apply op\n",
        "        # Use a unique seed per sample/step for provenance\n",
        "        sample_seed = base_seed + i\n",
        "        x_out[i] = transformer.apply(x_batch[i], op_name, strength, sample_seed)\n",
        "\n",
        "    return x_out\n"
      ],
      "metadata": {
        "id": "5yzv0Gmg-nAt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 12 — Implement curation and normalization layers for (\\mathcal{M})\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 12: Implement curation and normalization layers for M\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 12, Step 1: Post-transformation curation to enforce K-line validity\n",
        "# ------------------------------------------------------------------------------\n",
        "def curate_window(\n",
        "    x: np.ndarray,\n",
        "    ohlc_indices: Tuple[int, int, int, int]\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Enforces K-line consistency constraints on a time-series window.\n",
        "\n",
        "    Equations:\n",
        "        H_t := max(O_t, H_t, L_t, C_t)\n",
        "        L_t := min(O_t, H_t, L_t, C_t)\n",
        "\n",
        "    This ensures L_t <= min(O_t, C_t) <= max(O_t, C_t) <= H_t.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input window of shape (L, F).\n",
        "        ohlc_indices (Tuple[int, int, int, int]): Indices for (Open, High, Low, Close).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Curated window.\n",
        "    \"\"\"\n",
        "    idx_O, idx_H, idx_L, idx_C = ohlc_indices\n",
        "\n",
        "    # Extract columns\n",
        "    O = x[:, idx_O]\n",
        "    H = x[:, idx_H]\n",
        "    L = x[:, idx_L]\n",
        "    C = x[:, idx_C]\n",
        "\n",
        "    # Calculate new High and Low\n",
        "    # Note: We must copy to avoid modifying x in place before calculation is complete\n",
        "    # (though numpy ufuncs usually handle this, explicit is safer)\n",
        "\n",
        "    # H = max(O, H, L, C)\n",
        "    new_H = np.maximum.reduce([O, H, L, C])\n",
        "\n",
        "    # L = min(O, H, L, C)\n",
        "    new_L = np.minimum.reduce([O, H, L, C])\n",
        "\n",
        "    # Update x\n",
        "    x_curated = x.copy()\n",
        "    x_curated[:, idx_H] = new_H\n",
        "    x_curated[:, idx_L] = new_L\n",
        "\n",
        "    # Positivity check: Clip to epsilon if negative (augmentation artifact)\n",
        "    # Financial prices must be positive.\n",
        "    # We only clip price columns.\n",
        "    epsilon = 1e-4\n",
        "    for idx in ohlc_indices:\n",
        "        x_curated[:, idx] = np.maximum(x_curated[:, idx], epsilon)\n",
        "\n",
        "    return x_curated\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 12, Step 2: Normalization using train-only parameters before mix-up\n",
        "# ------------------------------------------------------------------------------\n",
        "def normalize_window(\n",
        "    x: np.ndarray,\n",
        "    normalizer: Any # Normalizer class\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies Z-score normalization to the window using training parameters.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Input window (L, F).\n",
        "        normalizer (Normalizer): Fitted normalizer.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Normalized window.\n",
        "    \"\"\"\n",
        "    return normalizer.normalize(x)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 12, Step 3: Denormalization to return to price space after mix-up\n",
        "# ------------------------------------------------------------------------------\n",
        "def denormalize_window(\n",
        "    x_norm: np.ndarray,\n",
        "    normalizer: Any\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies inverse Z-score normalization.\n",
        "\n",
        "    Args:\n",
        "        x_norm (np.ndarray): Normalized window.\n",
        "        normalizer (Normalizer): Fitted normalizer (sliced for specific stock).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Denormalized window.\n",
        "    \"\"\"\n",
        "    return normalizer.denormalize(x_norm)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 12, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def apply_curation_and_normalization(\n",
        "    x: np.ndarray,\n",
        "    ohlc_indices: Tuple[int, int, int, int],\n",
        "    mean: np.ndarray,\n",
        "    std: np.ndarray\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 12: Curation and Normalization.\n",
        "\n",
        "    This function is designed to be called inside the augmentation loop for a specific sample.\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Raw input window (L, F).\n",
        "        ohlc_indices (Tuple): Indices for O, H, L, C.\n",
        "        mean (np.ndarray): Mean vector for this stock (F,).\n",
        "        std (np.ndarray): Std vector for this stock (F,).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Curated and normalized window.\n",
        "    \"\"\"\n",
        "    # 1. Curate (Raw Space)\n",
        "    x_curated = curate_window(x, ohlc_indices)\n",
        "\n",
        "    # 2. Normalize\n",
        "    # Manual Z-score here since we passed specific vectors\n",
        "    epsilon = 1e-8\n",
        "    x_norm = (x_curated - mean) / (std + epsilon)\n",
        "\n",
        "    return x_norm\n"
      ],
      "metadata": {
        "id": "I1jTCD8vACLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 13 — Implement multi-stock mix-up operations for (\\mathcal{M})\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 13: Implement multi-stock mix-up operations for M\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 13, Step 1: Implement Cut Mix (segment replacement)\n",
        "# ------------------------------------------------------------------------------\n",
        "def op_cut_mix(\n",
        "    x_src: np.ndarray, y_src: float,\n",
        "    x_tgt: np.ndarray, y_tgt: float,\n",
        "    strength: float,\n",
        "    rng: np.random.Generator\n",
        ") -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Applies CutMix: Replaces a random time segment of source with target.\n",
        "\n",
        "    Args:\n",
        "        x_src, x_tgt: Input windows (L, F).\n",
        "        y_src, y_tgt: Target scalars.\n",
        "        strength: Lambda parameter determining cut size.\n",
        "        rng: Random number generator.\n",
        "\n",
        "    Returns:\n",
        "        x_new, y_new\n",
        "    \"\"\"\n",
        "    L = x_src.shape[0]\n",
        "\n",
        "    # Determine cut length proportional to strength\n",
        "    # strength \\in [0, 1] -> cut_len \\in [0, L]\n",
        "    cut_len = int(strength * L)\n",
        "\n",
        "    if cut_len == 0:\n",
        "        return x_src.copy(), y_src\n",
        "    if cut_len == L:\n",
        "        return x_tgt.copy(), y_tgt\n",
        "\n",
        "    # Sample start position\n",
        "    # Valid range: [0, L - cut_len]\n",
        "    start = rng.integers(0, L - cut_len + 1)\n",
        "    end = start + cut_len\n",
        "\n",
        "    # Create mixed sample\n",
        "    x_new = x_src.copy()\n",
        "    x_new[start:end] = x_tgt[start:end]\n",
        "\n",
        "    # Mix labels proportional to area\n",
        "    # ratio = replaced_area / total_area\n",
        "    ratio = cut_len / L\n",
        "    y_new = (1 - ratio) * y_src + ratio * y_tgt\n",
        "\n",
        "    return x_new, y_new\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 13, Step 2: Implement Linear Mix (weighted average)\n",
        "# ------------------------------------------------------------------------------\n",
        "def op_linear_mix(\n",
        "    x_src: np.ndarray, y_src: float,\n",
        "    x_tgt: np.ndarray, y_tgt: float,\n",
        "    strength: float,\n",
        "    rng: np.random.Generator\n",
        ") -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Applies Linear Mix (MixUp): Convex combination of source and target.\n",
        "\n",
        "    Args:\n",
        "        strength: Lambda parameter (weight of source? or mixing ratio?).\n",
        "                  Manuscript: \"Linear Mix linearly combines two stocks\".\n",
        "                  Usually lambda is the weight of the first operand.\n",
        "                  We assume strength is the interpolation ratio.\n",
        "                  However, planner outputs lambda.\n",
        "                  If lambda=1, we expect full mix? Or identity?\n",
        "                  Standard MixUp: x = lam*x1 + (1-lam)*x2.\n",
        "                  We will use strength as the weight for x_src.\n",
        "                  Wait, usually augmentation strength implies \"amount of change\".\n",
        "                  If strength=0 -> No change (x_src).\n",
        "                  If strength=1 -> Full change (x_tgt).\n",
        "                  So we define weight_src = 1 - strength.\n",
        "    \"\"\"\n",
        "    # Define mixing weight\n",
        "    # strength=0 => weight_src=1.0 (Original)\n",
        "    # strength=1 => weight_src=0.0 (Full Target)\n",
        "    w_src = 1.0 - strength\n",
        "    w_tgt = strength\n",
        "\n",
        "    x_new = w_src * x_src + w_tgt * x_tgt\n",
        "    y_new = w_src * y_src + w_tgt * y_tgt\n",
        "\n",
        "    return x_new, y_new\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 13, Step 3: Implement Amplitude Mix and Demirel-Holz Mix\n",
        "# ------------------------------------------------------------------------------\n",
        "def op_amplitude_mix(\n",
        "    x_src: np.ndarray, y_src: float,\n",
        "    x_tgt: np.ndarray, y_tgt: float,\n",
        "    strength: float,\n",
        "    rng: np.random.Generator\n",
        ") -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Applies Amplitude Mix: Mixes Fourier amplitudes, preserves source phase.\n",
        "\n",
        "    Args:\n",
        "        strength: Controls ratio of target amplitude injected.\n",
        "                  strength=0 -> Original amplitude.\n",
        "                  strength=1 -> Target amplitude.\n",
        "    \"\"\"\n",
        "    # FFT along time axis (axis 0)\n",
        "    fft_src = np.fft.rfft(x_src, axis=0)\n",
        "    fft_tgt = np.fft.rfft(x_tgt, axis=0)\n",
        "\n",
        "    amp_src = np.abs(fft_src)\n",
        "    amp_tgt = np.abs(fft_tgt)\n",
        "    phase_src = np.angle(fft_src)\n",
        "\n",
        "    # Mix amplitudes\n",
        "    # strength=0 => amp_new = amp_src\n",
        "    w_src = 1.0 - strength\n",
        "    w_tgt = strength\n",
        "    amp_new = w_src * amp_src + w_tgt * amp_tgt\n",
        "\n",
        "    # Reconstruct complex spectrum using source phase\n",
        "    fft_new = amp_new * np.exp(1j * phase_src)\n",
        "\n",
        "    # Inverse FFT\n",
        "    x_new = np.fft.irfft(fft_new, n=x_src.shape[0], axis=0)\n",
        "\n",
        "    # Label mixing: Amplitude mix preserves temporal structure (phase) of source,\n",
        "    # but changes intensity. Label should likely stay close to source or mix slightly.\n",
        "    # We'll use linear mixing of labels as a heuristic proxy for \"energy\" change.\n",
        "    y_new = w_src * y_src + w_tgt * y_tgt\n",
        "\n",
        "    return x_new, y_new\n",
        "\n",
        "def op_demirel_holz_mix(\n",
        "    x_src: np.ndarray,\n",
        "    y_src: float,\n",
        "    x_tgt: np.ndarray,\n",
        "    y_tgt: float,\n",
        "    strength: float,\n",
        "    rng: np.random.Generator\n",
        ") -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Applies the Demirel-Holz Mix operation, which blends both the phases and magnitudes\n",
        "    of the source and target signals in the frequency domain.\n",
        "\n",
        "    This operation is interpreted as a linear interpolation of both the amplitude and\n",
        "    phase components of the Fourier transform, controlled by the manipulation strength parameter.\n",
        "    It allows for the synthesis of new time-series samples that combine the structural\n",
        "    (phase) and intensity (amplitude) characteristics of two different assets.\n",
        "\n",
        "    Equations:\n",
        "        A_{mix} = (1 - \\lambda) A_{src} + \\lambda A_{tgt}\n",
        "        \\phi_{mix} = (1 - \\lambda) \\phi_{src} + \\lambda \\phi_{tgt}\n",
        "        x_{new} = \\mathcal{F}^{-1}(A_{mix} \\cdot e^{i \\phi_{mix}})\n",
        "        y_{new} = (1 - \\lambda) y_{src} + \\lambda y_{tgt}\n",
        "\n",
        "    Args:\n",
        "        x_src (np.ndarray): The normalized source time-series window. Shape: (L, F).\n",
        "        y_src (float): The target value associated with the source window.\n",
        "        x_tgt (np.ndarray): The normalized target time-series window. Shape: (L, F).\n",
        "        y_tgt (float): The target value associated with the target window.\n",
        "        strength (float): The manipulation strength parameter \\lambda \\in [0, 1],\n",
        "                          determining the blending ratio.\n",
        "        rng (np.random.Generator): A random number generator (unused in this deterministic\n",
        "                                   interpolation but kept for interface consistency).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, float]:\n",
        "            - x_new (np.ndarray): The mixed time-series window in the time domain.\n",
        "            - y_new (float): The interpolated target label.\n",
        "    \"\"\"\n",
        "    # Compute Real FFT along the time axis (axis 0)\n",
        "    fft_src = np.fft.rfft(x_src, axis=0)\n",
        "    fft_tgt = np.fft.rfft(x_tgt, axis=0)\n",
        "\n",
        "    # Extract Amplitude and Phase\n",
        "    amp_src = np.abs(fft_src)\n",
        "    amp_tgt = np.abs(fft_tgt)\n",
        "    phase_src = np.angle(fft_src)\n",
        "    phase_tgt = np.angle(fft_tgt)\n",
        "\n",
        "    # Define mixing weights based on strength parameter\n",
        "    # strength=0 => Full Source, strength=1 => Full Target\n",
        "    w_src = 1.0 - strength\n",
        "    w_tgt = strength\n",
        "\n",
        "    # Mix Amplitudes linearly\n",
        "    amp_new = w_src * amp_src + w_tgt * amp_tgt\n",
        "\n",
        "    # Mix Phases linearly\n",
        "    # Note: Linear interpolation of phase is used as a proxy for \"mixing phases\".\n",
        "    # While phase wrapping can be an issue for large differences, this approach\n",
        "    # aligns with the \"blending ratio\" description for generating intermediate patterns.\n",
        "    phase_new = w_src * phase_src + w_tgt * phase_tgt\n",
        "\n",
        "    # Reconstruct the complex spectrum\n",
        "    fft_new = amp_new * np.exp(1j * phase_new)\n",
        "\n",
        "    # Inverse FFT to return to the time domain\n",
        "    # n=x_src.shape[0] ensures the output length matches the input length L\n",
        "    x_new = np.fft.irfft(fft_new, n=x_src.shape[0], axis=0)\n",
        "\n",
        "    # Mix labels linearly to reflect the blended signal content\n",
        "    y_new = w_src * y_src + w_tgt * y_tgt\n",
        "\n",
        "    return x_new, y_new\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 13, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "class MultiStockMixup:\n",
        "    \"\"\"\n",
        "    A registry and dispatcher for multi-stock mix-up operations used within the\n",
        "    Data Manipulation Module (M).\n",
        "\n",
        "    This class manages the selection and execution of mix-up techniques (CutMix,\n",
        "    LinearMix, AmplitudeMix, Demirel_Holz_Mix) that combine information from a\n",
        "    source asset and a target asset. It ensures consistent interface usage and\n",
        "    deterministic execution via seeded random number generation.\n",
        "\n",
        "    Attributes:\n",
        "        ops (Dict[str, Callable]): A mapping from operation names to their corresponding\n",
        "                                   implementation functions.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the mix-up registry with supported operations.\n",
        "        \"\"\"\n",
        "        self.ops: Dict[str, Callable[[np.ndarray, float, np.ndarray, float, float, np.random.Generator], Tuple[np.ndarray, float]]] = {\n",
        "            \"CutMix\": op_cut_mix,\n",
        "            \"LinearMix\": op_linear_mix,\n",
        "            \"AmplitudeMix\": op_amplitude_mix,\n",
        "            \"Demirel_Holz_Mix\": op_demirel_holz_mix\n",
        "        }\n",
        "\n",
        "    def apply(\n",
        "        self,\n",
        "        x_src: np.ndarray,\n",
        "        y_src: float,\n",
        "        x_tgt: np.ndarray,\n",
        "        y_tgt: float,\n",
        "        op_name: str,\n",
        "        strength: float,\n",
        "        seed: int\n",
        "    ) -> Tuple[np.ndarray, float]:\n",
        "        \"\"\"\n",
        "        Applies a named mix-up operation to combine a source and a target sample.\n",
        "\n",
        "        This method retrieves the requested operation from the registry and executes it\n",
        "        using a locally instantiated random number generator seeded with the provided value.\n",
        "        This ensures that the mix-up process is deterministic and reproducible, supporting\n",
        "        provenance-aware replay.\n",
        "\n",
        "        Args:\n",
        "            x_src (np.ndarray): The normalized source time-series window. Shape: (L, F).\n",
        "            y_src (float): The target value for the source sample.\n",
        "            x_tgt (np.ndarray): The normalized target time-series window. Shape: (L, F).\n",
        "            y_tgt (float): The target value for the target sample.\n",
        "            op_name (str): The name of the mix-up operation to apply (e.g., \"CutMix\").\n",
        "                           Must be a key in `self.ops`.\n",
        "            strength (float): The manipulation strength parameter \\lambda \\in [0, 1].\n",
        "            seed (int): An integer seed to initialize the local random number generator.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[np.ndarray, float]:\n",
        "                - x_new (np.ndarray): The resulting mixed time-series window.\n",
        "                - y_new (float): The resulting mixed target value.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If `op_name` is not found in the registry of supported operations.\n",
        "        \"\"\"\n",
        "        # Validate that the requested operation exists in the registry\n",
        "        if op_name not in self.ops:\n",
        "            raise ValueError(f\"Unknown mix-up operation: {op_name}. Supported operations: {list(self.ops.keys())}\")\n",
        "\n",
        "        # Create a local RNG for this operation to ensure determinism independent of global state\n",
        "        rng = np.random.Generator(np.random.PCG64(seed))\n",
        "\n",
        "        # Execute the operation\n",
        "        return self.ops[op_name](x_src, y_src, x_tgt, y_tgt, strength, rng)\n",
        "\n"
      ],
      "metadata": {
        "id": "oGRhLNzJBtWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 14 — Implement Algorithm 1: Mix-up Target Stock Sampling\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 14: Implement Algorithm 1: Mix-up Target Stock Sampling\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 14, Step 1: Define inputs, exclude self-pairs, and build candidate set\n",
        "# ------------------------------------------------------------------------------\n",
        "def get_candidates(\n",
        "    source_idx: int,\n",
        "    p_matrix: np.ndarray\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Identifies valid candidate target stocks for a given source stock.\n",
        "\n",
        "    Excludes the source stock itself and any targets with invalid (NaN) p-values.\n",
        "\n",
        "    Args:\n",
        "        source_idx (int): Index of the source stock.\n",
        "        p_matrix (np.ndarray): Cointegration p-value matrix of shape (S, S).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, np.ndarray]:\n",
        "            - candidate_indices: Array of integer indices for valid candidates.\n",
        "            - candidate_p_values: Array of corresponding p-values.\n",
        "    \"\"\"\n",
        "    # Extract row for source stock\n",
        "    row = p_matrix[source_idx].copy()\n",
        "\n",
        "    # Exclude self (set to NaN if not already)\n",
        "    row[source_idx] = np.nan\n",
        "\n",
        "    # Find valid indices\n",
        "    valid_mask = ~np.isnan(row)\n",
        "    candidate_indices = np.where(valid_mask)[0]\n",
        "    candidate_p_values = row[valid_mask]\n",
        "\n",
        "    return candidate_indices, candidate_p_values\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 14, Step 2: Compute lambda-dependent scores\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_scores(\n",
        "    p_values: np.ndarray,\n",
        "    strength: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes selection scores based on manipulation strength lambda.\n",
        "\n",
        "    Algorithm 1 Logic:\n",
        "    - If lambda <= 0.5: Favor stronger cointegration (lower p-value).\n",
        "      Score = -p^beta, where beta = 1 - lambda.\n",
        "      (Lower p -> Higher Score)\n",
        "    - If lambda > 0.5: Favor weaker cointegration (higher p-value).\n",
        "      Score = p^(1/beta), where beta = lambda.\n",
        "      (Higher p -> Higher Score)\n",
        "\n",
        "    Args:\n",
        "        p_values (np.ndarray): Array of candidate p-values.\n",
        "        strength (float): Manipulation strength lambda.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array of scores.\n",
        "    \"\"\"\n",
        "    if strength <= 0.5:\n",
        "        beta = 1.0 - strength\n",
        "        # Favor low p-values (strong cointegration)\n",
        "        # p is in [0, 1]. p^beta is in [0, 1].\n",
        "        # -p^beta is in [-1, 0]. Smaller p -> closer to 0 (larger score).\n",
        "        scores = -np.power(p_values, beta)\n",
        "    else:\n",
        "        beta = strength\n",
        "        # Favor high p-values (weak cointegration)\n",
        "        # p^(1/beta). Larger p -> Larger score.\n",
        "        scores = np.power(p_values, 1.0 / beta)\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 14, Step 3: Select top-k candidates and sample\n",
        "# ------------------------------------------------------------------------------\n",
        "def sample_target(\n",
        "    candidate_indices: np.ndarray,\n",
        "    scores: np.ndarray,\n",
        "    k: int,\n",
        "    rng: np.random.Generator\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Selects the target stock index using softmax sampling on the top-k scores.\n",
        "\n",
        "    Args:\n",
        "        candidate_indices (np.ndarray): Indices of candidates.\n",
        "        scores (np.ndarray): Corresponding scores.\n",
        "        k (int): Number of top candidates to consider.\n",
        "        rng (np.random.Generator): Random number generator.\n",
        "\n",
        "    Returns:\n",
        "        int: The selected target stock index.\n",
        "    \"\"\"\n",
        "    n_candidates = len(scores)\n",
        "\n",
        "    if n_candidates == 0:\n",
        "        raise ValueError(\"No candidates available for sampling.\")\n",
        "\n",
        "    # Select Top-K\n",
        "    # If fewer than k candidates, take all\n",
        "    effective_k = min(k, n_candidates)\n",
        "\n",
        "    # Get indices of top-k scores\n",
        "    # argpartition puts top k elements at the end (if sorting ascending)\n",
        "    # We want largest scores.\n",
        "    if effective_k < n_candidates:\n",
        "        # Partition such that the last k elements are the largest\n",
        "        top_k_partition_indices = np.argpartition(scores, -effective_k)[-effective_k:]\n",
        "    else:\n",
        "        top_k_partition_indices = np.arange(n_candidates)\n",
        "\n",
        "    top_k_scores = scores[top_k_partition_indices]\n",
        "    top_k_indices = candidate_indices[top_k_partition_indices]\n",
        "\n",
        "    # Softmax\n",
        "    # Shift for stability\n",
        "    shift_scores = top_k_scores - np.max(top_k_scores)\n",
        "    exp_scores = np.exp(shift_scores)\n",
        "    probs = exp_scores / np.sum(exp_scores)\n",
        "\n",
        "    # Sample\n",
        "    selected_idx = rng.choice(top_k_indices, p=probs)\n",
        "\n",
        "    return selected_idx\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 14, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def sample_mixup_target(\n",
        "    source_idx: int,\n",
        "    strength: float,\n",
        "    p_matrix: np.ndarray,\n",
        "    k: int,\n",
        "    seed: int\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Orchestrator for Algorithm 1: Mix-up Target Stock Sampling.\n",
        "\n",
        "    Executes:\n",
        "    1. Candidate identification.\n",
        "    2. Score computation based on lambda regime.\n",
        "    3. Top-k softmax sampling.\n",
        "\n",
        "    Args:\n",
        "        source_idx (int): Index of source stock.\n",
        "        strength (float): Lambda parameter.\n",
        "        p_matrix (np.ndarray): Cointegration p-values (S, S).\n",
        "        k (int): Number of candidates.\n",
        "        seed (int): Random seed.\n",
        "\n",
        "    Returns:\n",
        "        int: Target stock index. Returns source_idx if no valid targets exist (fallback).\n",
        "    \"\"\"\n",
        "    # 1. Candidates\n",
        "    cand_indices, cand_pvals = get_candidates(source_idx, p_matrix)\n",
        "\n",
        "    # Fallback if no candidates (e.g. isolated node or data issues)\n",
        "    if len(cand_indices) == 0:\n",
        "        # logger.warning(f\"No valid mix-up candidates for source {source_idx}. Fallback to self.\")\n",
        "        return source_idx\n",
        "\n",
        "    # 2. Scores\n",
        "    scores = compute_scores(cand_pvals, strength)\n",
        "\n",
        "    # 3. Sample\n",
        "    rng = np.random.Generator(np.random.PCG64(seed))\n",
        "    target_idx = sample_target(cand_indices, scores, k, rng)\n",
        "\n",
        "    return target_idx\n"
      ],
      "metadata": {
        "id": "eNmj0f3KDN1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 15 — Implement Algorithm 2: Binary Mix (Interpolation Compensation)\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 15: Implement Algorithm 2: Binary Mix (Interpolation Compensation)\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 15, Step 1: Define inputs and randomly select a feature k\n",
        "# ------------------------------------------------------------------------------\n",
        "def select_random_feature(\n",
        "    n_features: int,\n",
        "    rng: np.random.Generator\n",
        ") -> int:\n",
        "    \"\"\"\n",
        "    Randomly selects a feature index k for fast MI estimation.\n",
        "\n",
        "    Args:\n",
        "        n_features (int): Total number of features.\n",
        "        rng (np.random.Generator): Random number generator.\n",
        "\n",
        "    Returns:\n",
        "        int: Selected feature index.\n",
        "    \"\"\"\n",
        "    return rng.integers(0, n_features)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 15, Step 2: Compute mutual information and mixing factor\n",
        "# ------------------------------------------------------------------------------\n",
        "def estimate_mutual_information_histogram(\n",
        "    x: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    bins: int = 10\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Estimates Mutual Information I(X;Y) using histogram-based discretization.\n",
        "\n",
        "    I(X;Y) = sum p(x,y) * log(p(x,y) / (p(x)p(y)))\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): 1D array of samples from X.\n",
        "        y (np.ndarray): 1D array of samples from Y.\n",
        "        bins (int): Number of bins for discretization.\n",
        "\n",
        "    Returns:\n",
        "        float: Estimated mutual information (nats).\n",
        "    \"\"\"\n",
        "    # Compute 2D histogram\n",
        "    hist_2d, _, _ = np.histogram2d(x, y, bins=bins)\n",
        "\n",
        "    # Convert to probabilities\n",
        "    n_samples = np.sum(hist_2d)\n",
        "    if n_samples == 0:\n",
        "        return 0.0\n",
        "\n",
        "    p_xy = hist_2d / n_samples\n",
        "    p_x = np.sum(p_xy, axis=1)\n",
        "    p_y = np.sum(p_xy, axis=0)\n",
        "\n",
        "    # Compute MI\n",
        "    # Mask zeros to avoid log(0)\n",
        "    mask = p_xy > 0\n",
        "    p_xy_valid = p_xy[mask]\n",
        "\n",
        "    # We need p_x[i] * p_y[j] for each valid (i,j)\n",
        "    # Outer product p_x * p_y gives the joint distribution under independence\n",
        "    p_x_py = np.outer(p_x, p_y)\n",
        "    p_x_py_valid = p_x_py[mask]\n",
        "\n",
        "    mi = np.sum(p_xy_valid * np.log(p_xy_valid / p_x_py_valid))\n",
        "\n",
        "    return max(0.0, mi)\n",
        "\n",
        "\n",
        "def compute_mixing_factor(\n",
        "    x_feat: np.ndarray,\n",
        "    y_feat: np.ndarray,\n",
        "    b_max: float,\n",
        "    bins: int = 10\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Computes the mixing factor b_mix based on Mutual Information.\n",
        "\n",
        "    Equation:\n",
        "        b_mix = b_max - (MI_xy / MI_xx) * b_max\n",
        "\n",
        "    Args:\n",
        "        x_feat (np.ndarray): Feature vector from original data.\n",
        "        y_feat (np.ndarray): Feature vector from augmented data.\n",
        "        b_max (float): Maximum compensation factor.\n",
        "        bins (int): Bins for MI estimation.\n",
        "\n",
        "    Returns:\n",
        "        float: Mixing factor b_mix.\n",
        "    \"\"\"\n",
        "    # Baseline MI (Self-Information / Entropy)\n",
        "    mi_xx = estimate_mutual_information_histogram(x_feat, x_feat, bins)\n",
        "\n",
        "    # Cross MI\n",
        "    mi_xy = estimate_mutual_information_histogram(x_feat, y_feat, bins)\n",
        "\n",
        "    # Compute ratio\n",
        "    if mi_xx < 1e-8:\n",
        "        # If original has no entropy (constant), ratio is undefined.\n",
        "        ratio = 0.0\n",
        "    else:\n",
        "        ratio = mi_xy / mi_xx\n",
        "\n",
        "    # Compute b_mix\n",
        "    b_mix = b_max - ratio * b_max\n",
        "\n",
        "    # Clip to valid range [0, 1] (though b_max usually <= 1)\n",
        "    # Also ratio can be > 1 due to estimator noise? Unlikely for MI(X,Y) vs MI(X,X).\n",
        "    b_mix = np.clip(b_mix, 0.0, 1.0)\n",
        "\n",
        "    return b_mix\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 15, Step 3: Compute and return compensated data\n",
        "# ------------------------------------------------------------------------------\n",
        "def apply_compensation(\n",
        "    x: np.ndarray,\n",
        "    y: np.ndarray,\n",
        "    b_mix: float\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Applies linear interpolation compensation.\n",
        "\n",
        "    Equation:\n",
        "        x' = b_mix * x + (1 - b_mix) * y\n",
        "\n",
        "    Args:\n",
        "        x (np.ndarray): Original data.\n",
        "        y (np.ndarray): Augmented data.\n",
        "        b_mix (float): Mixing factor.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Compensated data.\n",
        "    \"\"\"\n",
        "    return b_mix * x + (1.0 - b_mix) * y\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 15, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def binary_mix_compensation(\n",
        "    x_orig: np.ndarray,\n",
        "    x_aug: np.ndarray,\n",
        "    b_max: float,\n",
        "    seed: int,\n",
        "    bins: int = 10\n",
        ") -> Tuple[np.ndarray, float]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Algorithm 2: Binary Mix.\n",
        "\n",
        "    Executes:\n",
        "    1. Random feature selection.\n",
        "    2. MI estimation and factor computation.\n",
        "    3. Compensation application.\n",
        "\n",
        "    Args:\n",
        "        x_orig (np.ndarray): Original sample window (L, F).\n",
        "        x_aug (np.ndarray): Augmented sample window (L, F).\n",
        "        b_max (float): Max compensation factor.\n",
        "        seed (int): Random seed.\n",
        "        bins (int): Histogram bins.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[np.ndarray, float]: Compensated sample and the calculated b_mix factor.\n",
        "    \"\"\"\n",
        "    L, F = x_orig.shape\n",
        "    rng = np.random.Generator(np.random.PCG64(seed))\n",
        "\n",
        "    # 1. Select Feature\n",
        "    k = select_random_feature(F, rng)\n",
        "\n",
        "    # Extract vectors\n",
        "    x_k = x_orig[:, k]\n",
        "    y_k = x_aug[:, k]\n",
        "\n",
        "    # 2. Compute Factor\n",
        "    b_mix = compute_mixing_factor(x_k, y_k, b_max, bins)\n",
        "\n",
        "    # 3. Apply\n",
        "    x_comp = apply_compensation(x_orig, x_aug, b_mix)\n",
        "\n",
        "    return x_comp, b_mix\n"
      ],
      "metadata": {
        "id": "4X55haVTFKwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 16 — Implement Algorithm 3: Proportion (\\alpha) Scheduler\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 16: Implement Algorithm 3: Proportion alpha Scheduler\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 16, Step 1: Define inputs and compute rate penalty\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_rate_penalty(\n",
        "    current_es: int,\n",
        "    last_es: int,\n",
        "    active_penalty: float = 0.1,\n",
        "    inactive_penalty: float = 1.0\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Computes the rate penalty R_penalty based on early stopping counter progression.\n",
        "\n",
        "    Logic:\n",
        "    - If current_es > last_es: The model is stagnating/overfitting (validation loss not improving).\n",
        "      We \"remove\" the penalty to allow more augmentation (introduce diversity).\n",
        "      R_penalty = 1.0 (inactive_penalty).\n",
        "    - Otherwise: The model is improving. We apply the penalty to keep augmentation low.\n",
        "      R_penalty = 0.1 (active_penalty).\n",
        "\n",
        "    Args:\n",
        "        current_es (int): Current early stopping counter (epochs since last improvement).\n",
        "        last_es (int): Early stopping counter at the previous check.\n",
        "        active_penalty (float): Factor when penalty is applied (default 0.1).\n",
        "        inactive_penalty (float): Factor when penalty is removed (default 1.0).\n",
        "\n",
        "    Returns:\n",
        "        float: The rate penalty factor.\n",
        "    \"\"\"\n",
        "    if current_es > last_es:\n",
        "        # Stagnation detected -> Increase augmentation -> Remove penalty\n",
        "        return inactive_penalty\n",
        "    else:\n",
        "        # Improving -> Restrict augmentation -> Apply penalty\n",
        "        return active_penalty\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 16, Step 2: Update last counter\n",
        "# ------------------------------------------------------------------------------\n",
        "def update_last_counter(current_es: int) -> int:\n",
        "    \"\"\"\n",
        "    Updates the last early stopping counter for the next iteration.\n",
        "\n",
        "    Equation:\n",
        "        C_les := C_es\n",
        "\n",
        "    Args:\n",
        "        current_es (int): Current early stopping counter.\n",
        "\n",
        "    Returns:\n",
        "        int: The updated last_es value.\n",
        "    \"\"\"\n",
        "    return current_es\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 16, Step 3: Compute and return alpha\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_alpha(\n",
        "    epoch: int,\n",
        "    tau: float,\n",
        "    rate_penalty: float\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Computes the proportion of data to be manipulated (alpha).\n",
        "\n",
        "    Equation:\n",
        "        alpha = min(tanh(E / tau) + 0.01, 1.0) * R_penalty\n",
        "\n",
        "    Args:\n",
        "        epoch (int): Current training epoch E.\n",
        "        tau (float): Temperature parameter controlling curriculum speed.\n",
        "        rate_penalty (float): The computed rate penalty factor.\n",
        "\n",
        "    Returns:\n",
        "        float: The calculated alpha value, bounded in [0, 1].\n",
        "    \"\"\"\n",
        "    # Pacing function\n",
        "    # Note: If epoch starts at 0, tanh(0) = 0. Base alpha = 0.01 * R.\n",
        "    pacing = math.tanh(epoch / tau) + 0.01\n",
        "\n",
        "    # Clip pacing to 1.0 before penalty\n",
        "    pacing_clipped = min(pacing, 1.0)\n",
        "\n",
        "    # Apply penalty\n",
        "    alpha = pacing_clipped * rate_penalty\n",
        "\n",
        "    return alpha\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 16, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def scheduler_step(\n",
        "    epoch: int,\n",
        "    tau: float,\n",
        "    current_es: int,\n",
        "    last_es: int,\n",
        "    config: Dict[str, Any]\n",
        ") -> Tuple[float, int]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Algorithm 3: Proportion alpha Scheduler.\n",
        "\n",
        "    Executes:\n",
        "    1. Rate penalty calculation.\n",
        "    2. Alpha computation.\n",
        "    3. State update (last_es).\n",
        "\n",
        "    Args:\n",
        "        epoch (int): Current epoch.\n",
        "        tau (float): Model-specific tau.\n",
        "        current_es (int): Current early stopping counter.\n",
        "        last_es (int): Previous early stopping counter.\n",
        "        config (Dict[str, Any]): Scheduler configuration (penalties).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[float, int]: (alpha, new_last_es)\n",
        "    \"\"\"\n",
        "    # Extract config\n",
        "    active_p = config.get(\"rate_penalty_active\", 0.1)\n",
        "    inactive_p = config.get(\"rate_penalty_inactive\", 1.0)\n",
        "\n",
        "    # 1. Penalty\n",
        "    r_penalty = compute_rate_penalty(current_es, last_es, active_p, inactive_p)\n",
        "\n",
        "    # 2. Alpha\n",
        "    alpha = compute_alpha(epoch, tau, r_penalty)\n",
        "\n",
        "    # 3. Update State\n",
        "    new_last_es = update_last_counter(current_es)\n",
        "\n",
        "    return alpha, new_last_es\n"
      ],
      "metadata": {
        "id": "hwBfRB8zGY3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 17 — Implement Algorithm 4: Joint Training Scheme\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 17: Implement Algorithm 4: Joint Training Scheme\n",
        "# ==============================================================================\n",
        "\n",
        "@dataclass\n",
        "class TrainingState:\n",
        "    \"\"\"\n",
        "    Encapsulates the dynamic state of the joint training process to ensure\n",
        "    persistence, reproducibility, and correct execution of the adaptive curriculum.\n",
        "\n",
        "    This dataclass maintains the counters and metrics required by the Scheduler (Algorithm 3)\n",
        "    and the Joint Training Scheme (Algorithm 4), including epoch tracking, global step counts,\n",
        "    and early stopping logic based on validation loss.\n",
        "\n",
        "    Attributes:\n",
        "        epoch (int): Current training epoch (0-indexed).\n",
        "        global_step (int): Total number of batches processed across all epochs.\n",
        "        early_stopping_counter (int): Number of consecutive epochs without validation loss improvement.\n",
        "                                      Used to trigger early stopping and calculate the rate penalty.\n",
        "        last_early_stopping_counter (int): The value of the early stopping counter at the previous check.\n",
        "                                           Used by the Scheduler to determine if the model is stagnating.\n",
        "        best_val_loss (float): The lowest validation loss observed so far. Initialized to infinity.\n",
        "        history (Dict[str, List[float]]): A dictionary storing the history of 'train_loss' and 'val_loss'\n",
        "                                          for visualization and analysis.\n",
        "    \"\"\"\n",
        "    epoch: int = 0\n",
        "    global_step: int = 0\n",
        "    early_stopping_counter: int = 0\n",
        "    last_early_stopping_counter: int = 0\n",
        "    best_val_loss: float = float('inf')\n",
        "    history: Dict[str, List[float]] = field(default_factory=lambda: {\"train_loss\": [], \"val_loss\": []})\n",
        "\n",
        "    def update_early_stopping(self, current_val_loss: float, patience: int, threshold: float) -> bool:\n",
        "        \"\"\"\n",
        "        Updates the early stopping counter based on the current validation performance.\n",
        "\n",
        "        This method checks if the current validation loss has improved upon the best observed loss\n",
        "        by at least the specified threshold. If so, it resets the counter; otherwise, it increments it.\n",
        "        It returns a boolean indicating whether the patience limit has been exceeded.\n",
        "\n",
        "        Args:\n",
        "            current_val_loss (float): The validation loss for the current epoch.\n",
        "            patience (int): The number of epochs to wait for improvement before stopping.\n",
        "            threshold (float): The minimum improvement required to consider the loss as \"better\".\n",
        "\n",
        "        Returns:\n",
        "            bool: True if the early stopping criteria are met (counter >= patience), False otherwise.\n",
        "        \"\"\"\n",
        "        if current_val_loss < self.best_val_loss - threshold:\n",
        "            self.best_val_loss = current_val_loss\n",
        "            self.early_stopping_counter = 0\n",
        "        else:\n",
        "            self.early_stopping_counter += 1\n",
        "\n",
        "        return self.early_stopping_counter >= patience\n",
        "\n",
        "class StraightThroughEstimator(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    Implements the Straight-Through Estimator (STE) for passing gradients\n",
        "    through non-differentiable augmentation operations with respect to the\n",
        "    manipulation strength parameter lambda.\n",
        "\n",
        "    In the bi-level optimization framework, the planner outputs a manipulation strength lambda.\n",
        "    However, the data manipulation module M(x) involves non-differentiable operations (e.g., selection).\n",
        "    To allow gradients to flow from the validation loss back to the planner's lambda output,\n",
        "    we use the STE assumption: dM(x)/dlambda = 1.\n",
        "\n",
        "    Forward Pass:\n",
        "        Returns the transformed data x_aug as computed by the manipulation module.\n",
        "\n",
        "    Backward Pass:\n",
        "        Passes the gradient from the output (x_aug) directly to the input parameter (lambda),\n",
        "        effectively treating the manipulation as an identity function for the purpose of\n",
        "        gradient flow w.r.t lambda.\n",
        "\n",
        "    Equation:\n",
        "        \\frac{\\partial \\mathcal{L}}{\\partial \\lambda} \\approx \\frac{\\partial \\mathcal{L}}{\\partial M(x)} \\cdot 1\n",
        "    \"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, x_aug: torch.Tensor, lambda_val: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass of the STE. Returns the augmented data unchanged.\n",
        "\n",
        "        Args:\n",
        "            ctx: Context object to save tensors (unused here).\n",
        "            x_aug (torch.Tensor): The augmented data tensor.\n",
        "            lambda_val (torch.Tensor): The manipulation strength parameter.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The input x_aug.\n",
        "        \"\"\"\n",
        "        return x_aug\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Backward pass of the STE.\n",
        "\n",
        "        Args:\n",
        "            ctx: Context object.\n",
        "            grad_output (torch.Tensor): Gradient of the loss w.r.t the output (x_aug).\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]:\n",
        "                - Gradient w.r.t x_aug (passed through as identity).\n",
        "                - Gradient w.r.t lambda_val (sum of grad_output, implementing the STE assumption).\n",
        "        \"\"\"\n",
        "        # Gradient w.r.t x_aug is passed through (identity)\n",
        "        grad_x_aug = grad_output\n",
        "\n",
        "        # Gradient w.r.t lambda_val is the sum of gradients flowing through the augmented data\n",
        "        # We sum over all dimensions of x_aug to produce a scalar gradient for the scalar lambda\n",
        "        # (or tensor gradient if lambda is a tensor, broadcasting handles it)\n",
        "        grad_lambda = grad_output.sum()\n",
        "\n",
        "        return grad_x_aug, grad_lambda\n",
        "\n",
        "def apply_ste(x_aug: torch.Tensor, lambda_val: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Applies the Straight-Through Estimator to the augmented data and lambda parameter.\n",
        "\n",
        "    This helper function wraps the custom autograd function for cleaner usage in the\n",
        "    training loop.\n",
        "\n",
        "    Args:\n",
        "        x_aug (torch.Tensor): The augmented data tensor.\n",
        "        lambda_val (torch.Tensor): The manipulation strength parameter.\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: The augmented data tensor, with the computational graph attached\n",
        "                      such that gradients flow back to lambda_val via STE.\n",
        "    \"\"\"\n",
        "    return StraightThroughEstimator.apply(x_aug, lambda_val)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 17, Step 1: Initialize models and training-state\n",
        "# ------------------------------------------------------------------------------\n",
        "def initialize_training(\n",
        "    task_model: nn.Module,\n",
        "    planner_model: nn.Module,\n",
        "    task_lr: float,\n",
        "    planner_lr: float\n",
        ") -> Tuple[optim.Optimizer, optim.Optimizer, TrainingState]:\n",
        "    \"\"\"\n",
        "    Initializes the optimizers for the Task Model and Planner, and creates the\n",
        "    initial TrainingState.\n",
        "\n",
        "    Args:\n",
        "        task_model (nn.Module): The forecasting model f_theta.\n",
        "        planner_model (nn.Module): The policy network g_phi.\n",
        "        task_lr (float): Learning rate for the task model.\n",
        "        planner_lr (float): Learning rate for the planner.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[optim.Optimizer, optim.Optimizer, TrainingState]:\n",
        "            Initialized task optimizer, planner optimizer, and training state.\n",
        "    \"\"\"\n",
        "    # Task Model Optimizer (Theta)\n",
        "    task_optimizer = optim.Adam(task_model.parameters(), lr=task_lr)\n",
        "\n",
        "    # Planner Optimizer (Phi)\n",
        "    planner_optimizer = optim.Adam(planner_model.parameters(), lr=planner_lr)\n",
        "\n",
        "    # Initial State\n",
        "    state = TrainingState()\n",
        "\n",
        "    return task_optimizer, planner_optimizer, state\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 17, Step 2: Inner loop: task model update\n",
        "# ------------------------------------------------------------------------------\n",
        "def inner_loop_step(\n",
        "    task_model: nn.Module,\n",
        "    planner_model: nn.Module,\n",
        "    task_optimizer: optim.Optimizer,\n",
        "    x_batch: torch.Tensor,\n",
        "    y_batch: torch.Tensor,\n",
        "    alpha: float,\n",
        "    manipulation_fn: Callable,\n",
        "    criterion: nn.Module\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Executes the inner loop step: updating the Task Model parameters theta.\n",
        "\n",
        "    Process:\n",
        "    1. Planner Inference: Get p and lambda based on current model state and data.\n",
        "    2. Data Manipulation: Apply M(alpha, p, lambda, x) to generate x_tilde.\n",
        "    3. Optimization: Update theta to minimize L_train(f_theta(x_tilde), y).\n",
        "\n",
        "    Args:\n",
        "        task_model (nn.Module): f_theta.\n",
        "        planner_model (nn.Module): g_phi.\n",
        "        task_optimizer (optim.Optimizer): Optimizer for theta.\n",
        "        x_batch (torch.Tensor): Input features (B, L, F).\n",
        "        y_batch (torch.Tensor): Targets (B,).\n",
        "        alpha (float): Proportion of data to manipulate.\n",
        "        manipulation_fn (Callable): Function applying the augmentation pipeline.\n",
        "        criterion (nn.Module): Loss function (e.g., MSELoss).\n",
        "\n",
        "    Returns:\n",
        "        float: The training loss value.\n",
        "    \"\"\"\n",
        "    task_model.train()\n",
        "    planner_model.eval() # Planner is fixed during inner loop\n",
        "\n",
        "    # 1. Planner Inference\n",
        "    # We detach to ensure no gradients flow to planner in this step\n",
        "    with torch.no_grad():\n",
        "        # Extract embedding from task model (Task 18 interface)\n",
        "        # Assuming task_model has extract_embedding method\n",
        "        model_embedding = task_model.extract_embedding(x_batch)\n",
        "\n",
        "        # Get policy from planner\n",
        "        # planner_model forward expects (model_embedding, x_batch)\n",
        "        p_matrix, lambda_matrix = planner_model(model_embedding, x_batch)\n",
        "\n",
        "    # 2. Data Manipulation\n",
        "    # Apply M(alpha, p, lambda, x)\n",
        "    # manipulation_fn handles the stochastic application based on alpha\n",
        "    # We assume manipulation_fn returns tensors on the correct device\n",
        "    x_aug, y_aug = manipulation_fn(x_batch, y_batch, alpha, p_matrix, lambda_matrix)\n",
        "\n",
        "    # 3. Task Model Update\n",
        "    task_optimizer.zero_grad()\n",
        "    predictions = task_model(x_aug)\n",
        "    loss = criterion(predictions.squeeze(), y_aug)\n",
        "    loss.backward()\n",
        "    task_optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 17, Step 3: Outer loop: planner update\n",
        "# ------------------------------------------------------------------------------\n",
        "def outer_loop_step(\n",
        "    task_model: nn.Module,\n",
        "    planner_model: nn.Module,\n",
        "    planner_optimizer: optim.Optimizer,\n",
        "    x_train_batch: torch.Tensor,\n",
        "    y_train_batch: torch.Tensor,\n",
        "    x_val_batch: torch.Tensor,\n",
        "    y_val_batch: torch.Tensor,\n",
        "    weighted_manipulation_fn: Callable,\n",
        "    criterion: nn.Module\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Executes the outer loop step: updating the Planner parameters phi.\n",
        "\n",
        "    Process:\n",
        "    1. Generate Weighted Mixture: x_weighted using all ops weighted by p.\n",
        "    2. Lookahead Update: Compute theta' = theta - lr * grad(L_train(theta, x_weighted)).\n",
        "    3. Validation: Compute L_val(f_theta'(x_val), y_val).\n",
        "    4. Optimization: Update phi to minimize L_val.\n",
        "\n",
        "    Args:\n",
        "        task_model (nn.Module): Current f_theta.\n",
        "        planner_model (nn.Module): g_phi.\n",
        "        planner_optimizer (optim.Optimizer): Optimizer for phi.\n",
        "        x_train_batch (torch.Tensor): Training batch for lookahead.\n",
        "        y_train_batch (torch.Tensor): Training targets.\n",
        "        x_val_batch (torch.Tensor): Validation batch for evaluation.\n",
        "        y_val_batch (torch.Tensor): Validation targets.\n",
        "        weighted_manipulation_fn (Callable): Function applying weighted mixture.\n",
        "        criterion (nn.Module): Loss function.\n",
        "\n",
        "    Returns:\n",
        "        float: The validation loss on the lookahead model.\n",
        "    \"\"\"\n",
        "    planner_model.train()\n",
        "    task_model.train() # We need gradients through task model structure\n",
        "\n",
        "    # 1. Planner Inference (with gradients enabled for phi)\n",
        "    model_embedding = task_model.extract_embedding(x_train_batch).detach() # Embedding of current theta\n",
        "    p_matrix, lambda_matrix = planner_model(model_embedding, x_train_batch)\n",
        "\n",
        "    # 2. Generate Weighted Mixture\n",
        "    # This function must be differentiable w.r.t p and lambda\n",
        "    # It should use the Straight-Through Estimator for lambda\n",
        "    x_weighted, y_weighted = weighted_manipulation_fn(x_train_batch, y_train_batch, p_matrix, lambda_matrix)\n",
        "\n",
        "    # 3. Compute Lookahead Update (Unrolled SGD Step)\n",
        "    # Predict on weighted data\n",
        "    pred_train = task_model(x_weighted)\n",
        "    loss_train = criterion(pred_train.squeeze(), y_weighted)\n",
        "\n",
        "    # Compute gradients w.r.t theta\n",
        "    # create_graph=True is essential to backpropagate through this gradient step later\n",
        "    params = dict(task_model.named_parameters())\n",
        "    grads = torch.autograd.grad(loss_train, params.values(), create_graph=True)\n",
        "\n",
        "    # Manual update to create theta_prime\n",
        "    # theta' = theta - lr * grad\n",
        "    # We assume SGD-like update for the lookahead step\n",
        "    lr = task_model.learning_rate if hasattr(task_model, 'learning_rate') else 0.001\n",
        "    updated_params = {\n",
        "        name: param - lr * grad\n",
        "        for (name, param), grad in zip(params.items(), grads)\n",
        "    }\n",
        "\n",
        "    # 4. Validation on Lookahead Model\n",
        "    # We need to evaluate task_model using updated_params\n",
        "    # Since standard nn.Module doesn't support functional calls easily,\n",
        "    # we assume task_model implements a `functional_forward` method (Task 18 requirement).\n",
        "    pred_val = task_model.functional_forward(x_val_batch, updated_params)\n",
        "    loss_val = criterion(pred_val.squeeze(), y_val_batch)\n",
        "\n",
        "    # 5. Update Planner\n",
        "    planner_optimizer.zero_grad()\n",
        "    loss_val.backward()\n",
        "    planner_optimizer.step()\n",
        "\n",
        "    return loss_val.item()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 17, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def joint_training_orchestrator(\n",
        "    task_model: nn.Module,\n",
        "    planner_model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: DataLoader,\n",
        "    study_config: Dict[str, Any],\n",
        "    manipulation_wrappers: Tuple[Callable, Callable],\n",
        "    scheduler_step_fn: Callable\n",
        ") -> Tuple[nn.Module, nn.Module, Dict[str, List[float]]]:\n",
        "    \"\"\"\n",
        "    Orchestrates the end-to-end joint training process (Algorithm 4).\n",
        "\n",
        "    Args:\n",
        "        task_model (nn.Module): Initialized task model.\n",
        "        planner_model (nn.Module): Initialized planner model.\n",
        "        train_loader (DataLoader): Training data loader.\n",
        "        val_loader (DataLoader): Validation data loader.\n",
        "        study_config (Dict[str, Any]): Configuration dictionary.\n",
        "        manipulation_wrappers (Tuple[Callable, Callable]):\n",
        "            (inner_loop_manipulation_fn, outer_loop_weighted_fn).\n",
        "        scheduler_step_fn (Callable): Function to compute alpha (Task 16).\n",
        "\n",
        "    Returns:\n",
        "        Tuple[nn.Module, nn.Module, Dict[str, List[float]]]:\n",
        "            Trained task model, trained planner, and loss history.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Joint Training Orchestrator...\")\n",
        "\n",
        "    # Extract Configuration\n",
        "    model_name = task_model.__class__.__name__\n",
        "\n",
        "    # Handle potential config key mismatch if model class name differs from config key\n",
        "    # Fallback to a known key if needed, but assuming strict mapping for now.\n",
        "    planner_cfg = study_config[\"planner\"].get(model_name, study_config[\"planner\"].get(\"GRU\")) # Fallback for safety\n",
        "    scheduler_cfg = study_config[\"scheduler\"]\n",
        "\n",
        "    freq = planner_cfg[\"update_freq\"]\n",
        "    start_epoch = planner_cfg[\"start_epoch\"]\n",
        "    tau = scheduler_cfg[\"tau\"].get(model_name, 5) # Default tau\n",
        "\n",
        "    # Initialize Optimizers and State\n",
        "    task_opt, planner_opt, state = initialize_training(\n",
        "        task_model, planner_model,\n",
        "        study_config[\"task_models\"][\"common\"][\"learning_rate\"],\n",
        "        study_config[\"planner\"][\"learning_rate\"]\n",
        "    )\n",
        "\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Training Loop\n",
        "    # Max epochs not specified in excerpt, assuming standard convergence or config\n",
        "    max_epochs = 100\n",
        "\n",
        "    # Validation iterator for outer loop sampling\n",
        "    val_iter = iter(val_loader)\n",
        "\n",
        "    for epoch in range(max_epochs):\n",
        "        state.epoch = epoch\n",
        "\n",
        "        # 1. Scheduler Step (Alpha)\n",
        "        # We need current_es and last_es from state\n",
        "        alpha, new_last_es = scheduler_step_fn(\n",
        "            epoch, tau,\n",
        "            state.early_stopping_counter,\n",
        "            state.last_early_stopping_counter,\n",
        "            scheduler_cfg\n",
        "        )\n",
        "        state.last_early_stopping_counter = new_last_es\n",
        "\n",
        "        epoch_train_loss = 0.0\n",
        "\n",
        "        # 2. Batch Loop\n",
        "        for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "            state.global_step += 1\n",
        "\n",
        "            # Move to device\n",
        "            device = next(task_model.parameters()).device\n",
        "            x_batch = x_batch.to(device)\n",
        "            y_batch = y_batch.to(device)\n",
        "\n",
        "            # Inner Loop Step\n",
        "            loss = inner_loop_step(\n",
        "                task_model, planner_model, task_opt,\n",
        "                x_batch, y_batch, alpha,\n",
        "                manipulation_wrappers[0], criterion\n",
        "            )\n",
        "            epoch_train_loss += loss\n",
        "\n",
        "            # Outer Loop Step (Conditional)\n",
        "            if state.global_step % freq == 0 and epoch >= start_epoch:\n",
        "                # Sample validation batch\n",
        "                try:\n",
        "                    x_val, y_val = next(val_iter)\n",
        "                except StopIteration:\n",
        "                    val_iter = iter(val_loader)\n",
        "                    x_val, y_val = next(val_iter)\n",
        "\n",
        "                x_val = x_val.to(device)\n",
        "                y_val = y_val.to(device)\n",
        "\n",
        "                outer_loop_step(\n",
        "                    task_model, planner_model, planner_opt,\n",
        "                    x_batch, y_batch, x_val, y_val,\n",
        "                    manipulation_wrappers[1], criterion\n",
        "                )\n",
        "\n",
        "        # 3. Validation Phase\n",
        "        task_model.eval()\n",
        "        epoch_val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for x_v, y_v in val_loader:\n",
        "                x_v, y_v = x_v.to(device), y_v.to(device)\n",
        "                pred = task_model(x_v)\n",
        "                epoch_val_loss += criterion(pred.squeeze(), y_v).item()\n",
        "\n",
        "        epoch_val_loss /= len(val_loader)\n",
        "        epoch_train_loss /= len(train_loader)\n",
        "\n",
        "        # Update History\n",
        "        state.history[\"train_loss\"].append(epoch_train_loss)\n",
        "        state.history[\"val_loss\"].append(epoch_val_loss)\n",
        "\n",
        "        logger.info(f\"Epoch {epoch}: Train Loss {epoch_train_loss:.6f}, Val Loss {epoch_val_loss:.6f}, Alpha {alpha:.4f}\")\n",
        "\n",
        "        # 4. Early Stopping Check\n",
        "        # Patience is model specific, usually 5 or 8\n",
        "        patience = study_config[\"task_models\"].get(model_name, {}).get(\"patience\", 5)\n",
        "        threshold = scheduler_cfg[\"early_stopping\"][\"improvement_threshold\"]\n",
        "\n",
        "        if state.update_early_stopping(epoch_val_loss, patience, threshold):\n",
        "            logger.info(f\"Early stopping triggered at epoch {epoch}.\")\n",
        "            break\n",
        "\n",
        "    logger.info(\"Joint Training Completed.\")\n",
        "\n",
        "    return task_model, planner_model, state.history\n"
      ],
      "metadata": {
        "id": "NDnyse50Hr_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 18 — Implement the required task model modular interface\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 18: Implement the required task model modular interface (j(.) and k(.))\n",
        "# ==============================================================================\n",
        "\n",
        "class ModularTaskModel(nn.Module, ABC):\n",
        "    \"\"\"\n",
        "    Abstract Base Class defining the modular interface required for the\n",
        "    Adaptive Dataflow System's task models.\n",
        "\n",
        "    This class enforces a strict architectural separation between the feature extraction\n",
        "    component j(.) and the prediction head k(.), as mandated by the manuscript. This\n",
        "    separation is critical for two reasons:\n",
        "    1. It allows the extraction of the penultimate embedding h, which serves as the\n",
        "       state input for the Planner (g_phi).\n",
        "    2. It facilitates functional (stateless) forward passes, which are required for the\n",
        "       'lookahead' update step in the bi-level optimization outer loop.\n",
        "\n",
        "    Architecture Pattern:\n",
        "        x -> [Encoder j_base] -> representation -> [Head j_head] -> embedding (h) -> [Predictor k] -> output\n",
        "\n",
        "    Attributes:\n",
        "        output_dim (int): The dimension of the final prediction output (e.g., 1 for forecasting).\n",
        "        embedding_dim (int): The dimension of the penultimate embedding vector h.\n",
        "                             Fixed at 128 in the manuscript for Planner compatibility.\n",
        "        j_head (nn.Sequential): The fully connected layers mapping encoder output to embedding h.\n",
        "        k_predictor (nn.Linear): The final linear layer mapping embedding h to the output.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_dim: int = 1, embedding_dim: int = 128) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the ModularTaskModel base class.\n",
        "\n",
        "        Args:\n",
        "            output_dim (int): Dimension of the prediction target. Default is 1 (next-step return).\n",
        "            embedding_dim (int): Dimension of the latent embedding h. Default is 128.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.output_dim = output_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        # Layers are initialized in build_head() after the subclass defines the encoder dim.\n",
        "        self.j_head: Optional[nn.Sequential] = None\n",
        "        self.k_predictor: Optional[nn.Linear] = None\n",
        "\n",
        "    @abstractmethod\n",
        "    def get_encoder_output_dim(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the dimension of the representation output by the base encoder.\n",
        "\n",
        "        This method must be implemented by subclasses (e.g., GRU, LSTM) to inform\n",
        "        the construction of the j_head layers.\n",
        "\n",
        "        Returns:\n",
        "            int: The size of the feature vector produced by forward_encoder.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward_encoder(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes the base encoder (e.g., GRU, LSTM, Transformer backbone).\n",
        "\n",
        "        This method encapsulates the model-specific sequence processing logic.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Latent representation tensor of shape (Batch, encoder_dim).\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def build_head(self) -> None:\n",
        "        \"\"\"\n",
        "        Constructs the standard 2-layer MLP head required for embedding extraction.\n",
        "\n",
        "        This method initializes the `j_head` and `k_predictor` modules. It must be called\n",
        "        by the subclass `__init__` after the encoder is defined.\n",
        "\n",
        "        Structure:\n",
        "            Representation -> FC1 -> Activation -> Embedding (h) -> FC2 -> Output\n",
        "\n",
        "        This ensures that `extract_embedding` always returns a vector of size `embedding_dim`.\n",
        "        \"\"\"\n",
        "        encoder_dim = self.get_encoder_output_dim()\n",
        "\n",
        "        # j_head: Maps encoder output to embedding (h)\n",
        "        # Corresponds to the first part of the prediction head\n",
        "        self.j_head = nn.Sequential(\n",
        "            nn.Linear(encoder_dim, self.embedding_dim),\n",
        "            nn.ReLU(),\n",
        "            # Optional: Dropout or LayerNorm could be added here if specified by config\n",
        "        )\n",
        "\n",
        "        # k: Maps embedding (h) to output\n",
        "        # Corresponds to the final prediction layer\n",
        "        self.k_predictor = nn.Linear(self.embedding_dim, self.output_dim)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Standard forward pass: y = k(j(x)).\n",
        "\n",
        "        This method chains the encoder, the embedding head, and the predictor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The model prediction.\n",
        "        \"\"\"\n",
        "        if self.j_head is None or self.k_predictor is None:\n",
        "            raise RuntimeError(\"Model head not initialized. Call build_head() in __init__.\")\n",
        "\n",
        "        # j(x) part 1: Encoder\n",
        "        rep = self.forward_encoder(x)\n",
        "\n",
        "        # j(x) part 2: Head to embedding\n",
        "        h = self.j_head(rep)\n",
        "\n",
        "        # k(h): Prediction\n",
        "        return self.k_predictor(h)\n",
        "\n",
        "    def extract_embedding(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Extracts the penultimate embedding h for the Planner.\n",
        "\n",
        "        This method executes the forward pass up to the second-to-last layer,\n",
        "        returning the state vector required by the Planner to condition its policy.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Embedding vector h of shape (Batch, embedding_dim).\n",
        "        \"\"\"\n",
        "        if self.j_head is None:\n",
        "            raise RuntimeError(\"Model head not initialized.\")\n",
        "\n",
        "        # Encode\n",
        "        rep = self.forward_encoder(x)\n",
        "\n",
        "        h = self.j_head(rep)\n",
        "\n",
        "        return h\n",
        "\n",
        "    def functional_forward(self, x: torch.Tensor, params: Dict[str, torch.Tensor]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes a forward pass using externally provided parameters (stateless execution).\n",
        "\n",
        "        This method is critical for the 'lookahead' update in the bi-level optimization outer loop.\n",
        "        It allows evaluating the model using a set of updated weights (theta_prime) without\n",
        "        modifying the model's internal state, preserving the computational graph for meta-learning.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor.\n",
        "            params (Dict[str, torch.Tensor]): Dictionary mapping parameter names to tensors.\n",
        "                                              These weights replace the model's internal weights\n",
        "                                              for this specific call.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Model output computed using the provided parameters.\n",
        "\n",
        "        Raises:\n",
        "            NotImplementedError: If the environment does not support torch.func (PyTorch < 2.0).\n",
        "        \"\"\"\n",
        "        # Use torch.func.functional_call (available in PyTorch 2.0+)\n",
        "        # This allows efficient stateless evaluation without manual layer rewriting.\n",
        "        if hasattr(torch.func, \"functional_call\"):\n",
        "            return torch.func.functional_call(self, params, (x,))\n",
        "        else:\n",
        "            # Fallback for older PyTorch versions is not implemented to ensure high-performance standards.\n",
        "            # Production environment is assumed to be modern (H100s imply recent software stack).\n",
        "            raise NotImplementedError(\"PyTorch 2.0+ with torch.func is required for functional_forward.\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 18, Orchestrator Function (Example Usage / Factory)\n",
        "# ------------------------------------------------------------------------------\n",
        "def create_modular_head(encoder_dim: int, embedding_dim: int = 128, output_dim: int = 1) -> Tuple[nn.Module, nn.Module]:\n",
        "    \"\"\"\n",
        "    Helper to create the j_head and k_predictor layers if manually assembling.\n",
        "\n",
        "    Args:\n",
        "        encoder_dim (int): Input dimension from encoder.\n",
        "        embedding_dim (int): Dimension of the penultimate embedding.\n",
        "        output_dim (int): Dimension of the final output.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[nn.Module, nn.Module]: (j_head, k_predictor)\n",
        "    \"\"\"\n",
        "    # Create head\n",
        "    j_head = nn.Sequential(\n",
        "        nn.Linear(encoder_dim, embedding_dim),\n",
        "        nn.ReLU()\n",
        "    )\n",
        "\n",
        "    # Create predictor\n",
        "    k_predictor = nn.Linear(embedding_dim, output_dim)\n",
        "    return j_head, k_predictor\n"
      ],
      "metadata": {
        "id": "etR-cWZhJUcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 19 — Implement GRU forecasting model\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 19: Implement GRU forecasting model\n",
        "# ==============================================================================\n",
        "\n",
        "class GRUForecaster(ModularTaskModel):\n",
        "    \"\"\"\n",
        "    GRU-based forecasting model implementing the ModularTaskModel interface.\n",
        "\n",
        "    This model uses a Gated Recurrent Unit (GRU) encoder to process the time-series\n",
        "    window, followed by the standard 2-layer MLP head for embedding extraction and prediction.\n",
        "\n",
        "    Hyperparameters (from Manuscript/Config):\n",
        "        - Hidden Dimension: 512\n",
        "        - Layers: 2 (default resolved)\n",
        "        - Dropout: 0.1 (default resolved)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int = 512,\n",
        "        num_layers: int = 2,\n",
        "        dropout: float = 0.1,\n",
        "        output_dim: int = 1,\n",
        "        embedding_dim: int = 128\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the GRU Forecaster.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Number of input features per time step.\n",
        "            hidden_dim (int): Hidden dimension of the GRU cells.\n",
        "            num_layers (int): Number of stacked GRU layers.\n",
        "            dropout (float): Dropout probability.\n",
        "            output_dim (int): Dimension of the prediction target (default 1).\n",
        "            embedding_dim (int): Dimension of the penultimate embedding (default 128).\n",
        "        \"\"\"\n",
        "        super().__init__(output_dim=output_dim, embedding_dim=embedding_dim)\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Encoder: GRU\n",
        "        # batch_first=True ensures input shape is (Batch, Length, Features)\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        # Initialize the modular head (j_head and k_predictor)\n",
        "        # This must be called after defining the encoder parameters\n",
        "        self.build_head()\n",
        "\n",
        "    def get_encoder_output_dim(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the dimension of the representation output by the GRU encoder.\n",
        "        For a standard GRU using the last hidden state, this is hidden_dim.\n",
        "        \"\"\"\n",
        "        return self.hidden_dim\n",
        "\n",
        "    def forward_encoder(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes the GRU encoder.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Latent representation of shape (Batch, hidden_dim).\n",
        "                          We use the output of the last time step.\n",
        "        \"\"\"\n",
        "        # GRU forward returns: output, h_n\n",
        "        # output shape: (Batch, Length, Hidden)\n",
        "        # h_n shape: (Layers, Batch, Hidden)\n",
        "        # We use the output of the last time step as the sequence representation\n",
        "        output, _ = self.gru(x)\n",
        "\n",
        "        # Extract last time step: (Batch, Hidden)\n",
        "        last_step_rep = output[:, -1, :]\n",
        "\n",
        "        return last_step_rep\n"
      ],
      "metadata": {
        "id": "jsRyCm9rQGAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 20 — Implement LSTM forecasting model\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 20: Implement LSTM forecasting model\n",
        "# ==============================================================================\n",
        "\n",
        "class LSTMForecaster(ModularTaskModel):\n",
        "    \"\"\"\n",
        "    LSTM-based forecasting model implementing the ModularTaskModel interface.\n",
        "\n",
        "    This model uses a Long Short-Term Memory (LSTM) encoder to process the time-series\n",
        "    window, followed by the standard 2-layer MLP head for embedding extraction and prediction.\n",
        "\n",
        "    Crucially, this architecture serves as the source model for the Transfer Learning\n",
        "    experiment in Part 2 of the manuscript, where the Planner trained on this LSTM\n",
        "    is transferred to the RL trading agent.\n",
        "\n",
        "    Hyperparameters (from Manuscript/Config):\n",
        "        - Hidden Dimension: 512\n",
        "        - Layers: 2 (default resolved)\n",
        "        - Dropout: 0.1 (default resolved)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int = 512,\n",
        "        num_layers: int = 2,\n",
        "        dropout: float = 0.1,\n",
        "        output_dim: int = 1,\n",
        "        embedding_dim: int = 128\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the LSTM Forecaster.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Number of input features per time step.\n",
        "            hidden_dim (int): Hidden dimension of the LSTM cells.\n",
        "            num_layers (int): Number of stacked LSTM layers.\n",
        "            dropout (float): Dropout probability.\n",
        "            output_dim (int): Dimension of the prediction target (default 1).\n",
        "            embedding_dim (int): Dimension of the penultimate embedding (default 128).\n",
        "        \"\"\"\n",
        "        super().__init__(output_dim=output_dim, embedding_dim=embedding_dim)\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        # Encoder: LSTM\n",
        "        # batch_first=True ensures input shape is (Batch, Length, Features)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=input_dim,\n",
        "            hidden_size=hidden_dim,\n",
        "            num_layers=num_layers,\n",
        "            batch_first=True,\n",
        "            dropout=dropout if num_layers > 1 else 0.0\n",
        "        )\n",
        "\n",
        "        # Initialize the modular head (j_head and k_predictor)\n",
        "        self.build_head()\n",
        "\n",
        "    def get_encoder_output_dim(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the dimension of the representation output by the LSTM encoder.\n",
        "        \"\"\"\n",
        "        return self.hidden_dim\n",
        "\n",
        "    def forward_encoder(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes the LSTM encoder.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Latent representation of shape (Batch, hidden_dim).\n",
        "                          We use the output of the last time step.\n",
        "        \"\"\"\n",
        "        # LSTM forward returns: output, (h_n, c_n)\n",
        "        # output shape: (Batch, Length, Hidden)\n",
        "        output, _ = self.lstm(x)\n",
        "\n",
        "        # Extract last time step: (Batch, Hidden)\n",
        "        last_step_rep = output[:, -1, :]\n",
        "\n",
        "        return last_step_rep\n"
      ],
      "metadata": {
        "id": "u_9JaRXGUPTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 21 — Implement DLinear forecasting model\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 21: Implement DLinear forecasting model\n",
        "# ==============================================================================\n",
        "\n",
        "class MovingAverage(nn.Module):\n",
        "    \"\"\"\n",
        "    Moving average block to highlight the trend of time series.\n",
        "\n",
        "    This module applies a 1D average pooling operation over the time dimension\n",
        "    to extract the trend component. It handles padding to ensure the output\n",
        "    sequence length matches the input length.\n",
        "\n",
        "    Attributes:\n",
        "        kernel_size (int): The size of the moving average window.\n",
        "        avg (nn.AvgPool1d): The pooling layer performing the averaging.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size: int, stride: int) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the MovingAverage module.\n",
        "\n",
        "        Args:\n",
        "            kernel_size (int): The size of the window for the moving average.\n",
        "            stride (int): The stride of the window.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.avg = nn.AvgPool1d(kernel_size=kernel_size, stride=stride, padding=0)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Applies the moving average to the input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The trend component of shape (Batch, Length, Features).\n",
        "        \"\"\"\n",
        "        # Padding on the both ends of time dimension to maintain sequence length\n",
        "        front = x[:, 0:1, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        end = x[:, -1:, :].repeat(1, (self.kernel_size - 1) // 2, 1)\n",
        "        x = torch.cat([front, x, end], dim=1)\n",
        "\n",
        "        # Permute to [Batch, Features, Length] for AvgPool1d\n",
        "        x = x.permute(0, 2, 1)\n",
        "        x = self.avg(x)\n",
        "        # Permute back to [Batch, Length, Features]\n",
        "        x = x.permute(0, 2, 1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SeriesDecomp(nn.Module):\n",
        "    \"\"\"\n",
        "    Series decomposition block.\n",
        "\n",
        "    This module decomposes a time series into a trend component (extracted via\n",
        "    moving average) and a seasonal/remainder component (residual).\n",
        "\n",
        "    Attributes:\n",
        "        moving_avg (MovingAverage): The module used to compute the trend.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kernel_size: int) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the SeriesDecomp module.\n",
        "\n",
        "        Args:\n",
        "            kernel_size (int): The window size for the moving average trend extraction.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.moving_avg = MovingAverage(kernel_size, stride=1)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Decomposes the input series.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]:\n",
        "                - res: The seasonal/remainder component (x - trend).\n",
        "                - moving_mean: The trend component.\n",
        "        \"\"\"\n",
        "        # Compute mean\n",
        "        moving_mean = self.moving_avg(x)\n",
        "\n",
        "        res = x - moving_mean\n",
        "\n",
        "        return res, moving_mean\n",
        "\n",
        "class DLinearForecaster(ModularTaskModel):\n",
        "    \"\"\"\n",
        "    DLinear-based forecasting model implementing the ModularTaskModel interface.\n",
        "\n",
        "    DLinear decomposes the time series into a trend component (moving average)\n",
        "    and a remainder (seasonal) component, and applies linear layers to each.\n",
        "\n",
        "    This implementation adapts DLinear for the embedding-based interface:\n",
        "    1. Decompose input (B, L, F) -> Trend, Remainder.\n",
        "    2. Flatten both to (B, L*F).\n",
        "    3. Apply Linear(L*F, hidden_dim) to both.\n",
        "    4. Sum to get representation (B, hidden_dim).\n",
        "    5. Standard head maps (B, hidden_dim) -> (B, embedding_dim) -> (B, output_dim).\n",
        "\n",
        "    Hyperparameters (from Manuscript/Config):\n",
        "        - Hidden Dimension: 512\n",
        "        - Batch Size: 1024 (training param)\n",
        "        - Patience: 8 (training param)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        seq_len: int,\n",
        "        hidden_dim: int = 512,\n",
        "        kernel_size: int = 25,\n",
        "        output_dim: int = 1,\n",
        "        embedding_dim: int = 128\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the DLinear Forecaster.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Number of input features per time step (F).\n",
        "            seq_len (int): Length of the input sequence (L).\n",
        "            hidden_dim (int): Dimension of the encoder output representation.\n",
        "            kernel_size (int): Kernel size for moving average decomposition.\n",
        "            output_dim (int): Dimension of the prediction target.\n",
        "            embedding_dim (int): Dimension of the penultimate embedding.\n",
        "        \"\"\"\n",
        "        super().__init__(output_dim=output_dim, embedding_dim=embedding_dim)\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.seq_len = seq_len\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Decomposition\n",
        "        self.decompsition = SeriesDecomp(kernel_size)\n",
        "\n",
        "        # Linear Encoders\n",
        "        # We map the flattened window (L*F) to hidden_dim\n",
        "        self.linear_trend = nn.Linear(seq_len * input_dim, hidden_dim)\n",
        "        self.linear_seasonal = nn.Linear(seq_len * input_dim, hidden_dim)\n",
        "\n",
        "        # Initialize the modular head\n",
        "        self.build_head()\n",
        "\n",
        "    def get_encoder_output_dim(self) -> int:\n",
        "        return self.hidden_dim\n",
        "\n",
        "    def forward_encoder(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes the DLinear encoder.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Latent representation of shape (Batch, hidden_dim).\n",
        "        \"\"\"\n",
        "        # Decompose\n",
        "        seasonal_init, trend_init = self.decompsition(x)\n",
        "\n",
        "        # Flatten: (B, L, F) -> (B, L*F)\n",
        "        B, L, F = x.shape\n",
        "        seasonal_flat = seasonal_init.reshape(B, -1)\n",
        "        trend_flat = trend_init.reshape(B, -1)\n",
        "\n",
        "        # Apply Linear Layers\n",
        "        seasonal_rep = self.linear_seasonal(seasonal_flat)\n",
        "        trend_rep = self.linear_trend(trend_flat)\n",
        "\n",
        "        # Sum components\n",
        "        return seasonal_rep + trend_rep\n"
      ],
      "metadata": {
        "id": "sCHmjqWpVuNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 22 — Implement TCN forecasting model\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 22: Implement TCN forecasting model\n",
        "# ==============================================================================\n",
        "\n",
        "class Chomp1d(nn.Module):\n",
        "    \"\"\"\n",
        "    Removes the last elements of a sequence to ensure causality after padding.\n",
        "\n",
        "    In causal convolutions, padding is typically applied to the left (past) to maintain\n",
        "    sequence length. However, standard PyTorch Conv1d with 'same' padding adds padding\n",
        "    to both sides. This module slices off the extra padding from the right (future)\n",
        "    to strictly enforce that the output at time t depends only on inputs up to time t.\n",
        "\n",
        "    Attributes:\n",
        "        chomp_size (int): The number of elements to remove from the end of the sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chomp_size: int) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the Chomp1d module.\n",
        "\n",
        "        Args:\n",
        "            chomp_size (int): The size of the padding to remove.\n",
        "        \"\"\"\n",
        "        super(Chomp1d, self).__init__()\n",
        "        self.chomp_size = chomp_size\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Slices the input tensor to remove the last `chomp_size` elements along the time dimension.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Channels, Length).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Chomped tensor of shape (Batch, Channels, Length - chomp_size).\n",
        "        \"\"\"\n",
        "        return x[:, :, :-self.chomp_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalBlock(nn.Module):\n",
        "    \"\"\"\n",
        "    A single residual block for the Temporal Convolutional Network (TCN).\n",
        "\n",
        "    This block consists of two dilated causal convolution layers, each followed by\n",
        "    weight normalization, activation (ReLU), and dropout. A residual connection\n",
        "    is added to the output, with an optional 1x1 convolution if the input and\n",
        "    output channel dimensions differ.\n",
        "\n",
        "    Structure:\n",
        "        Input -> [Dilated Conv1d -> Chomp -> ReLU -> Dropout] x2 -> + -> ReLU -> Output\n",
        "              |                                                     ^\n",
        "              ----------------- (Optional 1x1 Conv) ----------------|\n",
        "\n",
        "    Attributes:\n",
        "        conv1 (nn.Conv1d): First dilated convolution layer.\n",
        "        chomp1 (Chomp1d): Enforces causality for conv1.\n",
        "        relu1 (nn.ReLU): Activation for conv1.\n",
        "        dropout1 (nn.Dropout): Dropout for conv1.\n",
        "        conv2 (nn.Conv1d): Second dilated convolution layer.\n",
        "        chomp2 (Chomp1d): Enforces causality for conv2.\n",
        "        relu2 (nn.ReLU): Activation for conv2.\n",
        "        dropout2 (nn.Dropout): Dropout for conv2.\n",
        "        net (nn.Sequential): Sequential container for the block's layers.\n",
        "        downsample (nn.Conv1d): Optional 1x1 conv for residual connection if dimensions mismatch.\n",
        "        relu (nn.ReLU): Final activation after residual addition.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        n_inputs: int,\n",
        "        n_outputs: int,\n",
        "        kernel_size: int,\n",
        "        stride: int,\n",
        "        dilation: int,\n",
        "        padding: int,\n",
        "        dropout: float = 0.2\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the TemporalBlock.\n",
        "\n",
        "        Args:\n",
        "            n_inputs (int): Number of input channels.\n",
        "            n_outputs (int): Number of output channels.\n",
        "            kernel_size (int): Size of the convolution kernel.\n",
        "            stride (int): Stride of the convolution.\n",
        "            dilation (int): Dilation factor.\n",
        "            padding (int): Padding size (applied to both sides, then chomped).\n",
        "            dropout (float): Dropout probability.\n",
        "        \"\"\"\n",
        "        super(TemporalBlock, self).__init__()\n",
        "\n",
        "        # First conv layer\n",
        "        self.conv1 = weight_norm(nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp1 = Chomp1d(padding)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        # Second conv layer\n",
        "        self.conv2 = weight_norm(nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
        "                                           stride=stride, padding=padding, dilation=dilation))\n",
        "        self.chomp2 = Chomp1d(padding)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
        "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
        "\n",
        "        # Residual connection: Use 1x1 conv if channel dimensions change\n",
        "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
        "        self.relu = nn.ReLU()\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self) -> None:\n",
        "        \"\"\"\n",
        "        Initializes weights for convolution layers using a normal distribution.\n",
        "        \"\"\"\n",
        "        self.conv1.weight.data.normal_(0, 0.01)\n",
        "        self.conv2.weight.data.normal_(0, 0.01)\n",
        "        if self.downsample is not None:\n",
        "            self.downsample.weight.data.normal_(0, 0.01)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes the temporal block.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Channels, Length).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (Batch, Channels, Length).\n",
        "        \"\"\"\n",
        "        out = self.net(x)\n",
        "        res = x if self.downsample is None else self.downsample(x)\n",
        "        return self.relu(out + res)\n",
        "\n",
        "\n",
        "class TemporalConvNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Temporal Convolutional Network (TCN) encoder composed of a stack of TemporalBlocks.\n",
        "\n",
        "    This network processes sequential data using dilated causal convolutions, allowing\n",
        "    the receptive field to grow exponentially with depth. It serves as the backbone\n",
        "    encoder for the TCNForecaster.\n",
        "\n",
        "    Attributes:\n",
        "        network (nn.Sequential): The stack of TemporalBlocks.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_inputs: int,\n",
        "        num_channels: List[int],\n",
        "        kernel_size: int = 2,\n",
        "        dropout: float = 0.2\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the TemporalConvNet.\n",
        "\n",
        "        Args:\n",
        "            num_inputs (int): Number of input channels (features).\n",
        "            num_channels (List[int]): List containing the number of channels for each layer.\n",
        "                                      The length of this list determines the depth of the network.\n",
        "            kernel_size (int): Kernel size for convolutions.\n",
        "            dropout (float): Dropout probability.\n",
        "        \"\"\"\n",
        "        super(TemporalConvNet, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "\n",
        "        for i in range(num_levels):\n",
        "            dilation_size = 2 ** i\n",
        "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
        "            out_channels = num_channels[i]\n",
        "\n",
        "            # Padding for causality: (kernel_size - 1) * dilation\n",
        "            # This ensures that after convolution and chomping, the output length matches input length\n",
        "            padding = (kernel_size - 1) * dilation_size\n",
        "\n",
        "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
        "                                     padding=padding, dropout=dropout)]\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes the TCN.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Channels, Length).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor of shape (Batch, Channels, Length).\n",
        "        \"\"\"\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "class TCNForecaster(ModularTaskModel):\n",
        "    \"\"\"\n",
        "    TCN-based forecasting model implementing the ModularTaskModel interface.\n",
        "\n",
        "    Uses a Temporal Convolutional Network (TCN) with dilated causal convolutions\n",
        "    to capture long-range dependencies without future leakage.\n",
        "\n",
        "    Hyperparameters (from Manuscript/Config):\n",
        "        - Hidden Dimension: 512\n",
        "        - Kernel Size: 3 (resolved default)\n",
        "        - Dilations: [1, 2, 4, 8] (resolved default for L=60 coverage)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int = 512,\n",
        "        kernel_size: int = 3,\n",
        "        dropout: float = 0.1,\n",
        "        output_dim: int = 1,\n",
        "        embedding_dim: int = 128,\n",
        "        num_levels: int = 4 # Derived from L=60 coverage needs\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the TCN Forecaster.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Number of input features.\n",
        "            hidden_dim (int): Number of channels in TCN layers.\n",
        "            kernel_size (int): Convolution kernel size.\n",
        "            dropout (float): Dropout probability.\n",
        "            output_dim (int): Prediction target dimension.\n",
        "            embedding_dim (int): Penultimate embedding dimension.\n",
        "            num_levels (int): Number of TCN layers (depth).\n",
        "        \"\"\"\n",
        "        super().__init__(output_dim=output_dim, embedding_dim=embedding_dim)\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Define channel sizes for each level (constant hidden_dim)\n",
        "        num_channels = [hidden_dim] * num_levels\n",
        "\n",
        "        self.tcn = TemporalConvNet(\n",
        "            num_inputs=input_dim,\n",
        "            num_channels=num_channels,\n",
        "            kernel_size=kernel_size,\n",
        "            dropout=dropout\n",
        "        )\n",
        "\n",
        "        # Initialize the modular head\n",
        "        self.build_head()\n",
        "\n",
        "    def get_encoder_output_dim(self) -> int:\n",
        "        return self.hidden_dim\n",
        "\n",
        "    def forward_encoder(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes the TCN encoder.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Latent representation of shape (Batch, hidden_dim).\n",
        "                          We use the output of the last time step.\n",
        "        \"\"\"\n",
        "        # TCN expects (Batch, Channels, Length)\n",
        "        # Input x is (Batch, Length, Features) -> Permute to (Batch, Features, Length)\n",
        "        x_permuted = x.permute(0, 2, 1)\n",
        "\n",
        "        # Forward pass\n",
        "        # Output shape: (Batch, Hidden, Length)\n",
        "        output = self.tcn(x_permuted)\n",
        "\n",
        "        # Extract last time step: (Batch, Hidden)\n",
        "        # Slicing the last element along the time dimension\n",
        "        last_step_rep = output[:, :, -1]\n",
        "\n",
        "        return last_step_rep\n"
      ],
      "metadata": {
        "id": "He7yerMXXf0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 23 — Implement Transformer forecasting model\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 23: Implement Transformer forecasting model\n",
        "# ==============================================================================\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    \"\"\"\n",
        "    Injects information about the relative or absolute position of the tokens in the sequence.\n",
        "\n",
        "    Since the Transformer architecture contains no recurrence and no convolution, in order for the\n",
        "    model to make use of the order of the sequence, we must inject some information about the\n",
        "    relative or absolute position of the tokens in the sequence. The positional encodings have\n",
        "    the same dimension as the embeddings, so that the two can be summed.\n",
        "\n",
        "    This implementation uses sine and cosine functions of different frequencies:\n",
        "        PE(pos, 2i) = sin(pos / 10000^(2i/d_model))\n",
        "        PE(pos, 2i+1) = cos(pos / 10000^(2i/d_model))\n",
        "\n",
        "    Attributes:\n",
        "        dropout (nn.Dropout): Dropout layer applied to the sum of embeddings and positional encodings.\n",
        "        pe (torch.Tensor): The precomputed positional encoding matrix. Registered as a buffer.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the PositionalEncoding module.\n",
        "\n",
        "        Args:\n",
        "            d_model (int): The dimension of the model (embedding size).\n",
        "            dropout (float): The dropout probability.\n",
        "            max_len (int): The maximum length of the input sequences.\n",
        "        \"\"\"\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Create a matrix of shape (max_len, d_model) representing positional encodings\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        # Create a vector of positions (0, 1, ... max_len-1)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "\n",
        "        # Compute the division term for the sine/cosine arguments\n",
        "        # div_term = 1 / (10000^(2i/d_model)) = exp(2i * -log(10000) / d_model)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        # Apply sine to even indices\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "\n",
        "        # Apply cosine to odd indices\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        # Register 'pe' as a buffer so it is part of the state_dict but not a trainable parameter\n",
        "        # Unsqueeze to add batch dimension: (1, max_len, d_model)\n",
        "        self.register_buffer('pe', pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Adds positional encoding to the input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Dim).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor with positional information added, shape (Batch, Length, Dim).\n",
        "        \"\"\"\n",
        "        # Add positional encoding to the input\n",
        "        # Slice self.pe to match the sequence length of x\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class TransformerForecaster(ModularTaskModel):\n",
        "    \"\"\"\n",
        "    Transformer-based forecasting model implementing the ModularTaskModel interface.\n",
        "\n",
        "    Uses a Transformer Encoder to capture long-range dependencies via self-attention.\n",
        "    The input features are projected to the model dimension, positionally encoded,\n",
        "    and processed by stacked Transformer Encoder layers.\n",
        "\n",
        "    Hyperparameters (from Manuscript/Config):\n",
        "        - Hidden Dimension: 256\n",
        "        - Layers: 2 (default resolved)\n",
        "        - Heads: 4 (default resolved)\n",
        "        - Dropout: 0.1 (default resolved)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        hidden_dim: int = 256,\n",
        "        num_layers: int = 2,\n",
        "        nhead: int = 4,\n",
        "        dropout: float = 0.1,\n",
        "        output_dim: int = 1,\n",
        "        embedding_dim: int = 128\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the Transformer Forecaster.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Number of input features.\n",
        "            hidden_dim (int): Dimension of the Transformer model (d_model).\n",
        "            num_layers (int): Number of Transformer Encoder layers.\n",
        "            nhead (int): Number of attention heads.\n",
        "            dropout (float): Dropout probability.\n",
        "            output_dim (int): Prediction target dimension.\n",
        "            embedding_dim (int): Penultimate embedding dimension.\n",
        "        \"\"\"\n",
        "        super().__init__(output_dim=output_dim, embedding_dim=embedding_dim)\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        # Input Projection\n",
        "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
        "\n",
        "        # Positional Encoding\n",
        "        self.pos_encoder = PositionalEncoding(hidden_dim, dropout)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_dim,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=hidden_dim * 4,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # Initialize the modular head\n",
        "        self.build_head()\n",
        "\n",
        "    def get_encoder_output_dim(self) -> int:\n",
        "        return self.hidden_dim\n",
        "\n",
        "    def forward_encoder(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Executes the Transformer encoder.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Latent representation of shape (Batch, hidden_dim).\n",
        "                          We use the output of the last time step.\n",
        "        \"\"\"\n",
        "        # Project input\n",
        "        x = self.input_proj(x)\n",
        "\n",
        "        # Add positional encoding\n",
        "        x = self.pos_encoder(x)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        # Output: (Batch, Length, Hidden)\n",
        "        output = self.transformer_encoder(x)\n",
        "\n",
        "        # Extract last time step representation\n",
        "        last_step_rep = output[:, -1, :]\n",
        "\n",
        "        return last_step_rep\n"
      ],
      "metadata": {
        "id": "v7LbtpgaaK31"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 24 — Implement the planner network (Transformer controller)\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 24: Implement the planner network g_phi (Transformer controller)\n",
        "# ==============================================================================\n",
        "\n",
        "class Planner(nn.Module):\n",
        "    \"\"\"\n",
        "    The Planner network (g_phi) responsible for generating the adaptive data manipulation policy.\n",
        "\n",
        "    This module implements the meta-learning controller described in the manuscript. It observes\n",
        "    the current state of the Task Model (via its penultimate embedding) and the statistical\n",
        "    properties of the input data window, and outputs a policy consisting of operation probabilities (p)\n",
        "    and manipulation strengths (lambda) for the Data Manipulation Module.\n",
        "\n",
        "    Architecture:\n",
        "        1. State Construction: Concatenates Task Model Embedding (h) and Data Statistics.\n",
        "        2. Input Projection: Maps the combined state to the Transformer's d_model dimension.\n",
        "        3. Transformer Encoder: Processes the state vector (treated as a sequence of length 1).\n",
        "        4. Policy Heads: Two linear layers predicting 'p' (softmax) and 'lambda' (sigmoid).\n",
        "\n",
        "    Attributes:\n",
        "        input_proj (nn.Linear): Projects concatenated state to d_model.\n",
        "        transformer (nn.TransformerEncoder): The core reasoning backbone.\n",
        "        head_p (nn.Linear): Output head for operation probabilities.\n",
        "        head_lambda (nn.Linear): Output head for manipulation strengths.\n",
        "        n_ops_single (int): Number of single-stock operations.\n",
        "        n_ops_multi (int): Number of multi-stock operations.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_dim: int,\n",
        "        stats_dim: int,\n",
        "        planner_input_dim: int,\n",
        "        num_layers: int,\n",
        "        nhead: int,\n",
        "        dim_feedforward: int,\n",
        "        n_ops_single: int,\n",
        "        n_ops_multi: int,\n",
        "        dropout: float = 0.1\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the Planner network.\n",
        "\n",
        "        Args:\n",
        "            embedding_dim (int): Dimension of the task model's penultimate embedding (h).\n",
        "            stats_dim (int): Dimension of the data statistics vector (e.g., 6).\n",
        "            planner_input_dim (int): Dimension of the Transformer model (d_model).\n",
        "            num_layers (int): Number of Transformer Encoder layers.\n",
        "            nhead (int): Number of attention heads.\n",
        "            dim_feedforward (int): Dimension of the feedforward network model.\n",
        "            n_ops_single (int): Count of single-stock operations (n).\n",
        "            n_ops_multi (int): Count of multi-stock operations (m).\n",
        "            dropout (float): Dropout probability.\n",
        "        \"\"\"\n",
        "        super(Planner, self).__init__()\n",
        "\n",
        "        self.n_ops_single = n_ops_single\n",
        "        self.n_ops_multi = n_ops_multi\n",
        "        self.total_ops = n_ops_single * n_ops_multi\n",
        "\n",
        "        # 1. Input Projection\n",
        "        # Maps concatenated [embedding, stats] to planner_input_dim\n",
        "        # Input dim: embedding_dim + stats_dim\n",
        "        self.input_proj = nn.Linear(embedding_dim + stats_dim, planner_input_dim)\n",
        "\n",
        "        # 2. Transformer Encoder\n",
        "        # We treat the input state vector as a sequence of length 1.\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=planner_input_dim,\n",
        "            nhead=nhead,\n",
        "            dim_feedforward=dim_feedforward,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        # 3. Policy Heads\n",
        "        # Output p: Probability matrix (n, m) -> Flattened to (n*m) logits\n",
        "        self.head_p = nn.Linear(planner_input_dim, self.total_ops)\n",
        "\n",
        "        # Output lambda: Strength matrix (n, m) -> Flattened to (n*m) logits\n",
        "        self.head_lambda = nn.Linear(planner_input_dim, self.total_ops)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self) -> None:\n",
        "        \"\"\"Initializes weights for linear layers.\"\"\"\n",
        "        nn.init.xavier_uniform_(self.input_proj.weight)\n",
        "        nn.init.xavier_uniform_(self.head_p.weight)\n",
        "        nn.init.xavier_uniform_(self.head_lambda.weight)\n",
        "        nn.init.constant_(self.input_proj.bias, 0)\n",
        "        nn.init.constant_(self.head_p.bias, 0)\n",
        "        nn.init.constant_(self.head_lambda.bias, 0)\n",
        "\n",
        "    def compute_data_stats(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Computes statistical descriptors of the input window.\n",
        "\n",
        "        Metrics: Mean, Volatility, Momentum, Trend, Skewness, Kurtosis.\n",
        "        These are computed per feature and then aggregated (mean) across features\n",
        "        to produce a fixed-size vector representing the data state.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input window of shape (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Statistics vector of shape (Batch, 6).\n",
        "        \"\"\"\n",
        "        # x: (B, L, F)\n",
        "        B, L, F = x.shape\n",
        "\n",
        "        # 1. Mean\n",
        "        mean = x.mean(dim=1) # (B, F)\n",
        "\n",
        "        # 2. Volatility (Std)\n",
        "        std = x.std(dim=1) # (B, F)\n",
        "\n",
        "        # 3. Momentum (Last - First)\n",
        "        momentum = x[:, -1, :] - x[:, 0, :] # (B, F)\n",
        "\n",
        "        # 4. Trend (Slope of linear fit)\n",
        "        # Proxy: Covariance(time, value) / Var(time)\n",
        "        t = torch.arange(L, device=x.device, dtype=x.dtype)\n",
        "        t_mean = t.mean()\n",
        "        t_centered = t - t_mean # (L,)\n",
        "\n",
        "        # Center x along time dimension\n",
        "        x_mean_time = x.mean(dim=1, keepdim=True) # (B, 1, F)\n",
        "        x_centered = x - x_mean_time # (B, L, F)\n",
        "\n",
        "        # Covariance numerator: sum((t - t_mean) * (x - x_mean))\n",
        "        # t_centered: (L,) -> (1, L, 1) for broadcasting\n",
        "        numerator = (x_centered * t_centered.view(1, L, 1)).sum(dim=1) # (B, F)\n",
        "        denominator = (t_centered ** 2).sum()\n",
        "        trend = numerator / (denominator + 1e-8) # (B, F)\n",
        "\n",
        "        # 5. Skewness\n",
        "        # E[(x-mu)^3] / sigma^3\n",
        "        m3 = (x_centered ** 3).mean(dim=1)\n",
        "        skew = m3 / (std ** 3 + 1e-8)\n",
        "\n",
        "        # 6. Kurtosis\n",
        "        # E[(x-mu)^4] / sigma^4 - 3\n",
        "        m4 = (x_centered ** 4).mean(dim=1)\n",
        "        kurt = m4 / (std ** 4 + 1e-8) - 3.0\n",
        "\n",
        "        # Aggregate across features (Channel Mean)\n",
        "        # Result: (B, 6)\n",
        "        stats = torch.stack([\n",
        "            mean.mean(dim=1),\n",
        "            std.mean(dim=1),\n",
        "            momentum.mean(dim=1),\n",
        "            trend.mean(dim=1),\n",
        "            skew.mean(dim=1),\n",
        "            kurt.mean(dim=1)\n",
        "        ], dim=1)\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def forward(self, model_embedding: torch.Tensor, x_raw: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Forward pass of the Planner.\n",
        "\n",
        "        Args:\n",
        "            model_embedding (torch.Tensor): Penultimate embedding from Task Model (Batch, embedding_dim).\n",
        "            x_raw (torch.Tensor): Input data window (Batch, Length, Features).\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor]:\n",
        "                - p_matrix: Operation probabilities (Batch, n_ops_single, n_ops_multi).\n",
        "                            Sum over (n, m) dimensions equals 1.\n",
        "                - lambda_matrix: Manipulation strengths (Batch, n_ops_single, n_ops_multi).\n",
        "                                 Values in [0, 1].\n",
        "        \"\"\"\n",
        "        # 1. Compute Data Stats\n",
        "        stats = self.compute_data_stats(x_raw) # (B, 6)\n",
        "\n",
        "        # 2. Concatenate State\n",
        "        # embedding: (B, 128), stats: (B, 6) -> (B, 134)\n",
        "        state = torch.cat([model_embedding, stats], dim=1)\n",
        "\n",
        "        # 3. Project and Encode\n",
        "        # (B, 134) -> (B, d_model) -> (B, 1, d_model) for Transformer\n",
        "        x = self.input_proj(state).unsqueeze(1)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # Squeeze back: (B, d_model)\n",
        "        x = x.squeeze(1)\n",
        "\n",
        "        # 4. Heads\n",
        "        # Probabilities p\n",
        "        logits_p = self.head_p(x) # (B, n*m)\n",
        "        # Softmax over all operations to ensure sum(p) = 1\n",
        "        p_flat = F.softmax(logits_p, dim=1)\n",
        "        p_matrix = p_flat.view(-1, self.n_ops_single, self.n_ops_multi)\n",
        "\n",
        "        # Strengths lambda\n",
        "        logits_lambda = self.head_lambda(x) # (B, n*m)\n",
        "        # Sigmoid to bound in [0, 1]\n",
        "        lambda_flat = torch.sigmoid(logits_lambda)\n",
        "        lambda_matrix = lambda_flat.view(-1, self.n_ops_single, self.n_ops_multi)\n",
        "\n",
        "        return p_matrix, lambda_matrix\n"
      ],
      "metadata": {
        "id": "uCh2wkeVd_Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 25 — Implement the planner's risk-aware loss term\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 25: Implement the planner's risk-aware loss term\n",
        "# ==============================================================================\n",
        "\n",
        "class RiskAwareLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Implements the risk-aware loss function proposed in the manuscript.\n",
        "\n",
        "    This loss incorporates a penalty for the volatility (standard deviation) of the\n",
        "    loss distribution across the batch, guiding the model (specifically the Planner)\n",
        "    away from strategies that yield high-variance (risky) errors.\n",
        "\n",
        "    Equation:\n",
        "        L = E[loss] + gamma * sigma(loss)\n",
        "\n",
        "    Attributes:\n",
        "        base_criterion (nn.Module): The underlying loss function (e.g., MSELoss).\n",
        "                                    Must be set to reduction='none' to compute per-sample losses.\n",
        "        gamma (float): The risk penalty coefficient. Default is 0.05.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, base_criterion: nn.Module, gamma: float = 0.05) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the RiskAwareLoss.\n",
        "\n",
        "        Args:\n",
        "            base_criterion (nn.Module): The base loss function (e.g., nn.MSELoss(reduction='none')).\n",
        "                                        IMPORTANT: Must have reduction='none'.\n",
        "            gamma (float): The weight for the standard deviation penalty.\n",
        "        \"\"\"\n",
        "        super(RiskAwareLoss, self).__init__()\n",
        "        self.base_criterion = base_criterion\n",
        "        self.gamma = gamma\n",
        "\n",
        "        # Ensure base criterion does not reduce\n",
        "        if hasattr(base_criterion, 'reduction') and base_criterion.reduction != 'none':\n",
        "            logger.warning(f\"Base criterion reduction is '{base_criterion.reduction}'. \"\n",
        "                           f\"Forcing 'none' for RiskAwareLoss calculation.\")\n",
        "            base_criterion.reduction = 'none'\n",
        "\n",
        "    def forward(self, input: torch.Tensor, target: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Computes the risk-aware loss.\n",
        "\n",
        "        Args:\n",
        "            input (torch.Tensor): Predictions.\n",
        "            target (torch.Tensor): Ground truth.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Scalar loss value.\n",
        "        \"\"\"\n",
        "        # 1. Compute per-sample loss\n",
        "        # Shape: (Batch, ...) -> Flatten to (Batch,) for stats\n",
        "        per_sample_loss = self.base_criterion(input, target)\n",
        "\n",
        "        # Flatten to 1D vector of losses per sample\n",
        "        # If input is (B, 1) and target is (B,), MSE with reduction='none' might broadcast or return (B, 1).\n",
        "        # We ensure it's a flat vector of size B.\n",
        "        if per_sample_loss.ndim > 1:\n",
        "            per_sample_loss = per_sample_loss.view(per_sample_loss.size(0), -1).mean(dim=1)\n",
        "\n",
        "        # 2. Compute Statistics\n",
        "        # Expected loss (Mean)\n",
        "        mean_loss = per_sample_loss.mean()\n",
        "\n",
        "        # Volatility (Standard Deviation)\n",
        "        # Handle batch size < 2\n",
        "        if per_sample_loss.size(0) > 1:\n",
        "            std_loss = per_sample_loss.std(unbiased=True)\n",
        "        else:\n",
        "            std_loss = torch.tensor(0.0, device=per_sample_loss.device)\n",
        "\n",
        "        # 3. Combine\n",
        "        total_loss = mean_loss + self.gamma * std_loss\n",
        "\n",
        "        return total_loss\n"
      ],
      "metadata": {
        "id": "HkHyG_-ggieq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 26 — Implement bi-level optimization: outer-loop planner updates\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 26: Implement bi-level optimization: outer-loop planner updates\n",
        "# ==============================================================================\n",
        "\n",
        "# Re-importing STE helper for self-containment within this module context\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 26, Step 2: Implement the weighted augmentation mixture\n",
        "# ------------------------------------------------------------------------------\n",
        "def generate_weighted_mixture(\n",
        "    x_batch: torch.Tensor,\n",
        "    y_batch: torch.Tensor,\n",
        "    p_matrix: torch.Tensor,\n",
        "    lambda_matrix: torch.Tensor,\n",
        "    single_stock_ops: List[str],\n",
        "    multi_stock_ops: List[str],\n",
        "    transformer_registry: Any, # SingleStockTransformations\n",
        "    mixup_registry: Any,       # MultiStockMixup\n",
        "    base_seed: int\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Generates the weighted mixture of all augmentation operations for the planner update.\n",
        "\n",
        "    This function iterates over every combination of single-stock and multi-stock operations.\n",
        "    For each combination (i, j), it applies the operation M(x) using the strength lambda_{ij}.\n",
        "    The result is weighted by probability p_{ij} and summed.\n",
        "\n",
        "    Crucially, it uses the Straight-Through Estimator (STE) to allow gradients to flow\n",
        "    from the resulting tensor back to the lambda parameters, despite the operations\n",
        "    themselves being non-differentiable (NumPy-based).\n",
        "\n",
        "    Equation:\n",
        "        x_tilde = sum_{i,j} p_{ij} * STE(M(1, 1, lambda_{ij}, x), lambda_{ij})\n",
        "\n",
        "    Args:\n",
        "        x_batch (torch.Tensor): Input features (B, L, F).\n",
        "        y_batch (torch.Tensor): Input targets (B,).\n",
        "        p_matrix (torch.Tensor): Operation probabilities (B, n, m).\n",
        "        lambda_matrix (torch.Tensor): Operation strengths (B, n, m).\n",
        "        single_stock_ops (List[str]): List of single-stock operation names.\n",
        "        multi_stock_ops (List[str]): List of multi-stock operation names.\n",
        "        transformer_registry: Instance of SingleStockTransformations.\n",
        "        mixup_registry: Instance of MultiStockMixup.\n",
        "        base_seed (int): Seed for determinism.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[torch.Tensor, torch.Tensor]: Weighted features and targets.\n",
        "    \"\"\"\n",
        "    device = x_batch.device\n",
        "    B, L, F = x_batch.shape\n",
        "\n",
        "    # Initialize accumulators on device\n",
        "    x_weighted = torch.zeros_like(x_batch)\n",
        "    y_weighted = torch.zeros_like(y_batch, dtype=torch.float32)\n",
        "\n",
        "    # Detach input for numpy conversion (augmentation happens outside graph)\n",
        "    x_numpy = x_batch.detach().cpu().numpy()\n",
        "    y_numpy = y_batch.detach().cpu().numpy()\n",
        "\n",
        "    # Iterate over all combinations of operations\n",
        "    for i, single_op_name in enumerate(single_stock_ops):\n",
        "        for j, multi_op_name in enumerate(multi_stock_ops):\n",
        "            # Extract p and lambda for this op combination\n",
        "            # Shape: (B,)\n",
        "            p_ij = p_matrix[:, i, j]\n",
        "            lambda_ij = lambda_matrix[:, i, j]\n",
        "\n",
        "            # Generate augmented batch for this op combination\n",
        "            # We must apply the op per sample because lambda varies per sample\n",
        "            x_aug_list = []\n",
        "            y_aug_list = []\n",
        "\n",
        "            for b in range(B):\n",
        "                # Get scalar strength\n",
        "                lam = lambda_ij[b].item()\n",
        "                seed = base_seed + b + (i * len(multi_stock_ops) + j) * B\n",
        "\n",
        "                # 1. Single Stock Transform (Raw Space)\n",
        "                # Note: We assume x_batch is raw features as per Task 12 requirements\n",
        "                x_raw = x_numpy[b]\n",
        "                x_trans = transformer_registry.apply(x_raw, single_op_name, lam, seed)\n",
        "\n",
        "                # 2. Curation & Normalization (Task 12)\n",
        "                # Normalization (Instance-wise Z-score)\n",
        "                mean = np.mean(x_trans, axis=0)\n",
        "                std = np.std(x_trans, axis=0) + 1e-8\n",
        "                x_norm = (x_trans - mean) / std\n",
        "\n",
        "                # 3. Mixup\n",
        "                # We need a target. For the weighted mixture, we use a deterministic neighbor\n",
        "                # to ensure the graph structure is stable.\n",
        "                # Target: (b + 1) % B\n",
        "                x_tgt_raw = x_numpy[(b + 1) % B]\n",
        "                y_tgt = y_numpy[(b + 1) % B]\n",
        "\n",
        "                # Normalize target\n",
        "                x_tgt_norm = (x_tgt_raw - np.mean(x_tgt_raw, axis=0)) / (np.std(x_tgt_raw, axis=0) + 1e-8)\n",
        "\n",
        "                # Apply Mixup\n",
        "                x_mixed, y_mixed = mixup_registry.apply(\n",
        "                    x_norm, y_numpy[b], x_tgt_norm, y_tgt,\n",
        "                    multi_op_name, lam, seed\n",
        "                )\n",
        "\n",
        "                x_aug_list.append(x_mixed)\n",
        "                y_aug_list.append(y_mixed)\n",
        "\n",
        "            # Convert back to Tensor\n",
        "            x_aug_tensor = torch.tensor(np.stack(x_aug_list), device=device, dtype=torch.float32)\n",
        "            y_aug_tensor = torch.tensor(np.array(y_aug_list), device=device, dtype=torch.float32)\n",
        "\n",
        "            # Apply Straight-Through Estimator\n",
        "            # This connects the non-differentiable x_aug_tensor to the differentiable lambda_ij\n",
        "            x_aug_ste = apply_ste(x_aug_tensor, lambda_ij)\n",
        "\n",
        "            # Weighted Sum\n",
        "            # p_ij: (B,) -> (B, 1, 1) for broadcasting\n",
        "            p_weight = p_ij.view(B, 1, 1)\n",
        "            x_weighted += p_weight * x_aug_ste\n",
        "\n",
        "            # Weighted Targets\n",
        "            # Targets are also mixed, so they depend on lambda (via mixup) and p\n",
        "            # We apply STE to targets as well if they are used in the loss\n",
        "            y_aug_ste = apply_ste(y_aug_tensor, lambda_ij)\n",
        "            y_weighted += p_ij * y_aug_ste\n",
        "\n",
        "    return x_weighted, y_weighted\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 26, Step 3: Implement outer update logic\n",
        "# ------------------------------------------------------------------------------\n",
        "def bi_level_outer_update(\n",
        "    task_model: nn.Module,\n",
        "    planner_model: nn.Module,\n",
        "    planner_optimizer: optim.Optimizer,\n",
        "    x_train: torch.Tensor,\n",
        "    y_train: torch.Tensor,\n",
        "    x_val: torch.Tensor,\n",
        "    y_val: torch.Tensor,\n",
        "    p_matrix: torch.Tensor,\n",
        "    lambda_matrix: torch.Tensor,\n",
        "    weighted_mix_fn: Callable,\n",
        "    criterion: nn.Module\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Performs the outer loop update for the Planner parameters phi.\n",
        "\n",
        "    This function implements the one-step lookahead optimization:\n",
        "    1. Compute the weighted augmentation mixture x_weighted using current policy (p, lambda).\n",
        "    2. Simulate a gradient descent step on the Task Model (theta -> theta') using x_weighted.\n",
        "    3. Evaluate the validation loss of the updated Task Model (theta') on validation data.\n",
        "    4. Backpropagate the validation loss through theta' to x_weighted to (p, lambda) to phi.\n",
        "\n",
        "    Args:\n",
        "        task_model (nn.Module): The current Task Model f_theta.\n",
        "        planner_model (nn.Module): The Planner g_phi.\n",
        "        planner_optimizer (optim.Optimizer): Optimizer for phi.\n",
        "        x_train (torch.Tensor): Training batch features.\n",
        "        y_train (torch.Tensor): Training batch targets.\n",
        "        x_val (torch.Tensor): Validation batch features.\n",
        "        y_val (torch.Tensor): Validation batch targets.\n",
        "        p_matrix (torch.Tensor): Policy probabilities from Planner.\n",
        "        lambda_matrix (torch.Tensor): Policy strengths from Planner.\n",
        "        weighted_mix_fn (Callable): Function to generate weighted mixture (injects STE).\n",
        "        criterion (nn.Module): Loss function (e.g., MSE).\n",
        "\n",
        "    Returns:\n",
        "        float: The validation loss value (scalar).\n",
        "    \"\"\"\n",
        "    # 1. Generate Weighted Data\n",
        "    # This tensor is connected to the computation graph of phi via p_matrix and lambda_matrix\n",
        "    x_weighted, y_weighted = weighted_mix_fn(x_train, y_train, p_matrix, lambda_matrix)\n",
        "\n",
        "    # 2. Lookahead Update (Theta -> Theta')\n",
        "    # We compute gradients of the training loss w.r.t theta\n",
        "    pred_train = task_model(x_weighted)\n",
        "    loss_train = criterion(pred_train.squeeze(), y_weighted)\n",
        "\n",
        "    # Compute gradients\n",
        "    # create_graph=True is CRITICAL: it allows backprop through the gradient computation itself\n",
        "    params = dict(task_model.named_parameters())\n",
        "    grads = torch.autograd.grad(loss_train, params.values(), create_graph=True)\n",
        "\n",
        "    # Manual SGD Step to create Theta'\n",
        "    # We assume a simple SGD update for the lookahead step, which is standard in meta-learning\n",
        "    # even if the actual optimizer is Adam.\n",
        "    # lr should ideally match the task optimizer's lr\n",
        "    lr = 0.001 # Fixed for this implementation, or fetch from config\n",
        "    updated_params = {\n",
        "        name: param - lr * grad\n",
        "        for (name, param), grad in zip(params.items(), grads)\n",
        "    }\n",
        "\n",
        "    # 3. Validation Loss (L_val(Theta'))\n",
        "    # We evaluate the task model using the *updated* parameters Theta'\n",
        "    # This requires a functional forward pass (stateless evaluation)\n",
        "    # task_model must implement `functional_forward` (Task 18)\n",
        "    pred_val = task_model.functional_forward(x_val, updated_params)\n",
        "    loss_val = criterion(pred_val.squeeze(), y_val)\n",
        "\n",
        "    # 4. Update Planner (Phi)\n",
        "    planner_optimizer.zero_grad()\n",
        "    loss_val.backward()\n",
        "    planner_optimizer.step()\n",
        "\n",
        "    return loss_val.item()\n"
      ],
      "metadata": {
        "id": "EM6sVGA0Iy3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 27 — Train the forecasting system end-to-end (core models + planner + scheduler)\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 27: Train the forecasting system end-to-end\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Helper: Data Loading\n",
        "# ------------------------------------------------------------------------------\n",
        "def create_dataloaders(\n",
        "    tensor_data: Dict[str, Any],\n",
        "    split_metadata: Any, # SplitMetadata\n",
        "    batch_size: int\n",
        ") -> Tuple[DataLoader, DataLoader, DataLoader]:\n",
        "    \"\"\"\n",
        "    Creates DataLoaders for Train, Validation, and Test sets from the aligned tensor data.\n",
        "\n",
        "    Args:\n",
        "        tensor_data (Dict[str, Any]): Dictionary containing 'X_windows' and 'y' tensors.\n",
        "        split_metadata (SplitMetadata): Object containing split indices.\n",
        "        batch_size (int): Batch size for training and evaluation.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[DataLoader, DataLoader, DataLoader]: Train, Validation, and Test loaders.\n",
        "    \"\"\"\n",
        "    # Extract tensors\n",
        "    # X_windows: (N, L, F), y: (N,)\n",
        "    X = torch.tensor(tensor_data[\"X_windows\"], dtype=torch.float32)\n",
        "    y = torch.tensor(tensor_data[\"y\"], dtype=torch.float32)\n",
        "\n",
        "    # Indices\n",
        "    train_idx = split_metadata.train_indices\n",
        "    valid_idx = split_metadata.valid_indices\n",
        "    test_idx = split_metadata.test_indices\n",
        "\n",
        "    # Create Datasets\n",
        "    train_ds = TensorDataset(X[train_idx], y[train_idx])\n",
        "    valid_ds = TensorDataset(X[valid_idx], y[valid_idx])\n",
        "    test_ds = TensorDataset(X[test_idx], y[test_idx])\n",
        "\n",
        "    # Create Loaders\n",
        "    # Shuffle training data\n",
        "    train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_ds, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, valid_loader, test_loader\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Helper: Manipulation Wrappers\n",
        "# ------------------------------------------------------------------------------\n",
        "def inner_loop_manipulation_wrapper(\n",
        "    x_batch: torch.Tensor,\n",
        "    y_batch: torch.Tensor,\n",
        "    alpha: float,\n",
        "    p_matrix: torch.Tensor,\n",
        "    lambda_matrix: torch.Tensor,\n",
        "    single_stock_ops: List[str],\n",
        "    multi_stock_ops: List[str],\n",
        "    transformer_registry: Any,\n",
        "    mixup_registry: Any,\n",
        "    base_seed: int,\n",
        "    global_step: int\n",
        ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Wraps the manipulation logic for the inner loop (Task 17).\n",
        "    Applies sampling-based augmentation based on the policy (p, lambda) and proportion alpha.\n",
        "\n",
        "    Args:\n",
        "        x_batch (torch.Tensor): Input features.\n",
        "        y_batch (torch.Tensor): Input targets.\n",
        "        alpha (float): Proportion of data to manipulate.\n",
        "        p_matrix (torch.Tensor): Operation probabilities.\n",
        "        lambda_matrix (torch.Tensor): Operation strengths.\n",
        "        single_stock_ops (List[str]): List of single-stock operation names.\n",
        "        multi_stock_ops (List[str]): List of multi-stock operation names.\n",
        "        transformer_registry (Any): Registry for single-stock ops.\n",
        "        mixup_registry (Any): Registry for mix-up ops.\n",
        "        base_seed (int): Base seed for reproducibility.\n",
        "        global_step (int): Current global step for seeding.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[torch.Tensor, torch.Tensor]: Augmented features and targets.\n",
        "    \"\"\"\n",
        "    B = x_batch.shape[0]\n",
        "    device = x_batch.device\n",
        "\n",
        "    # 1. Masking based on alpha\n",
        "    # alpha is proportion of data to manipulate.\n",
        "    # We generate a mask M ~ Bernoulli(alpha)\n",
        "    rng = np.random.Generator(np.random.PCG64(base_seed + global_step))\n",
        "    mask = rng.random(B) < alpha\n",
        "\n",
        "    # 2. Sample Operations\n",
        "    # p_matrix: (B, n, m). Flatten to (B, n*m).\n",
        "    n = len(single_stock_ops)\n",
        "    m = len(multi_stock_ops)\n",
        "    p_flat = p_matrix.view(B, -1)\n",
        "\n",
        "    # Sample indices\n",
        "    # torch.multinomial expects probabilities\n",
        "    op_indices = torch.multinomial(p_flat, 1).squeeze() # (B,)\n",
        "\n",
        "    # 3. Apply Operations (Iterative implementation for correctness with numpy registries)\n",
        "    x_aug_list = []\n",
        "    y_aug_list = []\n",
        "\n",
        "    x_numpy = x_batch.detach().cpu().numpy()\n",
        "    y_numpy = y_batch.detach().cpu().numpy()\n",
        "\n",
        "    for b in range(B):\n",
        "        if not mask[b]:\n",
        "            x_aug_list.append(x_numpy[b])\n",
        "            y_aug_list.append(y_numpy[b])\n",
        "            continue\n",
        "\n",
        "        # Decode op index\n",
        "        idx = op_indices[b].item() if op_indices.ndim > 0 else op_indices.item()\n",
        "        i = idx // m\n",
        "        j = idx % m\n",
        "\n",
        "        single_op = single_stock_ops[i]\n",
        "        multi_op = multi_stock_ops[j]\n",
        "\n",
        "        # Strength\n",
        "        lam = lambda_matrix[b, i, j].item()\n",
        "        seed = base_seed + global_step + b\n",
        "\n",
        "        # Apply Single\n",
        "        x_raw = x_numpy[b]\n",
        "        x_trans = transformer_registry.apply(x_raw, single_op, lam, seed)\n",
        "\n",
        "        # Normalize (Instance)\n",
        "        mean = np.mean(x_trans, axis=0)\n",
        "        std = np.std(x_trans, axis=0) + 1e-8\n",
        "        x_norm = (x_trans - mean) / std\n",
        "\n",
        "        # Apply Multi\n",
        "        # Target: Random neighbor\n",
        "        tgt_idx = (b + 1) % B\n",
        "        x_tgt = x_numpy[tgt_idx]\n",
        "        y_tgt = y_numpy[tgt_idx]\n",
        "        x_tgt_norm = (x_tgt - np.mean(x_tgt, axis=0)) / (np.std(x_tgt, axis=0) + 1e-8)\n",
        "\n",
        "        x_mixed, y_mixed = mixup_registry.apply(\n",
        "            x_norm, y_numpy[b], x_tgt_norm, y_tgt,\n",
        "            multi_op, lam, seed\n",
        "        )\n",
        "\n",
        "        x_aug_list.append(x_mixed)\n",
        "        y_aug_list.append(y_mixed)\n",
        "\n",
        "    x_out = torch.tensor(np.stack(x_aug_list), device=device, dtype=torch.float32)\n",
        "    y_out = torch.tensor(np.array(y_aug_list), device=device, dtype=torch.float32)\n",
        "\n",
        "    return x_out, y_out\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 27, Step 3: Evaluation\n",
        "# ------------------------------------------------------------------------------\n",
        "def evaluate_test_set(\n",
        "    model: nn.Module,\n",
        "    test_loader: DataLoader,\n",
        "    criterion: nn.Module\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Evaluates the model on the test set and computes performance metrics.\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): Trained task model.\n",
        "        test_loader (DataLoader): Test data loader.\n",
        "        criterion (nn.Module): Loss function.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, float]: Dictionary containing MSE, MAE, and STD of loss.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    abs_errors = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in test_loader:\n",
        "            x, y = x.to(next(model.parameters()).device), y.to(next(model.parameters()).device)\n",
        "            pred = model(x).squeeze()\n",
        "\n",
        "            # MSE\n",
        "            loss = criterion(pred, y)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            # MAE\n",
        "            abs_errors.append(torch.abs(pred - y).mean().item())\n",
        "\n",
        "    mse = np.mean(losses)\n",
        "    mae = np.mean(abs_errors)\n",
        "    std_loss = np.std(losses) # Proxy for robustness\n",
        "\n",
        "    return {\"MSE\": mse, \"MAE\": mae, \"STD\": std_loss}\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 27, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def run_full_training_pipeline(\n",
        "    tensor_data: Dict[str, Any],\n",
        "    split_metadata: Any,\n",
        "    study_config: Dict[str, Any],\n",
        "    transformer_registry: Any,\n",
        "    mixup_registry: Any,\n",
        "    scheduler_step_fn: Callable,\n",
        "    joint_training_fn: Callable,\n",
        "    weighted_mixture_fn: Callable\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 27: End-to-End Training Pipeline.\n",
        "\n",
        "    Executes the full training and evaluation loop for all configured task models.\n",
        "\n",
        "    Args:\n",
        "        tensor_data (Dict[str, Any]): Prepared tensor data.\n",
        "        split_metadata (Any): Split definitions.\n",
        "        study_config (Dict[str, Any]): Master configuration.\n",
        "        transformer_registry (Any): Single-stock ops registry.\n",
        "        mixup_registry (Any): Multi-stock ops registry.\n",
        "        scheduler_step_fn (Callable): Scheduler step function.\n",
        "        joint_training_fn (Callable): Joint training orchestrator.\n",
        "        weighted_mixture_fn (Callable): Weighted mixture function.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Results dictionary containing metrics and artifacts for all models.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting Full Training Pipeline...\")\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    models_to_run = [\"GRU\", \"LSTM\", \"DLinear\", \"TCN\", \"Transformer\"]\n",
        "\n",
        "    for model_name in models_to_run:\n",
        "        logger.info(f\"Training Model: {model_name}\")\n",
        "\n",
        "        # Config\n",
        "        model_cfg = study_config[\"task_models\"][model_name]\n",
        "        batch_size = model_cfg[\"batch_size\"]\n",
        "\n",
        "        # Loaders\n",
        "        train_loader, valid_loader, test_loader = create_dataloaders(\n",
        "            tensor_data, split_metadata, batch_size\n",
        "        )\n",
        "\n",
        "        # Instantiate Model\n",
        "        input_dim = tensor_data[\"X_windows\"].shape[2]\n",
        "\n",
        "        if model_name == \"GRU\":\n",
        "            model = GRUForecaster(input_dim=input_dim, **model_cfg[\"architecture_details\"])\n",
        "        elif model_name == \"LSTM\":\n",
        "            model = LSTMForecaster(input_dim=input_dim, **model_cfg[\"architecture_details\"])\n",
        "        elif model_name == \"DLinear\":\n",
        "            # DLinear needs seq_len\n",
        "            seq_len = study_config[\"preprocessing\"][\"lookback_window\"]\n",
        "            model = DLinearForecaster(input_dim=input_dim, seq_len=seq_len, **model_cfg[\"architecture_details\"])\n",
        "        elif model_name == \"TCN\":\n",
        "            model = TCNForecaster(input_dim=input_dim, **model_cfg[\"architecture_details\"])\n",
        "        elif model_name == \"Transformer\":\n",
        "            model = TransformerForecaster(input_dim=input_dim, **model_cfg[\"architecture_details\"])\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model: {model_name}\")\n",
        "\n",
        "        # Instantiate Planner\n",
        "        planner_cfg = study_config[\"planner\"]\n",
        "        n_ops_single = len(study_config[\"manipulation_module\"][\"operations\"][\"single_stock\"])\n",
        "        n_ops_multi = len(study_config[\"manipulation_module\"][\"operations\"][\"multi_stock\"])\n",
        "\n",
        "        planner = Planner(\n",
        "            embedding_dim=128,\n",
        "            stats_dim=6,\n",
        "            planner_input_dim=planner_cfg[\"input_dim\"],\n",
        "            num_layers=planner_cfg[model_name][\"layers\"], # Model-specific planner depth\n",
        "            nhead=4, # Default\n",
        "            dim_feedforward=planner_cfg[\"input_dim\"] * 4,\n",
        "            n_ops_single=n_ops_single,\n",
        "            n_ops_multi=n_ops_multi\n",
        "        )\n",
        "\n",
        "        # Define Wrappers\n",
        "        single_ops = study_config[\"manipulation_module\"][\"operations\"][\"single_stock\"]\n",
        "        multi_ops = study_config[\"manipulation_module\"][\"operations\"][\"multi_stock\"]\n",
        "\n",
        "        # Inner Wrapper (Stateful for global_step)\n",
        "        class InnerWrapper:\n",
        "            def __init__(self):\n",
        "                self.step = 0\n",
        "            def __call__(self, x, y, a, p, l):\n",
        "                self.step += 1\n",
        "                return inner_loop_manipulation_wrapper(\n",
        "                    x, y, a, p, l, single_ops, multi_ops,\n",
        "                    transformer_registry, mixup_registry, 42, self.step\n",
        "                )\n",
        "\n",
        "        inner_fn = InnerWrapper()\n",
        "\n",
        "        # Outer Wrapper (Weighted)\n",
        "        outer_fn = partial(\n",
        "            weighted_mixture_fn,\n",
        "            single_stock_ops=single_ops,\n",
        "            multi_stock_ops=multi_ops,\n",
        "            transformer_registry=transformer_registry,\n",
        "            mixup_registry=mixup_registry,\n",
        "            base_seed=42\n",
        "        )\n",
        "\n",
        "        # Train\n",
        "        trained_model, trained_planner, history = joint_training_fn(\n",
        "            model, planner, train_loader, valid_loader, study_config,\n",
        "            (inner_fn, outer_fn), scheduler_step_fn\n",
        "        )\n",
        "\n",
        "        # Evaluate\n",
        "        metrics = evaluate_test_set(trained_model, test_loader, nn.MSELoss())\n",
        "        results[model_name] = {\n",
        "            \"metrics\": metrics,\n",
        "            \"history\": history,\n",
        "            \"model_state\": trained_model.state_dict(),\n",
        "            \"planner_state\": trained_planner.state_dict()\n",
        "        }\n",
        "\n",
        "        logger.info(f\"Model {model_name} Results: {metrics}\")\n",
        "\n",
        "    logger.info(\"Pipeline Completed.\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "nKho4c6KKf_4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 28 — Implement the RL environment (single-asset, discrete, all-in/all-out)\n",
        "\n",
        "# ===============================================================================\n",
        "# Task 28: Implement the RL environment (single-asset, discrete, all-in/all-out)\n",
        "# ===============================================================================\n",
        "\n",
        "class TradingEnvironment:\n",
        "    \"\"\"\n",
        "    Single-asset trading environment for Reinforcement Learning.\n",
        "\n",
        "    Implements a discrete action space (Sell, Hold, Buy) with an all-in/all-out\n",
        "    position sizing logic. The environment simulates portfolio value evolution\n",
        "    accounting for transaction costs and market returns.\n",
        "\n",
        "    MDP Definition:\n",
        "        State s_t: [x_{t-L+1:t}, p_t] (Windowed features + Current Position)\n",
        "        Action a_t: {-1, 0, 1} (Sell, Hold, Buy)\n",
        "        Reward r_t: p_{t-1} * r_mkt_t - c * |delta p_t|\n",
        "        Discount gamma: 0.99\n",
        "\n",
        "    Attributes:\n",
        "        data (Dict[pd.Timestamp, np.ndarray]): Feature windows indexed by date.\n",
        "        prices (pd.Series): Adjusted close prices for valuation.\n",
        "        returns (pd.Series): Market returns (Close-to-Close) for reward calculation.\n",
        "        transaction_cost (float): Cost ratio c (default 1e-3).\n",
        "        initial_capital (float): Starting cash (default 1e4).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        data: Dict[Any, np.ndarray], # Date -> Window\n",
        "        prices: Any, # pd.Series or dict\n",
        "        returns: Any, # pd.Series or dict\n",
        "        dates: List[Any], # Sorted list of valid dates\n",
        "        transaction_cost: float = 1e-3,\n",
        "        initial_capital: float = 1e4\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializes the trading environment.\n",
        "\n",
        "        Args:\n",
        "            data: Dictionary mapping timestamps to feature windows (x_t).\n",
        "            prices: Series/Dict of prices (P_t) for valuation.\n",
        "            returns: Series/Dict of market returns (r_t) for rewards.\n",
        "            dates: Sorted list of timestamps defining the episode trajectory.\n",
        "            transaction_cost: Transaction cost parameter c.\n",
        "            initial_capital: Initial portfolio value.\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.prices = prices\n",
        "        self.returns = returns\n",
        "        self.dates = dates\n",
        "        self.transaction_cost = transaction_cost\n",
        "        self.initial_capital = initial_capital\n",
        "\n",
        "        # State variables\n",
        "        self.current_step = 0\n",
        "        self.position = 0 # 0: Cash, 1: Invested\n",
        "        self.cash = initial_capital\n",
        "        self.shares = 0.0\n",
        "        self.portfolio_value = initial_capital\n",
        "        self.history = []\n",
        "\n",
        "    def reset(self) -> Tuple[Tuple[np.ndarray, int], Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Resets the environment to the beginning of the episode.\n",
        "\n",
        "        Returns:\n",
        "            state: (Initial Window, Initial Position)\n",
        "            info: Metadata\n",
        "        \"\"\"\n",
        "        self.current_step = 0\n",
        "        self.position = 0\n",
        "        self.cash = self.initial_capital\n",
        "        self.shares = 0.0\n",
        "        self.portfolio_value = self.initial_capital\n",
        "        self.history = []\n",
        "\n",
        "        # Get initial observation\n",
        "        date = self.dates[self.current_step]\n",
        "        window = self.data[date]\n",
        "\n",
        "        return (window, self.position), {}\n",
        "\n",
        "    def step(self, action: int) -> Tuple[Tuple[np.ndarray, int], float, bool, bool, Dict[str, Any]]:\n",
        "        \"\"\"\n",
        "        Executes one time step in the environment.\n",
        "\n",
        "        Logic:\n",
        "        1. Determine new position based on action.\n",
        "        2. Execute trade if position changes (incur cost).\n",
        "        3. Advance time (t -> t+1).\n",
        "        4. Update portfolio value based on new price P_{t+1}.\n",
        "        5. Compute reward.\n",
        "\n",
        "        Args:\n",
        "            action (int): -1 (Sell), 0 (Hold), 1 (Buy).\n",
        "\n",
        "        Returns:\n",
        "            state: (Next Window, Next Position)\n",
        "            reward: Scalar reward\n",
        "            terminated: Boolean\n",
        "            truncated: Boolean\n",
        "            info: Metadata\n",
        "        \"\"\"\n",
        "        # Current state at t\n",
        "        current_date = self.dates[self.current_step]\n",
        "        current_price = self.prices[current_date]\n",
        "        prev_position = self.position\n",
        "\n",
        "        # 1. Determine New Position\n",
        "        # Action interpretation:\n",
        "        # 1 (Buy): Enter Long (p=1)\n",
        "        # -1 (Sell): Exit to Cash (p=0)\n",
        "        # 0 (Hold): Keep current p\n",
        "\n",
        "        if action == 1:\n",
        "            new_position = 1\n",
        "        elif action == -1:\n",
        "            new_position = 0\n",
        "        else:\n",
        "            new_position = prev_position\n",
        "\n",
        "        # 2. Execution & Costs\n",
        "        trade_cost_val = 0.0\n",
        "\n",
        "        if new_position != prev_position:\n",
        "            # Regime switch\n",
        "            if new_position == 1: # Buy\n",
        "                # Cash -> Shares\n",
        "                # Value available to buy\n",
        "                investible = self.cash * (1 - self.transaction_cost)\n",
        "                self.shares = investible / current_price\n",
        "                self.cash = 0.0\n",
        "                trade_cost_val = self.cash * self.transaction_cost # Approximation\n",
        "            else: # Sell\n",
        "                # Shares -> Cash\n",
        "                # Value realized\n",
        "                proceeds = (self.shares * current_price) * (1 - self.transaction_cost)\n",
        "                self.cash = proceeds\n",
        "                self.shares = 0.0\n",
        "                trade_cost_val = (self.shares * current_price) * self.transaction_cost\n",
        "\n",
        "        self.position = new_position\n",
        "\n",
        "        # 3. Advance Time\n",
        "        self.current_step += 1\n",
        "        terminated = self.current_step >= len(self.dates) - 1\n",
        "\n",
        "        if terminated:\n",
        "            # End of episode\n",
        "            # No next state, reward is 0 or final value?\n",
        "            # Usually we return last valid state and 0 reward or final return.\n",
        "            # Let's return current state and 0 reward.\n",
        "            return (self.data[current_date], self.position), 0.0, True, False, {\"portfolio_value\": self.portfolio_value}\n",
        "\n",
        "        next_date = self.dates[self.current_step]\n",
        "        next_window = self.data[next_date]\n",
        "        next_price = self.prices[next_date]\n",
        "\n",
        "        # 4. Update Portfolio Value\n",
        "        # V_{t+1} = cash + shares * P_{t+1}\n",
        "        self.portfolio_value = self.cash + self.shares * next_price\n",
        "\n",
        "        # 5. Compute Reward\n",
        "        # r_t = p_t * r_mkt - c * |delta p|\n",
        "        # Market return t -> t+1\n",
        "        # r_mkt = (P_{t+1} - P_t) / P_t\n",
        "        # We can use the pre-computed returns series if aligned, or compute on fly.\n",
        "        # Using prices is safer for alignment.\n",
        "        r_mkt = (next_price - current_price) / current_price\n",
        "\n",
        "        # Cost penalty\n",
        "        # c * |new - prev|\n",
        "        # Note: This is a \"reward shaping\" term. The actual cost is embedded in V_t.\n",
        "        # We should use the reward definition for the agent's signal.\n",
        "        cost_penalty = self.transaction_cost * abs(new_position - prev_position)\n",
        "\n",
        "        reward = new_position * r_mkt - cost_penalty\n",
        "\n",
        "        info = {\n",
        "            \"date\": next_date,\n",
        "            \"portfolio_value\": self.portfolio_value,\n",
        "            \"market_return\": r_mkt,\n",
        "            \"position\": new_position\n",
        "        }\n",
        "\n",
        "        return (next_window, new_position), reward, False, False, info\n"
      ],
      "metadata": {
        "id": "J4U6JvyXOGDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 29 — Implement DQN agent\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 29: Implement DQN agent\n",
        "# ==============================================================================\n",
        "\n",
        "class ReplayBuffer:\n",
        "    \"\"\"\n",
        "    Experience Replay Buffer for Deep Q-Network (DQN).\n",
        "\n",
        "    Stores transitions (state, action, reward, next_state, done) to break temporal\n",
        "    correlations in the training data and improve sample efficiency.\n",
        "\n",
        "    Attributes:\n",
        "        buffer (Deque): A double-ended queue with a fixed maximum length to store transitions.\n",
        "        rng (random.Random): A seeded random number generator for reproducible sampling.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, capacity: int, seed: int) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the ReplayBuffer.\n",
        "\n",
        "        Args:\n",
        "            capacity (int): The maximum number of transitions the buffer can hold.\n",
        "            seed (int): The seed for the random number generator.\n",
        "        \"\"\"\n",
        "        self.buffer: Deque[Tuple[Any, int, float, Any, bool]] = deque(maxlen=capacity)\n",
        "        self.rng = random.Random(seed)\n",
        "\n",
        "    def push(\n",
        "        self,\n",
        "        state: Tuple[np.ndarray, int],\n",
        "        action: int,\n",
        "        reward: float,\n",
        "        next_state: Tuple[np.ndarray, int],\n",
        "        done: bool\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Adds a transition to the buffer.\n",
        "\n",
        "        Args:\n",
        "            state (Tuple[np.ndarray, int]): The current state (window, position).\n",
        "            action (int): The action taken.\n",
        "            reward (float): The reward received.\n",
        "            next_state (Tuple[np.ndarray, int]): The resulting state.\n",
        "            done (bool): Whether the episode terminated.\n",
        "        \"\"\"\n",
        "        self.buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def sample(self, batch_size: int) -> List[Tuple[Any, int, float, Any, bool]]:\n",
        "        \"\"\"\n",
        "        Samples a random batch of transitions from the buffer.\n",
        "\n",
        "        Args:\n",
        "            batch_size (int): The number of transitions to sample.\n",
        "\n",
        "        Returns:\n",
        "            List[Tuple]: A list of sampled transitions.\n",
        "        \"\"\"\n",
        "        return self.rng.sample(self.buffer, batch_size)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        \"\"\"\n",
        "        Returns the current number of transitions in the buffer.\n",
        "        \"\"\"\n",
        "        return len(self.buffer)\n",
        "\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Q-Network architecture for the DQN Agent.\n",
        "\n",
        "    This network estimates the Q-values Q(s, a) for a given state s and all possible actions a.\n",
        "    The state consists of a time-series window of market features and the current portfolio position.\n",
        "\n",
        "    Architecture:\n",
        "        1. Encoder: An LSTM processes the time-series window to produce a latent embedding.\n",
        "        2. Fusion: The embedding is concatenated with the current position indicator.\n",
        "        3. Head: A Multi-Layer Perceptron (MLP) maps the fused state to Q-values for each action.\n",
        "\n",
        "    Attributes:\n",
        "        encoder (nn.LSTM): The recurrent encoder for the time-series window.\n",
        "        head (nn.Sequential): The fully connected layers producing Q-values.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: int, embedding_dim: int = 128, n_actions: int = 3) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the QNetwork.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): The number of features in the input time-series window.\n",
        "            embedding_dim (int): The dimension of the latent embedding produced by the encoder.\n",
        "                                 Default is 128, consistent with the Planner's embedding size.\n",
        "            n_actions (int): The number of possible actions (Sell, Hold, Buy). Default is 3.\n",
        "        \"\"\"\n",
        "        super(QNetwork, self).__init__()\n",
        "\n",
        "        # Encoder (Depth 1 LSTM as implied by manuscript \"depth at 1\")\n",
        "        # batch_first=True ensures input shape is (Batch, Length, Features)\n",
        "        self.encoder = nn.LSTM(input_dim, embedding_dim, num_layers=1, batch_first=True)\n",
        "\n",
        "        # Head\n",
        "        # Input dimension: embedding (128) + position (1) = 129\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(embedding_dim + 1, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, n_actions)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor, p: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass to compute Q-values.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input time-series window of shape (Batch, Length, Features).\n",
        "            p (torch.Tensor): The current position indicator of shape (Batch, 1).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The estimated Q-values for each action, shape (Batch, n_actions).\n",
        "        \"\"\"\n",
        "        # Encode window\n",
        "        # LSTM output: (Batch, Length, Hidden)\n",
        "        # We take the output of the last time step as the representation of the sequence\n",
        "        out, _ = self.encoder(x)\n",
        "        embedding = out[:, -1, :]\n",
        "\n",
        "        # Concatenate position to the embedding\n",
        "        # embedding: (Batch, 128), p: (Batch, 1) -> state: (Batch, 129)\n",
        "        state = torch.cat([embedding, p], dim=1)\n",
        "\n",
        "        # Compute Q-values\n",
        "        return self.head(state)\n",
        "\n",
        "\n",
        "class DQNAgent:\n",
        "    \"\"\"\n",
        "    Deep Q-Network (DQN) Agent for single-asset trading.\n",
        "\n",
        "    This agent learns a policy to maximize the expected cumulative reward by estimating\n",
        "    the Q-value function Q(s, a). It uses an epsilon-greedy strategy for exploration\n",
        "    and a target network to stabilize training.\n",
        "\n",
        "    Hyperparameters (from Manuscript Part 2):\n",
        "        - Gamma (Discount Factor): 0.99\n",
        "        - Learning Rate: 2.5e-4\n",
        "        - Batch Size: 128\n",
        "        - Target Update Frequency: 500 steps\n",
        "        - Exploration Fraction: 0.5 (Linear decay of epsilon over the first 50% of total steps)\n",
        "\n",
        "    Attributes:\n",
        "        policy_net (QNetwork): The neural network used to select actions.\n",
        "        target_net (QNetwork): A frozen copy of the policy network used to compute TD targets.\n",
        "        optimizer (optim.Adam): The optimizer for updating policy network weights.\n",
        "        memory (ReplayBuffer): The experience replay buffer.\n",
        "        rng (np.random.Generator): Random number generator for action selection.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        total_steps: int,\n",
        "        seed: int,\n",
        "        device: str = \"cpu\",\n",
        "        gamma: float = 0.99,\n",
        "        lr: float = 2.5e-4,\n",
        "        batch_size: int = 128,\n",
        "        target_update_freq: int = 500,\n",
        "        exploration_fraction: float = 0.5,\n",
        "        initial_epsilon: float = 1.0,\n",
        "        final_epsilon: float = 0.01,\n",
        "        buffer_size: int = 100000\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the DQN Agent.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Number of features in the input state window.\n",
        "            total_steps (int): Total number of training steps (for epsilon decay schedule).\n",
        "            seed (int): Random seed for reproducibility.\n",
        "            device (str): Computation device ('cpu' or 'cuda').\n",
        "            gamma (float): Discount factor for future rewards.\n",
        "            lr (float): Learning rate for the Adam optimizer.\n",
        "            batch_size (int): Number of transitions to sample from replay buffer.\n",
        "            target_update_freq (int): Frequency (in steps) to update the target network.\n",
        "            exploration_fraction (float): Fraction of total steps over which epsilon decays.\n",
        "            initial_epsilon (float): Starting value of epsilon.\n",
        "            final_epsilon (float): Minimum value of epsilon.\n",
        "            buffer_size (int): Maximum capacity of the replay buffer.\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        self.gamma = gamma\n",
        "        self.batch_size = batch_size\n",
        "        self.target_update_freq = target_update_freq\n",
        "\n",
        "        # Epsilon Schedule Parameters\n",
        "        self.total_steps = total_steps\n",
        "        self.decay_steps = int(total_steps * exploration_fraction)\n",
        "        self.initial_epsilon = initial_epsilon\n",
        "        self.final_epsilon = final_epsilon\n",
        "\n",
        "        # Networks\n",
        "        self.policy_net = QNetwork(input_dim).to(device)\n",
        "        self.target_net = QNetwork(input_dim).to(device)\n",
        "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "        self.target_net.eval() # Target network is always in eval mode\n",
        "\n",
        "        self.optimizer = optim.Adam(self.policy_net.parameters(), lr=lr)\n",
        "        self.memory = ReplayBuffer(buffer_size, seed)\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "\n",
        "        self.steps_done = 0\n",
        "\n",
        "    def get_epsilon(self) -> float:\n",
        "        \"\"\"\n",
        "        Computes the current epsilon value based on a linear decay schedule.\n",
        "\n",
        "        Returns:\n",
        "            float: The current epsilon probability for exploration.\n",
        "        \"\"\"\n",
        "        if self.steps_done >= self.decay_steps:\n",
        "            return self.final_epsilon\n",
        "\n",
        "        slope = (self.final_epsilon - self.initial_epsilon) / self.decay_steps\n",
        "        return self.initial_epsilon + slope * self.steps_done\n",
        "\n",
        "    def select_action(self, x: np.ndarray, p: int) -> int:\n",
        "        \"\"\"\n",
        "        Selects an action using the epsilon-greedy policy.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): The current market feature window (L, F).\n",
        "            p (int): The current position indicator (0 or 1).\n",
        "\n",
        "        Returns:\n",
        "            int: The selected action index mapped to {-1, 0, 1}.\n",
        "        \"\"\"\n",
        "        epsilon = self.get_epsilon()\n",
        "\n",
        "        # Exploration: Random action\n",
        "        if self.rng.random() < epsilon:\n",
        "            return self.rng.integers(0, 3) - 1 # Returns one of {-1, 0, 1}\n",
        "\n",
        "        # Exploitation: Greedy action from Q-network\n",
        "        with torch.no_grad():\n",
        "            x_t = torch.FloatTensor(x).unsqueeze(0).to(self.device)\n",
        "            p_t = torch.FloatTensor([[p]]).to(self.device)\n",
        "            q_values = self.policy_net(x_t, p_t)\n",
        "\n",
        "            # Map output index 0,1,2 -> action -1,0,1\n",
        "            action_idx = q_values.argmax().item()\n",
        "            return action_idx - 1\n",
        "\n",
        "    def update(self) -> None:\n",
        "        \"\"\"\n",
        "        Performs one step of optimization on the policy network.\n",
        "\n",
        "        Samples a batch from the replay buffer, computes the TD error, and updates weights.\n",
        "        Also handles the periodic update of the target network.\n",
        "        \"\"\"\n",
        "        if len(self.memory) < self.batch_size:\n",
        "            return\n",
        "\n",
        "        transitions = self.memory.sample(self.batch_size)\n",
        "        # Transpose batch of tuples to tuple of batches\n",
        "        batch = list(zip(*transitions))\n",
        "\n",
        "        # Unpack and convert to tensors\n",
        "        # State is a tuple (x, p)\n",
        "        state_batch = batch[0]\n",
        "        x_batch = torch.FloatTensor(np.stack([s[0] for s in state_batch])).to(self.device)\n",
        "        p_batch = torch.FloatTensor(np.stack([[s[1]] for s in state_batch])).to(self.device)\n",
        "\n",
        "        # Action: Map -1,0,1 -> 0,1,2 for indexing\n",
        "        action_batch = torch.LongTensor(batch[1]).to(self.device) + 1\n",
        "        reward_batch = torch.FloatTensor(batch[2]).to(self.device)\n",
        "\n",
        "        next_state_batch = batch[3]\n",
        "        next_x_batch = torch.FloatTensor(np.stack([s[0] for s in next_state_batch])).to(self.device)\n",
        "        next_p_batch = torch.FloatTensor(np.stack([[s[1]] for s in next_state_batch])).to(self.device)\n",
        "\n",
        "        done_batch = torch.FloatTensor(batch[4]).to(self.device)\n",
        "\n",
        "        # Compute Q(s, a)\n",
        "        # policy_net outputs (B, 3). gather selects the Q-value corresponding to the action taken.\n",
        "        q_values = self.policy_net(x_batch, p_batch).gather(1, action_batch.unsqueeze(1)).squeeze(1)\n",
        "\n",
        "        # Compute V(s') = max_a Q_target(s', a)\n",
        "        # We use the target network for stability.\n",
        "        with torch.no_grad():\n",
        "            next_q_values = self.target_net(next_x_batch, next_p_batch).max(1)[0]\n",
        "            # Bellman Target: r + gamma * max Q(s', a') * (1 - done)\n",
        "            expected_q_values = reward_batch + self.gamma * next_q_values * (1 - done_batch)\n",
        "\n",
        "        # Compute Loss (MSE)\n",
        "        loss = nn.MSELoss()(q_values, expected_q_values)\n",
        "\n",
        "        # Optimize\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # Gradient clipping for stability\n",
        "        torch.nn.utils.clip_grad_norm_(self.policy_net.parameters(), 1.0)\n",
        "        self.optimizer.step()\n",
        "\n",
        "        # Target Network Update\n",
        "        if self.steps_done % self.target_update_freq == 0:\n",
        "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
        "\n",
        "        self.steps_done += 1\n"
      ],
      "metadata": {
        "id": "cOwt4zDhQzpD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 30 — Implement PPO agent\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 30: Implement PPO agent\n",
        "# ==============================================================================\n",
        "\n",
        "class ActorCritic(nn.Module):\n",
        "    \"\"\"\n",
        "    Actor-Critic network architecture for the PPO Agent.\n",
        "\n",
        "    This module encapsulates both the Policy (Actor) and Value (Critic) networks.\n",
        "    Following the manuscript's setup and standard PPO practices for stability,\n",
        "    it uses separate encoders for the actor and critic, allowing for distinct\n",
        "    learning rates and preventing interference between policy and value learning.\n",
        "\n",
        "    Architecture:\n",
        "        - Actor: LSTM Encoder -> Fusion (with position) -> MLP Head -> Action Logits\n",
        "        - Critic: LSTM Encoder -> Fusion (with position) -> MLP Head -> Scalar Value\n",
        "\n",
        "    Attributes:\n",
        "        actor_encoder (nn.LSTM): Encodes the time-series window for the policy.\n",
        "        actor_head (nn.Sequential): Maps fused state to action logits.\n",
        "        critic_encoder (nn.LSTM): Encodes the time-series window for the value function.\n",
        "        critic_head (nn.Sequential): Maps fused state to scalar value.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, input_dim: int, embedding_dim: int = 128, n_actions: int = 3) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the ActorCritic network.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Number of features in the input time-series window.\n",
        "            embedding_dim (int): Dimension of the latent embedding. Default 128.\n",
        "            n_actions (int): Number of discrete actions. Default 3.\n",
        "        \"\"\"\n",
        "        super(ActorCritic, self).__init__()\n",
        "\n",
        "        # Actor Network\n",
        "        self.actor_encoder = nn.LSTM(input_dim, embedding_dim, num_layers=1, batch_first=True)\n",
        "        # Input to head: embedding (128) + position (1)\n",
        "        self.actor_head = nn.Sequential(\n",
        "            nn.Linear(embedding_dim + 1, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, n_actions)\n",
        "        )\n",
        "\n",
        "        # Critic Network\n",
        "        self.critic_encoder = nn.LSTM(input_dim, embedding_dim, num_layers=1, batch_first=True)\n",
        "        self.critic_head = nn.Sequential(\n",
        "            nn.Linear(embedding_dim + 1, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self) -> None:\n",
        "        \"\"\"\n",
        "        Forward is not used directly; use get_action_and_value or get_value.\n",
        "        \"\"\"\n",
        "        raise NotImplementedError(\"Use get_action_and_value or get_value\")\n",
        "\n",
        "    def get_value(self, x: torch.Tensor, p: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Computes the value function V(s).\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Time-series window (Batch, Length, Features).\n",
        "            p (torch.Tensor): Position indicator (Batch, 1).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Scalar value estimate V(s) of shape (Batch, 1).\n",
        "        \"\"\"\n",
        "        out, _ = self.critic_encoder(x)\n",
        "        embedding = out[:, -1, :]\n",
        "        state = torch.cat([embedding, p], dim=1)\n",
        "        return self.critic_head(state)\n",
        "\n",
        "    def get_action_and_value(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        p: torch.Tensor,\n",
        "        action: Optional[torch.Tensor] = None\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"\n",
        "        Computes action distribution, sampled action, log probability, entropy, and value.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Time-series window.\n",
        "            p (torch.Tensor): Position indicator.\n",
        "            action (Optional[torch.Tensor]): If provided, computes log_prob for this action.\n",
        "                                             If None, samples a new action.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "                - action: The selected action indices.\n",
        "                - log_prob: Log probability of the selected action.\n",
        "                - entropy: Entropy of the action distribution (for regularization).\n",
        "                - value: Estimated value of the state.\n",
        "        \"\"\"\n",
        "        # Actor Forward Pass\n",
        "        out_a, _ = self.actor_encoder(x)\n",
        "        embedding_a = out_a[:, -1, :]\n",
        "        state_a = torch.cat([embedding_a, p], dim=1)\n",
        "        logits = self.actor_head(state_a)\n",
        "        probs = Categorical(logits=logits)\n",
        "\n",
        "        if action is None:\n",
        "            action = probs.sample()\n",
        "\n",
        "        log_prob = probs.log_prob(action)\n",
        "        entropy = probs.entropy()\n",
        "\n",
        "        # Critic Forward Pass\n",
        "        value = self.get_value(x, p)\n",
        "\n",
        "        return action, log_prob, entropy, value\n",
        "\n",
        "\n",
        "class PPOAgent:\n",
        "    \"\"\"\n",
        "    Proximal Policy Optimization (PPO) Agent.\n",
        "\n",
        "    Implements the PPO-Clip algorithm with Generalized Advantage Estimation (GAE).\n",
        "    This agent learns a stochastic policy for trading by optimizing a surrogate objective\n",
        "    that prevents large policy updates, ensuring stability.\n",
        "\n",
        "    Hyperparameters (from Manuscript Part 2):\n",
        "        - Policy Learning Rate: 5e-7\n",
        "        - Value Learning Rate: 1e-6\n",
        "        - GAE Lambda: 0.95\n",
        "        - Gamma (Discount): 0.99\n",
        "        - Value Coefficient: 0.5\n",
        "        - Entropy Coefficient: 0.01\n",
        "        - Target KL: 0.02 (for early stopping of updates)\n",
        "\n",
        "    Attributes:\n",
        "        network (ActorCritic): The neural network model.\n",
        "        optimizer (optim.Adam): The optimizer with parameter groups for actor and critic.\n",
        "        rng (np.random.Generator): Random number generator.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        input_dim: int,\n",
        "        seed: int,\n",
        "        device: str = \"cpu\",\n",
        "        gamma: float = 0.99,\n",
        "        gae_lambda: float = 0.95,\n",
        "        policy_lr: float = 5e-7,\n",
        "        value_lr: float = 1e-6,\n",
        "        value_coef: float = 0.5,\n",
        "        entropy_coef: float = 0.01,\n",
        "        target_kl: float = 0.02,\n",
        "        clip_coef: float = 0.2,\n",
        "        update_epochs: int = 10,\n",
        "        batch_size: int = 64\n",
        "    ) -> None:\n",
        "        \"\"\"\n",
        "        Initializes the PPO Agent.\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Number of input features.\n",
        "            seed (int): Random seed.\n",
        "            device (str): Computation device.\n",
        "            gamma (float): Discount factor.\n",
        "            gae_lambda (float): GAE smoothing parameter.\n",
        "            policy_lr (float): Learning rate for the actor.\n",
        "            value_lr (float): Learning rate for the critic.\n",
        "            value_coef (float): Weight of value loss in total loss.\n",
        "            entropy_coef (float): Weight of entropy bonus.\n",
        "            target_kl (float): KL divergence threshold for early stopping.\n",
        "            clip_coef (float): PPO clipping parameter (epsilon).\n",
        "            update_epochs (int): Number of epochs to update per rollout.\n",
        "            batch_size (int): Mini-batch size for updates.\n",
        "        \"\"\"\n",
        "        self.device = device\n",
        "        self.gamma = gamma\n",
        "        self.gae_lambda = gae_lambda\n",
        "        self.value_coef = value_coef\n",
        "        self.entropy_coef = entropy_coef\n",
        "        self.target_kl = target_kl\n",
        "        self.clip_coef = clip_coef\n",
        "        self.update_epochs = update_epochs\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.network = ActorCritic(input_dim).to(device)\n",
        "\n",
        "        # Separate parameter groups for distinct learning rates\n",
        "        self.optimizer = optim.Adam([\n",
        "            {'params': self.network.actor_encoder.parameters(), 'lr': policy_lr},\n",
        "            {'params': self.network.actor_head.parameters(), 'lr': policy_lr},\n",
        "            {'params': self.network.critic_encoder.parameters(), 'lr': value_lr},\n",
        "            {'params': self.network.critic_head.parameters(), 'lr': value_lr}\n",
        "        ])\n",
        "\n",
        "        self.rng = np.random.default_rng(seed)\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "    def get_action(self, x: np.ndarray, p: int) -> Tuple[int, float, float]:\n",
        "        \"\"\"\n",
        "        Selects an action for the current state during interaction.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): Feature window (L, F).\n",
        "            p (int): Position indicator.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[int, float, float]:\n",
        "                - action_idx: Selected action mapped to {-1, 0, 1}.\n",
        "                - log_prob: Log probability of the action.\n",
        "                - value: Estimated state value.\n",
        "        \"\"\"\n",
        "        self.network.eval()\n",
        "        with torch.no_grad():\n",
        "            x_t = torch.FloatTensor(x).unsqueeze(0).to(self.device)\n",
        "            p_t = torch.FloatTensor([[p]]).to(self.device)\n",
        "\n",
        "            action, log_prob, _, value = self.network.get_action_and_value(x_t, p_t)\n",
        "\n",
        "            action_idx = action.item()\n",
        "            # Map 0,1,2 -> -1,0,1\n",
        "            return action_idx - 1, log_prob.item(), value.item()\n",
        "\n",
        "    def update(self, rollouts: Dict[str, Any]) -> None:\n",
        "        \"\"\"\n",
        "        Performs the PPO update using collected trajectories.\n",
        "\n",
        "        Computes Generalized Advantage Estimation (GAE), normalizes advantages,\n",
        "        and updates the network using the clipped surrogate objective.\n",
        "\n",
        "        Args:\n",
        "            rollouts (Dict[str, Any]): Dictionary containing arrays of:\n",
        "                - 'x': Feature windows.\n",
        "                - 'p': Positions.\n",
        "                - 'actions': Actions taken (mapped to -1,0,1).\n",
        "                - 'logprobs': Log probabilities of actions.\n",
        "                - 'rewards': Rewards received.\n",
        "                - 'dones': Termination flags.\n",
        "                - 'values': Value estimates.\n",
        "        \"\"\"\n",
        "        self.network.train()\n",
        "\n",
        "        # Unpack and convert to tensors\n",
        "        obs_x = torch.FloatTensor(rollouts['x']).to(self.device)\n",
        "        obs_p = torch.FloatTensor(rollouts['p']).to(self.device)\n",
        "\n",
        "        # Map actions -1,0,1 -> 0,1,2 for Categorical\n",
        "        actions = torch.LongTensor(rollouts['actions']).to(self.device) + 1\n",
        "        logprobs = torch.FloatTensor(rollouts['logprobs']).to(self.device)\n",
        "        rewards = torch.FloatTensor(rollouts['rewards']).to(self.device)\n",
        "        dones = torch.FloatTensor(rollouts['dones']).to(self.device)\n",
        "        values = torch.FloatTensor(rollouts['values']).to(self.device)\n",
        "\n",
        "        # Compute GAE and Returns\n",
        "        with torch.no_grad():\n",
        "            advantages = torch.zeros_like(rewards).to(self.device)\n",
        "            lastgaelam = 0\n",
        "            # Assume next_value is 0 for the last step of the rollout chunk for simplicity,\n",
        "            # or that the rollout includes the bootstrap value.\n",
        "            # Standard implementation iterates backwards.\n",
        "            for t in reversed(range(len(rewards))):\n",
        "                if t == len(rewards) - 1:\n",
        "                    nextnonterminal = 1.0 - dones[t]\n",
        "                    nextvalues = 0 # Bootstrap value should ideally be passed in\n",
        "                else:\n",
        "                    nextnonterminal = 1.0 - dones[t]\n",
        "                    nextvalues = values[t+1]\n",
        "\n",
        "                delta = rewards[t] + self.gamma * nextvalues * nextnonterminal - values[t]\n",
        "                advantages[t] = lastgaelam = delta + self.gamma * self.gae_lambda * nextnonterminal * lastgaelam\n",
        "\n",
        "            returns = advantages + values\n",
        "\n",
        "        # Flatten batch for PPO epochs\n",
        "        b_obs_x = obs_x\n",
        "        b_obs_p = obs_p\n",
        "        b_logprobs = logprobs\n",
        "        b_actions = actions\n",
        "        b_advantages = advantages\n",
        "        b_returns = returns\n",
        "\n",
        "        # PPO Update Loop\n",
        "        for epoch in range(self.update_epochs):\n",
        "            # Shuffle indices\n",
        "            indices = np.arange(len(b_obs_x))\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "            for start in range(0, len(b_obs_x), self.batch_size):\n",
        "                end = start + self.batch_size\n",
        "                mb_inds = indices[start:end]\n",
        "\n",
        "                # Evaluate current policy\n",
        "                _, newlogprob, entropy, newvalue = self.network.get_action_and_value(\n",
        "                    b_obs_x[mb_inds], b_obs_p[mb_inds], b_actions[mb_inds]\n",
        "                )\n",
        "\n",
        "                # Ratios\n",
        "                logratio = newlogprob - b_logprobs[mb_inds]\n",
        "                ratio = logratio.exp()\n",
        "\n",
        "                # KL Divergence Check\n",
        "                with torch.no_grad():\n",
        "                    # http://joschu.net/blog/kl-approx.html\n",
        "                    approx_kl = ((ratio - 1) - logratio).mean()\n",
        "\n",
        "                if self.target_kl is not None and approx_kl > self.target_kl:\n",
        "                    break # Early stopping for this batch/epoch\n",
        "\n",
        "                # Normalize Advantages\n",
        "                mb_advantages = b_advantages[mb_inds]\n",
        "                mb_advantages = (mb_advantages - mb_advantages.mean()) / (mb_advantages.std() + 1e-8)\n",
        "\n",
        "                # Policy Loss (Clipped Surrogate)\n",
        "                pg_loss1 = -mb_advantages * ratio\n",
        "                pg_loss2 = -mb_advantages * torch.clamp(ratio, 1 - self.clip_coef, 1 + self.clip_coef)\n",
        "                pg_loss = torch.max(pg_loss1, pg_loss2).mean()\n",
        "\n",
        "                # Value Loss (MSE)\n",
        "                newvalue = newvalue.view(-1)\n",
        "                v_loss = 0.5 * ((newvalue - b_returns[mb_inds]) ** 2).mean()\n",
        "\n",
        "                # Entropy Loss\n",
        "                entropy_loss = entropy.mean()\n",
        "\n",
        "                # Total Loss\n",
        "                loss = pg_loss - self.entropy_coef * entropy_loss + self.value_coef * v_loss\n",
        "\n",
        "                # Optimize\n",
        "                self.optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                nn.utils.clip_grad_norm_(self.network.parameters(), 0.5)\n",
        "                self.optimizer.step()\n",
        "\n",
        "            # Check KL at epoch level\n",
        "            if self.target_kl is not None and approx_kl > self.target_kl:\n",
        "                break\n",
        "\n"
      ],
      "metadata": {
        "id": "c48nmokBXnbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 31 — Train RL agents under transferred planner policy\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 31: Train RL agents under transferred planner policy (Re-implementation)\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Helper: Alpha Schedule\n",
        "# ------------------------------------------------------------------------------\n",
        "def get_transfer_alpha(step: int) -> float:\n",
        "    \"\"\"\n",
        "    Returns the augmentation proportion alpha based on the transfer schedule\n",
        "    specified in the manuscript (Part 2).\n",
        "\n",
        "    Schedule:\n",
        "    - Steps 0 to 200,000: alpha = 0.0 (Baseline training)\n",
        "    - Steps 200,000 to 300,000: alpha = 0.05 (Curriculum injection)\n",
        "    - Steps 300,000+: alpha = 0.0 (Fine-tuning)\n",
        "\n",
        "    Args:\n",
        "        step (int): Current global training step.\n",
        "\n",
        "    Returns:\n",
        "        float: The alpha value.\n",
        "    \"\"\"\n",
        "    if step < 200_000:\n",
        "        return 0.0\n",
        "    elif step < 300_000:\n",
        "        return 0.05\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Helper: Planner Wrapper for RL\n",
        "# ------------------------------------------------------------------------------\n",
        "class RLPlannerWrapper:\n",
        "    \"\"\"\n",
        "    Wraps the pre-trained Planner for use in the RL loop.\n",
        "\n",
        "    Adapts the planner's output (n x m matrix) to the RL setting where\n",
        "    mix-up operations are disabled. It marginalizes the policy over the\n",
        "    multi-stock dimension to produce a policy for single-stock operations only.\n",
        "    \"\"\"\n",
        "    def __init__(self, planner: torch.nn.Module, transformer_registry: Any, device: str):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            planner: The trained Planner model.\n",
        "            transformer_registry: Registry containing single-stock operations.\n",
        "            device: Computation device.\n",
        "        \"\"\"\n",
        "        self.planner = planner\n",
        "        self.registry = transformer_registry\n",
        "        self.device = device\n",
        "        self.planner.eval() # Freeze planner weights\n",
        "\n",
        "    def augment_state(\n",
        "        self,\n",
        "        x: np.ndarray,\n",
        "        agent_embedding: torch.Tensor,\n",
        "        step: int,\n",
        "        alpha: float\n",
        "    ) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Applies augmentation to the RL state window x based on the planner's policy.\n",
        "\n",
        "        Args:\n",
        "            x (np.ndarray): Input window (L, F).\n",
        "            agent_embedding (torch.Tensor): Embedding from RL agent (1, 128).\n",
        "            step (int): Current step for seeding.\n",
        "            alpha (float): Probability of augmentation.\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Augmented window.\n",
        "        \"\"\"\n",
        "        # 1. Check Alpha (Bernoulli Mask)\n",
        "        rng = np.random.Generator(np.random.PCG64(step))\n",
        "        if rng.random() > alpha:\n",
        "            return x\n",
        "\n",
        "        # 2. Get Policy from Planner\n",
        "        # Planner expects (B, 128) embedding and (B, L, F) input\n",
        "        x_tensor = torch.FloatTensor(x).unsqueeze(0).to(self.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # p_matrix: (1, n, m), lambda_matrix: (1, n, m)\n",
        "            p_matrix, lambda_matrix = self.planner(agent_embedding, x_tensor)\n",
        "\n",
        "        # 3. Marginalize over Multi-Stock Ops (Remove Mixup)\n",
        "        # We sum probabilities over the multi-stock dimension (dim 2)\n",
        "        # p_single[i] = sum_j p[i, j]\n",
        "        p_single = p_matrix.sum(dim=2).squeeze(0) # (n,)\n",
        "\n",
        "        # We compute weighted average strength for each single op\n",
        "        # lambda_single[i] = sum_j (p[i, j] * lambda[i, j]) / p_single[i]\n",
        "        lambda_weighted = (p_matrix * lambda_matrix).sum(dim=2).squeeze(0)\n",
        "        lambda_single = lambda_weighted / (p_single + 1e-8)\n",
        "\n",
        "        # 4. Sample Single Op\n",
        "        p_np = p_single.cpu().numpy()\n",
        "        # Renormalize to ensure sum is exactly 1.0 (handling float errors)\n",
        "        p_sum = p_np.sum()\n",
        "        if p_sum > 0:\n",
        "            p_np /= p_sum\n",
        "        else:\n",
        "            # Fallback if p is all zero (unlikely with softmax)\n",
        "            p_np = np.ones_like(p_np) / len(p_np)\n",
        "\n",
        "        op_idx = rng.choice(len(p_np), p=p_np)\n",
        "        op_name = list(self.registry.ops.keys())[op_idx]\n",
        "        strength = lambda_single[op_idx].item()\n",
        "\n",
        "        # 5. Apply Operation\n",
        "        x_aug = self.registry.apply(x, op_name, strength, step)\n",
        "\n",
        "        return x_aug\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 31, Step 3: Train DQN and PPO\n",
        "# ------------------------------------------------------------------------------\n",
        "def train_rl_agent_with_transfer(\n",
        "    agent_type: str, # \"DQN\" or \"PPO\"\n",
        "    env: Any, # TradingEnvironment\n",
        "    planner: torch.nn.Module,\n",
        "    transformer_registry: Any,\n",
        "    total_steps: int = 400_000,\n",
        "    seed: int = 42\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Trains an RL agent using the transferred planner policy.\n",
        "\n",
        "    Args:\n",
        "        agent_type: \"DQN\" or \"PPO\".\n",
        "        env: Initialized TradingEnvironment.\n",
        "        planner: Trained Planner model.\n",
        "        transformer_registry: Registry for single-stock ops.\n",
        "        total_steps: Total training steps.\n",
        "        seed: Random seed.\n",
        "\n",
        "    Returns:\n",
        "        Dict containing training history.\n",
        "    \"\"\"\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Initialize Agent\n",
        "    # Get input dim from environment reset\n",
        "    sample_obs, _ = env.reset()\n",
        "    sample_window, _ = sample_obs\n",
        "    input_dim = sample_window.shape[1]\n",
        "\n",
        "    if agent_type == \"DQN\":\n",
        "        agent = DQNAgent(input_dim, total_steps, seed, device=device)\n",
        "    elif agent_type == \"PPO\":\n",
        "        agent = PPOAgent(input_dim, seed, device=device)\n",
        "    else:\n",
        "        raise ValueError(f\"Unknown agent type: {agent_type}\")\n",
        "\n",
        "    # Initialize Planner Wrapper\n",
        "    planner_wrapper = RLPlannerWrapper(planner.to(device), transformer_registry, device)\n",
        "\n",
        "    # Training Loop Variables\n",
        "    obs, _ = env.reset()\n",
        "    window, position = obs\n",
        "\n",
        "    rewards_history = []\n",
        "    portfolio_values = []\n",
        "\n",
        "    # PPO specific buffer\n",
        "    ppo_rollout = {'x': [], 'p': [], 'actions': [], 'logprobs': [], 'rewards': [], 'dones': [], 'values': []}\n",
        "\n",
        "    logger.info(f\"Starting training for {agent_type} with transfer...\")\n",
        "\n",
        "    for step in range(total_steps):\n",
        "        # 1. Get Alpha from Schedule\n",
        "        alpha = get_transfer_alpha(step)\n",
        "\n",
        "        # 2. Augment State\n",
        "        # Extract embedding from agent's encoder to condition the planner\n",
        "        x_tensor = torch.FloatTensor(window).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if agent_type == \"DQN\":\n",
        "                # DQN: policy_net.encoder -> (out, (h, c)) -> out[:, -1, :]\n",
        "                enc_out, _ = agent.policy_net.encoder(x_tensor)\n",
        "                embedding = enc_out[:, -1, :]\n",
        "            else:\n",
        "                # PPO: network.actor_encoder -> (out, (h, c)) -> out[:, -1, :]\n",
        "                enc_out, _ = agent.network.actor_encoder(x_tensor)\n",
        "                embedding = enc_out[:, -1, :]\n",
        "\n",
        "        window_aug = planner_wrapper.augment_state(window, embedding, step, alpha)\n",
        "\n",
        "        # 3. Select Action & Step\n",
        "        if agent_type == \"DQN\":\n",
        "            action = agent.select_action(window_aug, position)\n",
        "\n",
        "            next_obs, reward, term, trunc, info = env.step(action)\n",
        "            next_window, next_position = next_obs\n",
        "            done = term or trunc\n",
        "\n",
        "            # Store transition\n",
        "            agent.memory.push((window_aug, position), action, reward, (next_window, next_position), done)\n",
        "\n",
        "            # Update\n",
        "            agent.update()\n",
        "\n",
        "        elif agent_type == \"PPO\":\n",
        "            action, logprob, value = agent.get_action(window_aug, position)\n",
        "\n",
        "            next_obs, reward, term, trunc, info = env.step(action)\n",
        "            next_window, next_position = next_obs\n",
        "            done = term or trunc\n",
        "\n",
        "            # Store in rollout\n",
        "            ppo_rollout['x'].append(window_aug)\n",
        "            ppo_rollout['p'].append([position])\n",
        "            ppo_rollout['actions'].append(action)\n",
        "            ppo_rollout['logprobs'].append(logprob)\n",
        "            ppo_rollout['rewards'].append(reward)\n",
        "            ppo_rollout['dones'].append(done)\n",
        "            ppo_rollout['values'].append(value)\n",
        "\n",
        "            # Update PPO periodically\n",
        "            # PPO updates per batch of collected experience\n",
        "            # We use agent.batch_size * 10 as rollout length heuristic\n",
        "            if len(ppo_rollout['rewards']) >= agent.batch_size * 10:\n",
        "                # Convert lists to numpy arrays for update method\n",
        "                rollout_np = {k: np.array(v) for k, v in ppo_rollout.items()}\n",
        "                agent.update(rollout_np)\n",
        "                # Clear buffer\n",
        "                ppo_rollout = {k: [] for k in ppo_rollout}\n",
        "\n",
        "        # Logging\n",
        "        rewards_history.append(reward)\n",
        "        portfolio_values.append(info['portfolio_value'])\n",
        "\n",
        "        # Handle Episode End\n",
        "        if done:\n",
        "            obs, _ = env.reset()\n",
        "            window, position = obs\n",
        "        else:\n",
        "            window, position = next_window, next_position\n",
        "\n",
        "        if step % 10000 == 0:\n",
        "            logger.info(f\"Step {step}: PV {portfolio_values[-1]:.2f}, Alpha {alpha}\")\n",
        "\n",
        "    return {\n",
        "        \"rewards\": rewards_history,\n",
        "        \"portfolio_values\": portfolio_values,\n",
        "        \"final_value\": portfolio_values[-1]\n",
        "    }\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 31, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def run_rl_transfer_experiment(\n",
        "    planner_artifact: Dict[str, Any], # Contains trained planner state_dict\n",
        "    tensor_data: Dict[str, Any],\n",
        "    df_final: pd.DataFrame, # Real historical data\n",
        "    study_config: Dict[str, Any],\n",
        "    transformer_registry: Any\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 31: RL Transfer Experiment.\n",
        "\n",
        "    Executes the RL training process for both DQN and PPO agents using a\n",
        "    pre-trained Planner (transferred from LSTM forecasting task).\n",
        "\n",
        "    Crucially, this function extracts REAL historical price and return data\n",
        "    from df_final to ensure the RL environment reflects actual market dynamics,\n",
        "    validating the transfer learning hypothesis.\n",
        "\n",
        "    Args:\n",
        "        planner_artifact: Dictionary containing the trained planner's state_dict.\n",
        "        tensor_data: Dictionary containing RL data trajectories (windowed features).\n",
        "        df_final: The cleansed, curated DataFrame containing raw price series.\n",
        "        study_config: Master configuration dictionary.\n",
        "        transformer_registry: Registry for single-stock operations.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Results for DQN and PPO agents.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting RL Transfer Experiment...\")\n",
        "\n",
        "    # 1. Re-instantiate Planner\n",
        "    planner_cfg = study_config[\"planner\"]\n",
        "    n_ops_single = len(study_config[\"manipulation_module\"][\"operations\"][\"single_stock\"])\n",
        "    n_ops_multi = len(study_config[\"manipulation_module\"][\"operations\"][\"multi_stock\"])\n",
        "\n",
        "    # We assume the planner was trained with LSTM config\n",
        "    planner = Planner(\n",
        "        embedding_dim=128,\n",
        "        stats_dim=6,\n",
        "        planner_input_dim=planner_cfg[\"input_dim\"],\n",
        "        num_layers=planner_cfg[\"LSTM\"][\"layers\"],\n",
        "        nhead=4,\n",
        "        dim_feedforward=planner_cfg[\"input_dim\"] * 4,\n",
        "        n_ops_single=n_ops_single,\n",
        "        n_ops_multi=n_ops_multi\n",
        "    )\n",
        "\n",
        "    # Load weights (Simulated here, in prod use: planner.load_state_dict(planner_artifact['state_dict']))\n",
        "    if \"state_dict\" in planner_artifact:\n",
        "        planner.load_state_dict(planner_artifact[\"state_dict\"])\n",
        "    else:\n",
        "        logger.warning(\"No state_dict found in planner_artifact. Using initialized weights (Simulation).\")\n",
        "\n",
        "    # 2. Setup Environment with REAL Data\n",
        "    # We need to construct the environment from the tensor data.\n",
        "    # tensor_data[\"rl_data\"] is Dict[ticker, Dict[date, window]]\n",
        "    rl_data = tensor_data[\"rl_data\"]\n",
        "\n",
        "    # Select a ticker for the single-asset experiment (e.g., first one)\n",
        "    ticker = list(rl_data.keys())[0]\n",
        "    ticker_data = rl_data[ticker]\n",
        "    dates = sorted(list(ticker_data.keys()))\n",
        "\n",
        "    # Extract REAL prices and returns aligned with dates\n",
        "    # df_final is indexed by (date, ticker) or (ticker, date)\n",
        "    # We need to slice for the specific ticker and reindex to match 'dates'\n",
        "    # Ensure df_final is sorted\n",
        "    if df_final.index.names == [\"date\", \"ticker\"]:\n",
        "        df_ticker = df_final.xs(ticker, level=\"ticker\")\n",
        "    else:\n",
        "        df_ticker = df_final.xs(ticker, level=\"ticker\")\n",
        "\n",
        "    # Extract AdjClose (P_t) and target_return (r_t)\n",
        "    # Note: target_return was computed in Task 6. If not present, recompute.\n",
        "    if \"target_return\" not in df_ticker.columns:\n",
        "        # Fallback: Compute returns on the fly\n",
        "        # r_t = (C_{t+1} - C_t) / C_t\n",
        "        # We need to ensure alignment.\n",
        "        # Let's assume 'target_return' exists from Task 6.\n",
        "        raise ValueError(\"df_final must contain 'target_return' column from Task 6.\")\n",
        "\n",
        "    # Reindex to match the RL trajectory dates\n",
        "    # This ensures that for every step t in the environment, we have the correct P_t and r_t\n",
        "    df_aligned = df_ticker.reindex(dates)\n",
        "\n",
        "    # Check for missing data after alignment\n",
        "    if df_aligned.isnull().any().any():\n",
        "        logger.warning(\"Missing price/return data after alignment. Forward filling.\")\n",
        "        df_aligned = df_aligned.ffill().bfill()\n",
        "\n",
        "    # Convert to dictionaries for the environment\n",
        "    prices = df_aligned[\"AdjClose\"].to_dict()\n",
        "    returns = df_aligned[\"target_return\"].to_dict()\n",
        "\n",
        "    env = TradingEnvironment(ticker_data, prices, returns, dates)\n",
        "\n",
        "    # 3. Train Agents\n",
        "    results = {}\n",
        "    for agent_type in [\"DQN\", \"PPO\"]:\n",
        "        logger.info(f\"Training {agent_type}...\")\n",
        "        res = train_rl_agent_with_transfer(\n",
        "            agent_type, env, planner, transformer_registry\n",
        "        )\n",
        "        results[agent_type] = res\n",
        "\n",
        "    logger.info(\"RL Transfer Experiment Completed.\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "_ZeFbCa-ZBDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 32 — Implement trading evaluation metrics\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 32: Implement trading evaluation metrics\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 32, Step 1: Compute Total Return (TR)\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_total_return(portfolio_values: List[float]) -> float:\n",
        "    \"\"\"\n",
        "    Computes the Total Return (TR) of a trading strategy.\n",
        "\n",
        "    Equation:\n",
        "        TR = (P_T - P_0) / P_0\n",
        "\n",
        "    Where P_T is the final portfolio value and P_0 is the initial capital.\n",
        "\n",
        "    Args:\n",
        "        portfolio_values (List[float]): Sequence of portfolio values over time.\n",
        "\n",
        "    Returns:\n",
        "        float: The total return as a decimal (e.g., 0.10 for 10%).\n",
        "    \"\"\"\n",
        "    if not portfolio_values:\n",
        "        return 0.0\n",
        "\n",
        "    P_0 = portfolio_values[0]\n",
        "    P_T = portfolio_values[-1]\n",
        "\n",
        "    if P_0 == 0:\n",
        "        logger.warning(\"Initial portfolio value is 0. Total Return undefined.\")\n",
        "        return 0.0\n",
        "\n",
        "    return (P_T - P_0) / P_0\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 32, Step 2: Compute Sharpe Ratio (SR)\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_sharpe_ratio(portfolio_values: List[float]) -> float:\n",
        "    \"\"\"\n",
        "    Computes the Sharpe Ratio (SR) of a trading strategy.\n",
        "\n",
        "    Equation:\n",
        "        SR = E[return] / sigma(return)\n",
        "\n",
        "    Where 'return' is the sequence of periodic returns: r_t = (V_t - V_{t-1}) / V_{t-1}.\n",
        "    Note: This implementation computes the raw Sharpe Ratio per period (not annualized),\n",
        "    consistent with the manuscript's lack of annualization instruction.\n",
        "\n",
        "    Args:\n",
        "        portfolio_values (List[float]): Sequence of portfolio values over time.\n",
        "\n",
        "    Returns:\n",
        "        float: The Sharpe Ratio.\n",
        "    \"\"\"\n",
        "    if len(portfolio_values) < 2:\n",
        "        return 0.0\n",
        "\n",
        "    # Convert to numpy array\n",
        "    values = np.array(portfolio_values)\n",
        "\n",
        "    # Compute returns: (V_t - V_{t-1}) / V_{t-1}\n",
        "    # We use values[1:] / values[:-1] - 1\n",
        "    # Handle division by zero if value drops to 0 (bankruptcy)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        returns = values[1:] / values[:-1] - 1.0\n",
        "\n",
        "    # Replace NaNs/Infs (bankruptcy) with -1.0 (100% loss) or 0\n",
        "    returns = np.nan_to_num(returns, nan=0.0, posinf=0.0, neginf=0.0)\n",
        "\n",
        "    mean_return = np.mean(returns)\n",
        "    std_return = np.std(returns)\n",
        "\n",
        "    if std_return < 1e-9:\n",
        "        return 0.0\n",
        "\n",
        "    return mean_return / std_return\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 32, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def evaluate_trading_performance(\n",
        "    portfolio_values: List[float]\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 32: Trading Evaluation Metrics.\n",
        "\n",
        "    Computes Total Return (TR) and Sharpe Ratio (SR) for a given portfolio trajectory.\n",
        "\n",
        "    Args:\n",
        "        portfolio_values (List[float]): Time series of portfolio equity.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, float]: Dictionary containing 'TR' and 'SR'.\n",
        "    \"\"\"\n",
        "    tr = compute_total_return(portfolio_values)\n",
        "    sr = compute_sharpe_ratio(portfolio_values)\n",
        "\n",
        "    logger.info(f\"Trading Evaluation: TR={tr:.4f}, SR={sr:.4f}\")\n",
        "\n",
        "    return {\n",
        "        \"TR\": tr,\n",
        "        \"SR\": sr\n",
        "    }\n"
      ],
      "metadata": {
        "id": "OhgGC7CKcBL7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 33 — Implement distribution-shift proximity metrics\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 33: Implement distribution-shift proximity metrics\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 33, Step 1: Implement Population Stability Index (PSI)\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_psi(\n",
        "    baseline: np.ndarray,\n",
        "    target: np.ndarray,\n",
        "    num_bins: int = 10,\n",
        "    epsilon: float = 1e-8\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Computes the Population Stability Index (PSI) between two distributions.\n",
        "\n",
        "    Equation:\n",
        "        PSI = sum((p_i - q_i) * ln(p_i / q_i))\n",
        "\n",
        "    Where p_i and q_i are the proportions of observations in bin i for the\n",
        "    baseline and target distributions, respectively. Bins are defined based on\n",
        "    the baseline distribution (e.g., deciles).\n",
        "\n",
        "    Args:\n",
        "        baseline (np.ndarray): Baseline data (e.g., Training set). Shape (N, F).\n",
        "        target (np.ndarray): Target data (e.g., Test set). Shape (M, F).\n",
        "        num_bins (int): Number of bins for discretization.\n",
        "        epsilon (float): Small constant to avoid division by zero or log(0).\n",
        "\n",
        "    Returns:\n",
        "        float: The average PSI across all features.\n",
        "    \"\"\"\n",
        "    # We compute PSI per feature and average\n",
        "    n_features = baseline.shape[1]\n",
        "    psi_values = []\n",
        "\n",
        "    for f in range(n_features):\n",
        "        base_col = baseline[:, f]\n",
        "        target_col = target[:, f]\n",
        "\n",
        "        # Define bins based on baseline deciles\n",
        "        # We use linspace 0 to 100 for percentiles\n",
        "        breakpoints = np.percentile(base_col, np.linspace(0, 100, num_bins + 1))\n",
        "\n",
        "        # Handle duplicate breakpoints (e.g. sparse data)\n",
        "        breakpoints = np.unique(breakpoints)\n",
        "\n",
        "        # If too few unique values, fallback to simple histogram range\n",
        "        if len(breakpoints) < 2:\n",
        "             # Use min/max\n",
        "             breakpoints = np.linspace(np.min(base_col), np.max(base_col), num_bins + 1)\n",
        "\n",
        "        # Compute histograms\n",
        "        # We use -inf and +inf for outer edges to catch outliers in target\n",
        "        breakpoints[0] = -np.inf\n",
        "        breakpoints[-1] = np.inf\n",
        "\n",
        "        base_counts, _ = np.histogram(base_col, bins=breakpoints)\n",
        "        target_counts, _ = np.histogram(target_col, bins=breakpoints)\n",
        "\n",
        "        # Normalize to proportions\n",
        "        base_props = base_counts / len(base_col)\n",
        "        target_props = target_counts / len(target_col)\n",
        "\n",
        "        # Smooth\n",
        "        base_props = np.maximum(base_props, epsilon)\n",
        "        target_props = np.maximum(target_props, epsilon)\n",
        "\n",
        "        # PSI formula\n",
        "        psi = np.sum((base_props - target_props) * np.log(base_props / target_props))\n",
        "        psi_values.append(psi)\n",
        "\n",
        "    return float(np.mean(psi_values))\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 33, Step 2: Implement Kolmogorov–Smirnov (K–S) statistic\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_ks_statistic(\n",
        "    baseline: np.ndarray,\n",
        "    target: np.ndarray\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Computes the Kolmogorov-Smirnov (K-S) statistic.\n",
        "\n",
        "    Equation:\n",
        "        D_KS = sup |F_1(x) - F_2(x)|\n",
        "\n",
        "    Where F_1 and F_2 are the empirical CDFs.\n",
        "    We compute the K-S statistic for each feature and report the average.\n",
        "\n",
        "    Args:\n",
        "        baseline (np.ndarray): Baseline data (N, F).\n",
        "        target (np.ndarray): Target data (M, F).\n",
        "\n",
        "    Returns:\n",
        "        float: Average K-S statistic across features.\n",
        "    \"\"\"\n",
        "    n_features = baseline.shape[1]\n",
        "    ks_values = []\n",
        "\n",
        "    for f in range(n_features):\n",
        "        base_col = baseline[:, f]\n",
        "        target_col = target[:, f]\n",
        "\n",
        "        # ks_2samp returns (statistic, pvalue)\n",
        "        stat, _ = stats.ks_2samp(base_col, target_col)\n",
        "        ks_values.append(stat)\n",
        "\n",
        "    return float(np.mean(ks_values))\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 33, Step 3: Implement Maximum Mean Discrepancy (MMD)\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_mmd_rbf(\n",
        "    baseline: np.ndarray,\n",
        "    target: np.ndarray,\n",
        "    bandwidth: float = 1.0,\n",
        "    max_samples: int = 2000\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Computes the Maximum Mean Discrepancy (MMD) using an RBF kernel.\n",
        "\n",
        "    Equation:\n",
        "        MMD^2 = E[k(x,x')] + E[k(y,y')] - 2E[k(x,y)]\n",
        "        k(x,y) = exp(-||x-y||^2 / (2*sigma^2))\n",
        "\n",
        "    Args:\n",
        "        baseline (np.ndarray): Baseline data (N, F).\n",
        "        target (np.ndarray): Target data (M, F).\n",
        "        bandwidth (float): RBF kernel bandwidth (sigma).\n",
        "        max_samples (int): Maximum number of samples to use (subsampling for speed).\n",
        "\n",
        "    Returns:\n",
        "        float: The MMD statistic.\n",
        "    \"\"\"\n",
        "    # Subsample if necessary to avoid O(N^2) memory explosion\n",
        "    if len(baseline) > max_samples:\n",
        "        idx = np.random.choice(len(baseline), max_samples, replace=False)\n",
        "        baseline = baseline[idx]\n",
        "    if len(target) > max_samples:\n",
        "        idx = np.random.choice(len(target), max_samples, replace=False)\n",
        "        target = target[idx]\n",
        "\n",
        "    # Convert to torch for efficient pairwise distance computation\n",
        "    X = torch.tensor(baseline, dtype=torch.float32)\n",
        "    Y = torch.tensor(target, dtype=torch.float32)\n",
        "\n",
        "    def rbf_kernel(A, B, sigma):\n",
        "        # Pairwise squared euclidean distance\n",
        "        # ||A - B||^2 = ||A||^2 + ||B||^2 - 2*A*B^T\n",
        "        A_norm = (A**2).sum(1).view(-1, 1)\n",
        "        B_norm = (B**2).sum(1).view(1, -1)\n",
        "        dist_sq = A_norm + B_norm - 2.0 * torch.mm(A, B.t())\n",
        "        # Clamp for numerical stability\n",
        "        dist_sq = torch.clamp(dist_sq, min=0.0)\n",
        "\n",
        "        gamma = 1.0 / (2 * sigma**2)\n",
        "        K = torch.exp(-gamma * dist_sq)\n",
        "        return K\n",
        "\n",
        "    K_xx = rbf_kernel(X, X, bandwidth)\n",
        "    K_yy = rbf_kernel(Y, Y, bandwidth)\n",
        "    K_xy = rbf_kernel(X, Y, bandwidth)\n",
        "\n",
        "    # MMD^2 estimate (unbiased or biased? Biased is simpler: mean of matrix)\n",
        "    # Biased V-statistic:\n",
        "    mmd_sq = K_xx.mean() + K_yy.mean() - 2 * K_xy.mean()\n",
        "\n",
        "    # Return MMD (sqrt)\n",
        "    return float(torch.sqrt(torch.clamp(mmd_sq, min=0.0)).item())\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 33, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_distributional_shift_metrics(\n",
        "    train_data: np.ndarray,\n",
        "    test_data: np.ndarray,\n",
        "    val_data: Optional[np.ndarray] = None,\n",
        "    config: Dict[str, Any] = None\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 33: Distribution Shift Metrics.\n",
        "\n",
        "    Computes PSI, K-S, and MMD between Train-Test and (optionally) Val-Test.\n",
        "    Data is assumed to be standardized (Task 9).\n",
        "\n",
        "    Args:\n",
        "        train_data (np.ndarray): Training features (N, F).\n",
        "        test_data (np.ndarray): Test features (M, F).\n",
        "        val_data (Optional[np.ndarray]): Validation features.\n",
        "        config (Dict): Configuration for metrics (bins, bandwidth).\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, float]: Dictionary of computed metrics.\n",
        "    \"\"\"\n",
        "    logger.info(\"Computing distributional shift metrics...\")\n",
        "\n",
        "    # Defaults\n",
        "    psi_bins = 10\n",
        "    mmd_bw = 1.0\n",
        "    if config:\n",
        "        psi_bins = config.get(\"psi\", {}).get(\"bins_k\", 10)\n",
        "        mmd_bw = config.get(\"mmd\", {}).get(\"bandwidth\", 1.0)\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # Train vs Test\n",
        "    results[\"Train-Test PSI\"] = compute_psi(train_data, test_data, psi_bins)\n",
        "    results[\"Train-Test KS\"] = compute_ks_statistic(train_data, test_data)\n",
        "    results[\"Train-Test MMD\"] = compute_mmd_rbf(train_data, test_data, mmd_bw)\n",
        "\n",
        "    # Val vs Test\n",
        "    if val_data is not None:\n",
        "        results[\"Val-Test PSI\"] = compute_psi(val_data, test_data, psi_bins)\n",
        "        results[\"Val-Test KS\"] = compute_ks_statistic(val_data, test_data)\n",
        "        results[\"Val-Test MMD\"] = compute_mmd_rbf(val_data, test_data, mmd_bw)\n",
        "\n",
        "    logger.info(f\"Shift Metrics: {results}\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "MK9ART8otrHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 34 — Implement stylized facts fidelity metrics\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 34: Implement stylized facts fidelity metrics\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 34, Step 1: Compute autocorrelation of returns\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_autocorrelation(\n",
        "    series: np.ndarray,\n",
        "    lags: List[int]\n",
        ") -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Computes the autocorrelation of a time series for specified lags.\n",
        "\n",
        "    Equation:\n",
        "        rho(k) = Cov(x_t, x_{t-k}) / Var(x_t)\n",
        "\n",
        "    Args:\n",
        "        series (np.ndarray): Time series data (1D).\n",
        "        lags (List[int]): List of lags to compute.\n",
        "\n",
        "    Returns:\n",
        "        Dict[int, float]: Dictionary mapping lag to autocorrelation.\n",
        "    \"\"\"\n",
        "    n = len(series)\n",
        "    results = {}\n",
        "\n",
        "    # Pre-compute mean and var for the whole series (stationarity assumption)\n",
        "    mu = np.mean(series)\n",
        "    var = np.var(series)\n",
        "\n",
        "    if var < 1e-9:\n",
        "        return {k: 0.0 for k in lags}\n",
        "\n",
        "    for k in lags:\n",
        "        if k >= n:\n",
        "            results[k] = 0.0\n",
        "            continue\n",
        "\n",
        "        # Slice\n",
        "        y_t = series[k:]\n",
        "        y_tk = series[:-k]\n",
        "\n",
        "        # Compute covariance term\n",
        "        # We use the global mean for consistency with standard ACF definitions\n",
        "        cov = np.mean((y_t - mu) * (y_tk - mu))\n",
        "\n",
        "        rho = cov / var\n",
        "        results[k] = float(rho)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 34, Step 2: Compute autocorrelation of absolute returns\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_abs_autocorrelation(\n",
        "    returns: np.ndarray,\n",
        "    lags: List[int]\n",
        ") -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Computes the autocorrelation of absolute returns.\n",
        "    Captures volatility clustering (long memory in volatility).\n",
        "\n",
        "    Args:\n",
        "        returns (np.ndarray): Return series.\n",
        "        lags (List[int]): Lags.\n",
        "\n",
        "    Returns:\n",
        "        Dict[int, float]: Autocorrelation of |r_t|.\n",
        "    \"\"\"\n",
        "    abs_returns = np.abs(returns)\n",
        "    return compute_autocorrelation(abs_returns, lags)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 34, Step 3: Compute leverage effect correlation\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_leverage_effect(\n",
        "    returns: np.ndarray,\n",
        "    lags: List[int],\n",
        "    volatility_proxy: str = \"abs_ret\"\n",
        ") -> Dict[int, float]:\n",
        "    \"\"\"\n",
        "    Computes the leverage effect: Correlation between return at t and volatility at t+k.\n",
        "\n",
        "    Equation:\n",
        "        rho_{r,sigma}(k) = Corr(r_t, sigma_{t+k})\n",
        "\n",
        "    Typically negative for stocks (price drop -> higher future volatility).\n",
        "\n",
        "    Args:\n",
        "        returns (np.ndarray): Return series.\n",
        "        lags (List[int]): Lags k > 0.\n",
        "        volatility_proxy (str): 'abs_ret' (|r|) or 'sq_ret' (r^2).\n",
        "                                (Rolling std requires pre-computation).\n",
        "\n",
        "    Returns:\n",
        "        Dict[int, float]: Correlation values.\n",
        "    \"\"\"\n",
        "    n = len(returns)\n",
        "    results = {}\n",
        "\n",
        "    # Define proxy\n",
        "    if volatility_proxy == \"abs_ret\":\n",
        "        vol = np.abs(returns)\n",
        "    elif volatility_proxy == \"sq_ret\":\n",
        "        vol = returns ** 2\n",
        "    else:\n",
        "        # Default to abs\n",
        "        vol = np.abs(returns)\n",
        "\n",
        "    for k in lags:\n",
        "        if k >= n:\n",
        "            results[k] = 0.0\n",
        "            continue\n",
        "\n",
        "        # r_t: 0 to N-1-k\n",
        "        # vol_{t+k}: k to N-1\n",
        "        r_t = returns[:-k]\n",
        "        vol_tk = vol[k:]\n",
        "\n",
        "        if len(r_t) < 2:\n",
        "            results[k] = 0.0\n",
        "            continue\n",
        "\n",
        "        # Pearson Correlation\n",
        "        corr = np.corrcoef(r_t, vol_tk)[0, 1]\n",
        "\n",
        "        if np.isnan(corr):\n",
        "            corr = 0.0\n",
        "\n",
        "        results[k] = float(corr)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 34, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_stylized_facts(\n",
        "    real_returns: np.ndarray,\n",
        "    fake_returns: np.ndarray,\n",
        "    lags: List[int] = [1, 5, 10, 20, 50]\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 34: Stylized Facts Fidelity.\n",
        "\n",
        "    Computes and compares stylized facts between real and synthetic/augmented returns.\n",
        "\n",
        "    Args:\n",
        "        real_returns (np.ndarray): Real return series.\n",
        "        fake_returns (np.ndarray): Synthetic return series.\n",
        "        lags (List[int]): Lags to evaluate.\n",
        "\n",
        "    Returns:\n",
        "        Dict[str, Any]: Dictionary of metrics and differences.\n",
        "    \"\"\"\n",
        "    logger.info(\"Computing stylized facts...\")\n",
        "\n",
        "    # 1. ACF of Returns (Linear)\n",
        "    real_acf = compute_autocorrelation(real_returns, lags)\n",
        "    fake_acf = compute_autocorrelation(fake_returns, lags)\n",
        "\n",
        "    # 2. ACF of Absolute Returns (Volatility Clustering)\n",
        "    real_abs_acf = compute_abs_autocorrelation(real_returns, lags)\n",
        "    fake_abs_acf = compute_abs_autocorrelation(fake_returns, lags)\n",
        "\n",
        "    # 3. Leverage Effect\n",
        "    real_lev = compute_leverage_effect(real_returns, lags)\n",
        "    fake_lev = compute_leverage_effect(fake_returns, lags)\n",
        "\n",
        "    # 4. Compute Differences (Error Metrics)\n",
        "    # Mean Absolute Error across lags\n",
        "    acf_err = np.mean([abs(real_acf[k] - fake_acf[k]) for k in lags])\n",
        "    abs_acf_err = np.mean([abs(real_abs_acf[k] - fake_abs_acf[k]) for k in lags])\n",
        "    lev_err = np.mean([abs(real_lev[k] - fake_lev[k]) for k in lags])\n",
        "\n",
        "    results = {\n",
        "        \"ACF_Returns_Error\": acf_err,\n",
        "        \"ACF_AbsReturns_Error\": abs_acf_err,\n",
        "        \"Leverage_Effect_Error\": lev_err,\n",
        "        \"Real_Stats\": {\n",
        "            \"ACF\": real_acf, \"AbsACF\": real_abs_acf, \"Lev\": real_lev\n",
        "        },\n",
        "        \"Fake_Stats\": {\n",
        "            \"ACF\": fake_acf, \"AbsACF\": fake_abs_acf, \"Lev\": fake_lev\n",
        "        }\n",
        "    }\n",
        "\n",
        "    logger.info(f\"Stylized Facts Errors: ACF={acf_err:.4f}, AbsACF={abs_acf_err:.4f}, Lev={lev_err:.4f}\")\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "usOq5IQivU5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 35 — Implement t-SNE visualization for drift analysis\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 35: Implement t-SNE visualization for drift analysis\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 35, Step 1: Configure t-SNE\n",
        "# ------------------------------------------------------------------------------\n",
        "def configure_tsne(\n",
        "    perplexity: int = 30,\n",
        "    n_iter: int = 500,\n",
        "    random_state: int = 42\n",
        ") -> TSNE:\n",
        "    \"\"\"\n",
        "    Configures the t-SNE estimator with manuscript-specified parameters.\n",
        "\n",
        "    Args:\n",
        "        perplexity (int): The perplexity is related to the number of nearest neighbors.\n",
        "        n_iter (int): Maximum number of iterations for the optimization.\n",
        "        random_state (int): Seed for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "        TSNE: Configured sklearn TSNE object.\n",
        "    \"\"\"\n",
        "    return TSNE(\n",
        "        n_components=2,\n",
        "        perplexity=perplexity,\n",
        "        n_iter=n_iter,\n",
        "        random_state=random_state,\n",
        "        init='pca', # Standard initialization\n",
        "        learning_rate='auto'\n",
        "    )\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 35, Step 2: Generate t-SNE embeddings\n",
        "# ------------------------------------------------------------------------------\n",
        "def compute_tsne_embeddings(\n",
        "    train_x: np.ndarray,\n",
        "    train_y: np.ndarray,\n",
        "    test_x: np.ndarray,\n",
        "    test_y: np.ndarray,\n",
        "    max_samples: int = 2000,\n",
        "    random_state: int = 42\n",
        ") -> Dict[str, Tuple[np.ndarray, np.ndarray]]:\n",
        "    \"\"\"\n",
        "    Computes t-SNE embeddings for P(X) and P(Y|X) (approximated by P(X,Y)).\n",
        "\n",
        "    Args:\n",
        "        train_x (np.ndarray): Training features (N, F).\n",
        "        train_y (np.ndarray): Training targets (N,).\n",
        "        test_x (np.ndarray): Test features (M, F).\n",
        "        test_y (np.ndarray): Test targets (M,).\n",
        "        max_samples (int): Max samples to use per split to keep t-SNE fast.\n",
        "        random_state (int): Seed for subsampling.\n",
        "\n",
        "    Returns:\n",
        "        Dict: Keys 'P(X)', 'P(Y|X)'. Values are tuples (train_embedding, test_embedding).\n",
        "    \"\"\"\n",
        "    rng = np.random.default_rng(random_state)\n",
        "\n",
        "    # Subsample if needed\n",
        "    if len(train_x) > max_samples:\n",
        "        idx = rng.choice(len(train_x), max_samples, replace=False)\n",
        "        train_x = train_x[idx]\n",
        "        train_y = train_y[idx]\n",
        "\n",
        "    if len(test_x) > max_samples:\n",
        "        idx = rng.choice(len(test_x), max_samples, replace=False)\n",
        "        test_x = test_x[idx]\n",
        "        test_y = test_y[idx]\n",
        "\n",
        "    # 1. P(X) Embedding\n",
        "    # Concatenate\n",
        "    X_combined = np.vstack([train_x, test_x])\n",
        "    tsne_x = configure_tsne(random_state=random_state)\n",
        "    emb_x = tsne_x.fit_transform(X_combined)\n",
        "\n",
        "    train_emb_x = emb_x[:len(train_x)]\n",
        "    test_emb_x = emb_x[len(train_x):]\n",
        "\n",
        "    # 2. P(Y|X) Embedding (Joint P(X,Y))\n",
        "    # Normalize Y to match X scale roughly (Z-score)\n",
        "    y_mean = np.mean(train_y)\n",
        "    y_std = np.std(train_y) + 1e-8\n",
        "\n",
        "    train_y_norm = (train_y - y_mean) / y_std\n",
        "    test_y_norm = (test_y - y_mean) / y_std\n",
        "\n",
        "    # Concatenate X and Y\n",
        "    # Reshape Y to (N, 1)\n",
        "    train_xy = np.hstack([train_x, train_y_norm.reshape(-1, 1)])\n",
        "    test_xy = np.hstack([test_x, test_y_norm.reshape(-1, 1)])\n",
        "\n",
        "    XY_combined = np.vstack([train_xy, test_xy])\n",
        "    tsne_xy = configure_tsne(random_state=random_state)\n",
        "    emb_xy = tsne_xy.fit_transform(XY_combined)\n",
        "\n",
        "    train_emb_xy = emb_xy[:len(train_x)]\n",
        "    test_emb_xy = emb_xy[len(train_x):]\n",
        "\n",
        "    return {\n",
        "        \"P(X)\": (train_emb_x, test_emb_x),\n",
        "        \"P(Y|X)\": (train_emb_xy, test_emb_xy)\n",
        "    }\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 35, Step 3: Visualize and persist\n",
        "# ------------------------------------------------------------------------------\n",
        "def plot_tsne(\n",
        "    embeddings: Dict[str, Tuple[np.ndarray, np.ndarray]],\n",
        "    save_dir: str = \".\"\n",
        ") -> List[str]:\n",
        "    \"\"\"\n",
        "    Plots t-SNE embeddings with Train (Orange) and Test (Blue) colors.\n",
        "\n",
        "    Args:\n",
        "        embeddings (Dict): Output from compute_tsne_embeddings.\n",
        "        save_dir (str): Directory to save figures.\n",
        "\n",
        "    Returns:\n",
        "        List[str]: Paths to saved figures.\n",
        "    \"\"\"\n",
        "    saved_paths = []\n",
        "\n",
        "    for key, (train_emb, test_emb) in embeddings.items():\n",
        "        plt.figure(figsize=(8, 6))\n",
        "\n",
        "        # Plot Train (Orange)\n",
        "        plt.scatter(train_emb[:, 0], train_emb[:, 1], c='orange', label='Train', alpha=0.5, s=10)\n",
        "\n",
        "        # Plot Test (Blue)\n",
        "        plt.scatter(test_emb[:, 0], test_emb[:, 1], c='blue', label='Test', alpha=0.5, s=10)\n",
        "\n",
        "        plt.title(f\"t-SNE Visualization: {key}\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "\n",
        "        # Save\n",
        "        filename = f\"tsne_{key.replace('|', '_').replace('(', '').replace(')', '')}.png\"\n",
        "        path = os.path.join(save_dir, filename)\n",
        "        plt.savefig(path, dpi=300)\n",
        "        plt.close()\n",
        "\n",
        "        saved_paths.append(path)\n",
        "\n",
        "    return saved_paths\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 35, Orchestrator Function\n",
        "# ------------------------------------------------------------------------------\n",
        "def run_drift_visualization(\n",
        "    train_x: np.ndarray,\n",
        "    train_y: np.ndarray,\n",
        "    test_x: np.ndarray,\n",
        "    test_y: np.ndarray,\n",
        "    save_dir: str = \".\"\n",
        ") -> Dict[str, Any]:\n",
        "    \"\"\"\n",
        "    Orchestrator for Task 35: t-SNE Drift Visualization.\n",
        "\n",
        "    Args:\n",
        "        train_x, train_y: Training data.\n",
        "        test_x, test_y: Test data.\n",
        "        save_dir: Output directory.\n",
        "\n",
        "    Returns:\n",
        "        Dict: Paths to saved figures.\n",
        "    \"\"\"\n",
        "    logger.info(\"Starting t-SNE drift visualization...\")\n",
        "\n",
        "    # Compute\n",
        "    embeddings = compute_tsne_embeddings(train_x, train_y, test_x, test_y)\n",
        "\n",
        "    # Plot\n",
        "    paths = plot_tsne(embeddings, save_dir)\n",
        "\n",
        "    logger.info(f\"t-SNE plots saved to: {paths}\")\n",
        "    return {\"plot_paths\": paths}\n"
      ],
      "metadata": {
        "id": "AZhMoYmywyVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 36: Create orchestrator function for end-to-end pipeline\n",
        "\n",
        "# ==============================================================================\n",
        "# Task 36: Create orchestrator function for end-to-end pipeline\n",
        "# ==============================================================================\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 36, Step 1: Define RunContext Dataclass\n",
        "# ------------------------------------------------------------------------------\n",
        "@dataclass\n",
        "class RunContext:\n",
        "    \"\"\"\n",
        "    Centralized state container for the Adaptive Dataflow System pipeline.\n",
        "\n",
        "    This dataclass encapsulates all artifacts generated during the execution of the\n",
        "    end-to-end workflow, ensuring provenance tracking, reproducibility, and\n",
        "    clean data handover between pipeline stages. It serves as the single source\n",
        "    of truth for the state of a specific experimental run.\n",
        "\n",
        "    Attributes:\n",
        "        universe (str): The universe identifier (e.g., \"US_Stocks_Daily\").\n",
        "        config (Dict[str, Any]): The fully resolved configuration dictionary.\n",
        "        config_hash (str): SHA256 hash of the configuration for unique identification.\n",
        "\n",
        "        # Data Artifacts\n",
        "        df_clean (pd.DataFrame): The cleansed and curated raw dataframe.\n",
        "        targets (pd.Series): The computed forecasting targets y_t.\n",
        "        tensor_data (Dict[str, Any]): Dictionary containing windowed and aligned tensors.\n",
        "        split_metadata (Any): The SplitMetadata object defining train/valid/test boundaries.\n",
        "        normalizer (Any): The fitted Normalizer artifact.\n",
        "        cointegration_matrix (np.ndarray): The pairwise cointegration p-value matrix.\n",
        "\n",
        "        # Model Artifacts\n",
        "        training_results (Dict[str, Any]): Output from the forecasting training pipeline (Task 27).\n",
        "                                           Contains metrics, history, and state_dicts for all models.\n",
        "        rl_results (Dict[str, Any]): Output from the RL transfer experiment (Task 31).\n",
        "\n",
        "        # Evaluation Artifacts\n",
        "        drift_metrics (Dict[str, float]): Distributional shift metrics (PSI, KS, MMD).\n",
        "        stylized_facts (Dict[str, Any]): Stylized facts fidelity analysis results.\n",
        "        drift_plots (Dict[str, Any]): Paths to generated t-SNE plots.\n",
        "    \"\"\"\n",
        "    universe: str\n",
        "    config: Dict[str, Any]\n",
        "    config_hash: str\n",
        "\n",
        "    # Data\n",
        "    df_clean: Optional[pd.DataFrame] = None\n",
        "    targets: Optional[pd.Series] = None\n",
        "    tensor_data: Optional[Dict[str, Any]] = None\n",
        "    split_metadata: Optional[Any] = None # SplitMetadata type\n",
        "    normalizer: Optional[Any] = None # Normalizer type\n",
        "    cointegration_matrix: Optional[np.ndarray] = None\n",
        "\n",
        "    # Models\n",
        "    training_results: Optional[Dict[str, Any]] = None\n",
        "    rl_results: Optional[Dict[str, Any]] = None\n",
        "\n",
        "    # Evaluation\n",
        "    drift_metrics: Optional[Dict[str, float]] = None\n",
        "    stylized_facts: Optional[Dict[str, Any]] = None\n",
        "    drift_plots: Optional[Dict[str, Any]] = None\n",
        "\n",
        "    def save(self, output_dir: str) -> None:\n",
        "        \"\"\"\n",
        "        Persists the RunContext to disk for provenance-aware replay.\n",
        "\n",
        "        Saves the context object as a pickle file and key metadata as JSON\n",
        "        for human readability.\n",
        "\n",
        "        Args:\n",
        "            output_dir (str): Directory to save artifacts.\n",
        "        \"\"\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Save full context via pickle\n",
        "        ctx_path = os.path.join(output_dir, \"run_context.pkl\")\n",
        "        with open(ctx_path, \"wb\") as f:\n",
        "            pickle.dump(self, f)\n",
        "\n",
        "        # Save Config JSON\n",
        "        config_path = os.path.join(output_dir, \"config.json\")\n",
        "        with open(config_path, \"w\") as f:\n",
        "            json.dump(self.config, f, indent=4, default=str)\n",
        "\n",
        "        # Save Metrics JSON (Extract from training_results if available)\n",
        "        if self.training_results:\n",
        "            metrics_summary = {\n",
        "                model: res[\"metrics\"]\n",
        "                for model, res in self.training_results.items()\n",
        "            }\n",
        "            metrics_path = os.path.join(output_dir, \"forecasting_metrics.json\")\n",
        "            with open(metrics_path, \"w\") as f:\n",
        "                json.dump(metrics_summary, f, indent=4)\n",
        "\n",
        "        logger.info(f\"RunContext saved to {output_dir}\")\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 36, Step 2: Helper for Synthetic Data Generation\n",
        "# ------------------------------------------------------------------------------\n",
        "def generate_synthetic_returns(\n",
        "    model_state: Dict[str, Any],\n",
        "    planner_state: Dict[str, Any],\n",
        "    tensor_data: Dict[str, Any],\n",
        "    split_metadata: Any,\n",
        "    config: Dict[str, Any],\n",
        "    normalizer: Any,\n",
        "    transformer_registry: Any,\n",
        "    mixup_registry: Any\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Generates a sequence of synthetic returns using the trained Planner and Task Model.\n",
        "    This is required for Task 34 (Stylized Facts) to compare Real vs. Synthetic distributions.\n",
        "\n",
        "    Args:\n",
        "        model_state (Dict): State dict of the trained task model.\n",
        "        planner_state (Dict): State dict of the trained planner.\n",
        "        tensor_data (Dict): Data dictionary containing X_windows.\n",
        "        split_metadata (Any): Split metadata for test indices.\n",
        "        config (Dict): Configuration dictionary.\n",
        "        normalizer (Any): Fitted normalizer.\n",
        "        transformer_registry (Any): Registry for single-stock ops.\n",
        "        mixup_registry (Any): Registry for mix-up ops.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array of synthetic returns.\n",
        "    \"\"\"\n",
        "    # Re-instantiate models\n",
        "    # Note: We assume LSTM for this generation as it's the primary model for transfer/analysis\n",
        "    input_dim = tensor_data[\"X_windows\"].shape[2]\n",
        "    model_cfg = config[\"task_models\"][\"LSTM\"]\n",
        "    planner_cfg = config[\"planner\"]\n",
        "\n",
        "    task_model = LSTMForecaster(input_dim=input_dim, **model_cfg[\"architecture_details\"])\n",
        "    task_model.load_state_dict(model_state)\n",
        "\n",
        "    n_ops_single = len(config[\"manipulation_module\"][\"operations\"][\"single_stock\"])\n",
        "    n_ops_multi = len(config[\"manipulation_module\"][\"operations\"][\"multi_stock\"])\n",
        "\n",
        "    planner = Planner(\n",
        "        embedding_dim=128,\n",
        "        stats_dim=6,\n",
        "        planner_input_dim=planner_cfg[\"input_dim\"],\n",
        "        num_layers=planner_cfg[\"LSTM\"][\"layers\"],\n",
        "        nhead=4,\n",
        "        dim_feedforward=planner_cfg[\"input_dim\"] * 4,\n",
        "        n_ops_single=n_ops_single,\n",
        "        n_ops_multi=n_ops_multi\n",
        "    )\n",
        "    planner.load_state_dict(planner_state)\n",
        "\n",
        "    task_model.eval()\n",
        "    planner.eval()\n",
        "\n",
        "    # Get Test Data (Using Test set as seed for generation to verify generalization)\n",
        "    # We filter X_windows using sample_keys and split_metadata.test_range\n",
        "    sample_keys = tensor_data[\"sample_keys\"] # List of (ticker, date)\n",
        "    test_start, test_end = split_metadata.test_range\n",
        "\n",
        "    # Create mask for test set\n",
        "    test_mask = []\n",
        "    for _, date in sample_keys:\n",
        "        test_mask.append(test_start <= date <= test_end)\n",
        "\n",
        "    X_test = torch.tensor(tensor_data[\"X_windows\"][test_mask], dtype=torch.float32)\n",
        "    y_test = torch.tensor(tensor_data[\"y\"][test_mask], dtype=torch.float32)\n",
        "\n",
        "    if len(X_test) == 0:\n",
        "        logger.warning(\"No test samples found for synthetic generation. Using Validation set.\")\n",
        "        val_start, val_end = split_metadata.valid_range\n",
        "        val_mask = []\n",
        "        for _, date in sample_keys:\n",
        "            val_mask.append(val_start <= date <= val_end)\n",
        "        X_test = torch.tensor(tensor_data[\"X_windows\"][val_mask], dtype=torch.float32)\n",
        "        y_test = torch.tensor(tensor_data[\"y\"][val_mask], dtype=torch.float32)\n",
        "\n",
        "    # Generate Synthetic Data\n",
        "    synthetic_returns = []\n",
        "\n",
        "    batch_size = 256\n",
        "    single_ops = config[\"manipulation_module\"][\"operations\"][\"single_stock\"]\n",
        "    multi_ops = config[\"manipulation_module\"][\"operations\"][\"multi_stock\"]\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, len(X_test), batch_size):\n",
        "            x_batch = X_test[i:i+batch_size]\n",
        "            y_batch = y_test[i:i+batch_size]\n",
        "\n",
        "            # Planner Inference\n",
        "            embedding = task_model.extract_embedding(x_batch)\n",
        "            p_matrix, lambda_matrix = planner(embedding, x_batch)\n",
        "\n",
        "            # Apply Manipulation\n",
        "            B = x_batch.shape[0]\n",
        "            x_numpy = x_batch.numpy()\n",
        "            y_numpy = y_batch.numpy()\n",
        "\n",
        "            x_aug_list = []\n",
        "\n",
        "            # Flatten p for sampling\n",
        "            p_flat = p_matrix.view(B, -1)\n",
        "            op_indices = torch.multinomial(p_flat, 1).squeeze()\n",
        "\n",
        "            for b in range(B):\n",
        "                idx = op_indices[b].item() if op_indices.ndim > 0 else op_indices.item()\n",
        "                op_i = idx // len(multi_ops)\n",
        "                op_j = idx % len(multi_ops)\n",
        "\n",
        "                single_op = single_ops[op_i]\n",
        "                multi_op = multi_ops[op_j]\n",
        "                lam = lambda_matrix[b, op_i, op_j].item()\n",
        "\n",
        "                # Single\n",
        "                x_trans = transformer_registry.apply(x_numpy[b], single_op, lam, seed=42+b)\n",
        "\n",
        "                # Normalize\n",
        "                x_norm = normalize_window(x_trans, normalizer)\n",
        "\n",
        "                # Multi (Target: next sample in batch, cyclic)\n",
        "                tgt_idx = (b + 1) % B\n",
        "                x_tgt = x_numpy[tgt_idx]\n",
        "                x_tgt_norm = normalize_window(x_tgt, normalizer)\n",
        "\n",
        "                x_mixed, _ = mixup_registry.apply(\n",
        "                    x_norm, y_numpy[b], x_tgt_norm, y_numpy[tgt_idx],\n",
        "                    multi_op, lam, seed=42+b\n",
        "                )\n",
        "                x_aug_list.append(x_mixed)\n",
        "\n",
        "            x_aug_tensor = torch.tensor(np.stack(x_aug_list), dtype=torch.float32)\n",
        "\n",
        "            # Predict\n",
        "            preds = task_model(x_aug_tensor).squeeze()\n",
        "            synthetic_returns.extend(preds.numpy())\n",
        "\n",
        "    return np.array(synthetic_returns)\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# Task 36, Step 3: Implement run_pipeline_orchestrator\n",
        "# ------------------------------------------------------------------------------\n",
        "def run_pipeline_orchestrator(\n",
        "    df_raw: pd.DataFrame,\n",
        "    universe: str,\n",
        "    study_config: Dict[str, Any],\n",
        "    output_dir: str = \"./artifacts\"\n",
        ") -> RunContext:\n",
        "    \"\"\"\n",
        "    Master Orchestrator for the Adaptive Dataflow System.\n",
        "\n",
        "    Executes the complete research pipeline in strict accordance with the manuscript's\n",
        "    methodology. Enforces the dependency graph between tasks, ensures leakage controls\n",
        "    via SplitMetadata, and manages the flow of artifacts from ingestion to evaluation.\n",
        "\n",
        "    Sequence:\n",
        "        1.  Validation (Tasks 1-3)\n",
        "        2.  Cleansing & Curation (Task 4)\n",
        "        3.  Configuration Resolution (Task 5)\n",
        "        4.  Target Generation (Task 6)\n",
        "        5.  Tensor Construction (Task 7)\n",
        "        6.  Chronological Splitting (Task 8)\n",
        "        7.  Normalization (Task 9)\n",
        "        8.  Cointegration Analysis (Task 10)\n",
        "        9.  Forecasting Training (Task 27)\n",
        "        10. RL Transfer Experiment (Task 31)\n",
        "        11. Evaluation & Drift Analysis (Tasks 33-35)\n",
        "\n",
        "    Args:\n",
        "        df_raw (pd.DataFrame): The raw input dataframe.\n",
        "        universe (str): The universe identifier.\n",
        "        study_config (Dict[str, Any]): The initial configuration dictionary.\n",
        "        output_dir (str): Directory to save run artifacts.\n",
        "\n",
        "    Returns:\n",
        "        RunContext: The populated state container holding all run artifacts.\n",
        "    \"\"\"\n",
        "    logger.info(\"=\" * 80)\n",
        "    logger.info(f\"Starting End-to-End Pipeline for Universe: {universe}\")\n",
        "    logger.info(\"=\" * 80)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Phase 1: Validation & Setup\n",
        "    # -------------------------------------------------------------------------\n",
        "    logger.info(\"Phase 1: Validation & Setup\")\n",
        "\n",
        "    # Task 1: Schema Validation\n",
        "    validate_raw_data_schema(df_raw, universe, study_config)\n",
        "\n",
        "    # Task 2: Config Validation\n",
        "    validate_study_config(study_config)\n",
        "\n",
        "    # Task 3: Financial Realism\n",
        "    validate_financial_realism(df_raw, universe)\n",
        "\n",
        "    # Task 5: Resolve Config (Moved up to ensure downstream tasks use resolved values)\n",
        "    resolved_config, config_hash = resolve_study_configuration(study_config)\n",
        "\n",
        "    # Initialize Context\n",
        "    ctx = RunContext(universe=universe, config=resolved_config, config_hash=config_hash)\n",
        "    run_dir = os.path.join(output_dir, config_hash)\n",
        "    os.makedirs(run_dir, exist_ok=True)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Phase 2: Data Engineering\n",
        "    # -------------------------------------------------------------------------\n",
        "    logger.info(\"Phase 2: Data Engineering\")\n",
        "\n",
        "    # Task 4: Cleanse & Curate\n",
        "    df_clean, _ = cleanse_and_curate_data(df_raw, universe)\n",
        "    ctx.df_clean = df_clean\n",
        "\n",
        "    # Task 6: Targets\n",
        "    y, _ = compute_forecasting_targets(df_clean)\n",
        "    ctx.targets = y\n",
        "\n",
        "    # Task 7: Tensors\n",
        "    # Note: construct_feature_tensors expects the resolved config\n",
        "    tensor_data = construct_feature_tensors(df_clean, y, resolved_config)\n",
        "    ctx.tensor_data = tensor_data\n",
        "\n",
        "    # Task 8: Splits\n",
        "    # Uses aligned timestamps from Task 7\n",
        "    timestamps = tensor_data[\"aligned_timestamps\"]\n",
        "    split_metadata = create_chronological_splits(timestamps, universe, resolved_config)\n",
        "    ctx.split_metadata = split_metadata\n",
        "\n",
        "    # Task 9: Normalization\n",
        "    # Uses aligned tensor and split metadata (train indices)\n",
        "    aligned_tensor = tensor_data[\"aligned_tensor\"]\n",
        "    feature_names = tensor_data[\"feature_names\"]\n",
        "\n",
        "    # Ensure train-only fit\n",
        "    split_metadata.assert_train_only(timestamps[split_metadata.train_indices])\n",
        "\n",
        "    normalized_tensor, normalizer = normalize_data(aligned_tensor, split_metadata, feature_names)\n",
        "    ctx.normalizer = normalizer\n",
        "\n",
        "    # Task 10: Cointegration\n",
        "    # Must use normalized or log-transformed prices from training set.\n",
        "    # compute_cointegration_matrix handles extraction and transform.\n",
        "    # We pass the aligned_tensor (raw) because the function handles the transform internally.\n",
        "    p_matrix = compute_cointegration_matrix(\n",
        "        aligned_tensor,\n",
        "        split_metadata,\n",
        "        resolved_config,\n",
        "        feature_names\n",
        "    )\n",
        "    ctx.cointegration_matrix = p_matrix\n",
        "\n",
        "    # Update config with computed p-matrix for the Manipulation Module\n",
        "    # The manipulation module needs this matrix for Algorithm 1.\n",
        "    resolved_config[\"manipulation_module\"][\"cointegration_p_values\"] = torch.tensor(p_matrix, dtype=torch.float32)\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Phase 3: Modeling & Training\n",
        "    # -------------------------------------------------------------------------\n",
        "    logger.info(\"Phase 3: Modeling & Training\")\n",
        "\n",
        "    # Task 27: Full Training Pipeline\n",
        "    # Instantiate Registries\n",
        "    transformer_registry = SingleStockTransformations()\n",
        "    mixup_registry = MultiStockMixup()\n",
        "\n",
        "    # Inject Normalizer into Config for Wrappers\n",
        "    # The wrappers in Task 27 need access to the normalizer to normalize windows on-the-fly\n",
        "    # after single-stock transformations.\n",
        "    resolved_config[\"runtime_normalizer\"] = normalizer\n",
        "    resolved_config[\"feature_names\"] = feature_names\n",
        "\n",
        "    training_results = run_full_training_pipeline(\n",
        "        tensor_data,\n",
        "        split_metadata,\n",
        "        resolved_config,\n",
        "        transformer_registry,\n",
        "        mixup_registry,\n",
        "        scheduler_step,\n",
        "        joint_training_orchestrator,\n",
        "        generate_weighted_mixture\n",
        "    )\n",
        "    ctx.training_results = training_results\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Phase 4: Transfer Learning\n",
        "    # -------------------------------------------------------------------------\n",
        "    logger.info(\"Phase 4: Transfer Learning\")\n",
        "\n",
        "    # Task 31: RL Transfer\n",
        "    # We need the LSTM planner artifact.\n",
        "    if \"LSTM\" in training_results:\n",
        "        lstm_planner_state = training_results[\"LSTM\"][\"planner_state\"]\n",
        "        planner_artifact = {\"state_dict\": lstm_planner_state}\n",
        "\n",
        "        rl_results = run_rl_transfer_experiment(\n",
        "            planner_artifact,\n",
        "            tensor_data,\n",
        "            df_clean, # Real historical data\n",
        "            resolved_config,\n",
        "            transformer_registry\n",
        "        )\n",
        "        ctx.rl_results = rl_results\n",
        "    else:\n",
        "        logger.warning(\"LSTM model not found in training results. Skipping RL Transfer.\")\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Phase 5: Evaluation\n",
        "    # -------------------------------------------------------------------------\n",
        "    logger.info(\"Phase 5: Evaluation\")\n",
        "\n",
        "    # Task 33: Distribution Shift\n",
        "    # We need standardized Train and Test data.\n",
        "    # We use the normalized_tensor computed in Task 9.\n",
        "    # Slice using split indices.\n",
        "    # Flatten (T, S, F) -> (N, F) for distribution comparison.\n",
        "    train_norm = normalized_tensor[split_metadata.train_indices].reshape(-1, len(feature_names))\n",
        "    test_norm = normalized_tensor[split_metadata.test_indices].reshape(-1, len(feature_names))\n",
        "    val_norm = normalized_tensor[split_metadata.valid_indices].reshape(-1, len(feature_names))\n",
        "\n",
        "    drift_metrics = compute_distributional_shift_metrics(\n",
        "        train_norm, test_norm, val_norm, resolved_config[\"evaluation\"][\"proximity_metrics\"]\n",
        "    )\n",
        "    ctx.drift_metrics = drift_metrics\n",
        "\n",
        "    # Task 34: Stylized Facts\n",
        "    # Compare Real Returns vs Synthetic Returns.\n",
        "    if \"LSTM\" in training_results:\n",
        "        logger.info(\"Generating synthetic returns for Stylized Facts analysis...\")\n",
        "\n",
        "        # Get Real Returns (Test Set)\n",
        "        # We filter y by test keys.\n",
        "        sample_keys = tensor_data[\"sample_keys\"]\n",
        "        test_start, test_end = split_metadata.test_range\n",
        "        test_mask = [test_start <= d <= test_end for _, d in sample_keys]\n",
        "        real_returns = tensor_data[\"y\"][test_mask]\n",
        "\n",
        "        # Generate Synthetic\n",
        "        synthetic_returns = generate_synthetic_returns(\n",
        "            training_results[\"LSTM\"][\"model_state\"],\n",
        "            training_results[\"LSTM\"][\"planner_state\"],\n",
        "            tensor_data,\n",
        "            split_metadata,\n",
        "            resolved_config,\n",
        "            normalizer,\n",
        "            transformer_registry,\n",
        "            mixup_registry\n",
        "        )\n",
        "\n",
        "        stylized_facts = compute_stylized_facts(\n",
        "            real_returns,\n",
        "            synthetic_returns,\n",
        "            resolved_config[\"evaluation\"][\"stylized_facts\"][\"acf_lags\"]\n",
        "        )\n",
        "        ctx.stylized_facts = stylized_facts\n",
        "    else:\n",
        "        logger.warning(\"LSTM model missing. Skipping Stylized Facts generation.\")\n",
        "\n",
        "    # Task 35: t-SNE\n",
        "    # We need targets for P(Y|X).\n",
        "    # The aligned tensor has shape (T, S, F). We need y of shape (T, S).\n",
        "    # We reconstruct y from the target series (Task 6) aligned to the tensor timestamps.\n",
        "    # y (Series) index is (ticker, date).\n",
        "    # We unstack to (date, ticker) -> (T, S).\n",
        "    y_series = ctx.targets\n",
        "\n",
        "    # Ensure y_series is sorted\n",
        "    y_series = y_series.sort_index()\n",
        "\n",
        "    # Unstack to match aligned tensor structure (Time x Stock)\n",
        "    # y_unstacked: Index=Date, Columns=Ticker\n",
        "    y_unstacked = y_series.unstack(level=\"ticker\")\n",
        "\n",
        "    # Reindex to match aligned tensor timestamps and tickers\n",
        "    aligned_timestamps = tensor_data[\"aligned_timestamps\"]\n",
        "    aligned_tickers = tensor_data[\"aligned_tickers\"]\n",
        "\n",
        "    y_aligned = y_unstacked.reindex(index=aligned_timestamps, columns=aligned_tickers)\n",
        "\n",
        "    # Convert to numpy (T, S)\n",
        "    y_matrix = y_aligned.values\n",
        "\n",
        "    # Flatten to (N_total,)\n",
        "    y_flat = y_matrix.flatten()\n",
        "\n",
        "    # Flatten normalized tensor to (N_total, F)\n",
        "    X_flat = normalized_tensor.reshape(-1, len(feature_names))\n",
        "\n",
        "    # Create masks for Train and Test based on split indices\n",
        "    # split_metadata indices are for the time dimension (T)\n",
        "    # We need to map T indices to flattened indices (T*S)\n",
        "    S = len(aligned_tickers)\n",
        "\n",
        "    # Train Mask\n",
        "    train_mask = np.zeros(len(y_flat), dtype=bool)\n",
        "    for t_idx in split_metadata.train_indices:\n",
        "        start = t_idx * S\n",
        "        end = start + S\n",
        "        train_mask[start:end] = True\n",
        "\n",
        "    # Test Mask\n",
        "    test_mask = np.zeros(len(y_flat), dtype=bool)\n",
        "    for t_idx in split_metadata.test_indices:\n",
        "        start = t_idx * S\n",
        "        end = start + S\n",
        "        test_mask[start:end] = True\n",
        "\n",
        "    # Filter NaNs (where targets or features are missing)\n",
        "    # X_flat might have NaNs if alignment was 'union'\n",
        "    # y_flat has NaNs for missing targets\n",
        "    valid_mask = ~np.isnan(y_flat) & ~np.isnan(X_flat).any(axis=1)\n",
        "\n",
        "    train_final_mask = train_mask & valid_mask\n",
        "    test_final_mask = test_mask & valid_mask\n",
        "\n",
        "    # Extract Data for t-SNE\n",
        "    train_x_tsne = X_flat[train_final_mask]\n",
        "    train_y_tsne = y_flat[train_final_mask]\n",
        "\n",
        "    test_x_tsne = X_flat[test_final_mask]\n",
        "    test_y_tsne = y_flat[test_final_mask]\n",
        "\n",
        "    drift_plots = run_drift_visualization(\n",
        "        train_x_tsne, train_y_tsne, test_x_tsne, test_y_tsne,\n",
        "        save_dir=run_dir\n",
        "    )\n",
        "    ctx.drift_plots = drift_plots\n",
        "\n",
        "    # -------------------------------------------------------------------------\n",
        "    # Phase 6: Persistence\n",
        "    # -------------------------------------------------------------------------\n",
        "    logger.info(\"Phase 6: Persistence\")\n",
        "    ctx.save(run_dir)\n",
        "\n",
        "    logger.info(\"=\" * 80)\n",
        "    logger.info(\"Pipeline Execution Completed Successfully.\")\n",
        "    logger.info(f\"Artifacts stored in: {run_dir}\")\n",
        "    logger.info(\"=\" * 80)\n",
        "\n",
        "    return ctx\n"
      ],
      "metadata": {
        "id": "h6iQDHPswt6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}